; ModuleID = 'conv_nn_hvx128'
source_filename = "/home/arnoor2/Racket/TensorSynth/Rosette-experiments/frontends/halide/src/runtime/qurt_allocator.cpp"
target datalayout = "e-m:e-p:32:32:32-a:0-n16:32-i64:64:64-i32:32:32-i16:16:16-i1:8:8-f32:32:32-f64:64:64-v32:32:32-v64:64:64-v512:512:512-v1024:1024:1024-v2048:2048:2048"
target triple = "hexagon-unknown--elf"

%struct.halide_parallel_task_t = type { i32 (i8*, i32, i32, i8*, i8*)*, i8*, i8*, %struct.halide_semaphore_acquire_t*, i32, i32, i32, i32, i8 }
%struct.halide_semaphore_acquire_t = type { %struct.halide_semaphore_t*, i32 }
%struct.halide_semaphore_t = type { [2 x i64] }
%struct.halide_mutex_array = type { %struct.halide_mutex* }
%struct.halide_mutex = type { [1 x i32] }
%struct.halide_device_allocation_pool = type { i32 (i8*)*, %struct.halide_device_allocation_pool* }
%struct.halide_filter_argument_t = type { i8*, i32, i32, %struct.halide_type_t, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, i64** }
%struct.halide_type_t = type { i8, i8, i16 }
%struct.halide_scalar_value_t = type { %union.anon }
%union.anon = type { i64 }
%struct.halide_filter_metadata_t = type { i32, i32, %struct.halide_filter_argument_t*, i8*, i8* }
%struct.halide_thread = type opaque
%struct.halide_buffer_t = type { i64, %struct.halide_device_interface_t*, i8*, i64, %struct.halide_type_t, i32, %struct.halide_dimension_t*, i8* }
%struct.halide_device_interface_t = type { i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, void (i8*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i64, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, i32*, i32*)*, %struct.halide_device_interface_impl_t* }
%struct.halide_device_interface_impl_t = type { void ()*, void ()*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i64)*, i32 (i8*, %struct.halide_buffer_t*)* }
%struct.halide_dimension_t = type { i32, i32, i32, i32 }
%"struct.Halide::Runtime::Internal::device_copy" = type { i64, i64, i64, [16 x i64], [16 x i64], [16 x i64], i64 }
%"struct.Halide::Runtime::Internal::CpuFeatures" = type { [2 x i64], [2 x i64] }

@_ZN6Halide7Runtime8Internal11buf_is_usedE = linkonce global [10 x i32] zeroinitializer, align 4
@_ZN6Halide7Runtime8Internal7mem_bufE = linkonce local_unnamed_addr global [10 x i8*] zeroinitializer, align 4
@_ZN6Halide7Runtime8Internal13custom_mallocE = linkonce local_unnamed_addr global i8* (i8*, i32)* @halide_default_malloc, align 4
@_ZN6Halide7Runtime8Internal11custom_freeE = linkonce local_unnamed_addr global void (i8*, i8*)* @halide_default_free, align 4
@.str = private unnamed_addr constant [45 x i8] c"custom allocators not supported on Hexagon.\0A\00", align 1
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 65535, void ()* @_ZN6Halide7Runtime8Internal24halide_allocator_cleanupEv, i8* null }]
@_ZN6Halide7Runtime8Internal14custom_do_taskE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* @halide_default_do_task, align 4
@_ZN6Halide7Runtime8Internal19custom_do_loop_taskE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)* @halide_default_do_loop_task, align 4
@_ZN6Halide7Runtime8Internal17custom_do_par_forE = linkonce local_unnamed_addr global i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* @halide_default_do_par_for, align 4
@_ZN6Halide7Runtime8Internal24custom_do_parallel_tasksE = linkonce local_unnamed_addr global i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)* @halide_default_do_parallel_tasks, align 4
@.str.1 = private unnamed_addr constant [67 x i8] c"halide_default_do_parallel_tasks not implemented on this platform.\00", align 1
@_ZN6Halide7Runtime8Internal21custom_semaphore_initE = linkonce local_unnamed_addr global i32 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_init, align 4
@.str.1.2 = private unnamed_addr constant [64 x i8] c"halide_default_semaphore_init not implemented on this platform.\00", align 1
@_ZN6Halide7Runtime8Internal28custom_semaphore_try_acquireE = linkonce local_unnamed_addr global i1 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_try_acquire, align 4
@.str.3 = private unnamed_addr constant [71 x i8] c"halide_default_semaphore_try_acquire not implemented on this platform.\00", align 1
@_ZN6Halide7Runtime8Internal24custom_semaphore_releaseE = linkonce local_unnamed_addr global i32 (%struct.halide_semaphore_t*, i32)* @halide_default_semaphore_release, align 4
@.str.2 = private unnamed_addr constant [67 x i8] c"halide_default_semaphore_release not implemented on this platform.\00", align 1
@_ZN6Halide7Runtime8Internal23halide_fake_mutex_arrayE = linkonce global %struct.halide_mutex_array zeroinitializer, align 4
@.str.4 = private unnamed_addr constant [54 x i8] c"halide_spawn_thread not implemented on this platform.\00", align 1
@.str.5 = private unnamed_addr constant [53 x i8] c"halide_join_thread not implemented on this platform.\00", align 1
@.str.6 = private unnamed_addr constant [69 x i8] c"halide_set_num_threads: only supports a value of 1 on this platform.\00", align 1
@_ZN6Halide7Runtime8Internal17halide_gpu_deviceE = linkonce local_unnamed_addr global i32 0, align 4
@_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE = linkonce global i8 0, align 1
@_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE = linkonce local_unnamed_addr global i8 0, align 1
@.str.7 = private unnamed_addr constant [14 x i8] c"HL_GPU_DEVICE\00", align 1
@.str.8 = private unnamed_addr constant [10 x i8] c"<nullptr>\00", align 1
@.str.1.9 = private unnamed_addr constant [5 x i8] c"-nan\00", align 1
@.str.2.10 = private unnamed_addr constant [4 x i8] c"nan\00", align 1
@.str.3.11 = private unnamed_addr constant [5 x i8] c"-inf\00", align 1
@.str.4.12 = private unnamed_addr constant [4 x i8] c"inf\00", align 1
@.str.5.13 = private unnamed_addr constant [14 x i8] c"-0.000000e+00\00", align 1
@.str.6.14 = private unnamed_addr constant [13 x i8] c"0.000000e+00\00", align 1
@.str.7.15 = private unnamed_addr constant [10 x i8] c"-0.000000\00", align 1
@.str.8.16 = private unnamed_addr constant [9 x i8] c"0.000000\00", align 1
@.str.9 = private unnamed_addr constant [2 x i8] c"-\00", align 1
@.str.11 = private unnamed_addr constant [3 x i8] c"e+\00", align 1
@.str.12 = private unnamed_addr constant [3 x i8] c"e-\00", align 1
@.str.13 = private unnamed_addr constant [17 x i8] c"0123456789abcdef\00", align 1
@.str.18 = private unnamed_addr constant [14 x i8] c"bad_type_code\00", align 1
@.str.17 = private unnamed_addr constant [7 x i8] c"handle\00", align 1
@.str.16 = private unnamed_addr constant [6 x i8] c"float\00", align 1
@.str.15 = private unnamed_addr constant [5 x i8] c"uint\00", align 1
@.str.14 = private unnamed_addr constant [4 x i8] c"int\00", align 1
@.str.19 = private unnamed_addr constant [2 x i8] c"x\00", align 1
@.str.20 = private unnamed_addr constant [8 x i8] c"nullptr\00", align 1
@.str.21 = private unnamed_addr constant [8 x i8] c"buffer(\00", align 1
@.str.23 = private unnamed_addr constant [4 x i8] c", {\00", align 1
@.str.24 = private unnamed_addr constant [2 x i8] c"}\00", align 1
@_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE = linkonce local_unnamed_addr global i8 1, align 1
@_ZN6Halide7Runtime8Internal21allocation_pools_lockE = linkonce global %struct.halide_mutex zeroinitializer, align 4
@_ZN6Halide7Runtime8Internal23device_allocation_poolsE = linkonce local_unnamed_addr global %struct.halide_device_allocation_pool* null, align 4
@_ZN6Halide7Runtime8Internal17device_copy_mutexE = linkonce global %struct.halide_mutex zeroinitializer, align 4
@.str.6.17 = private unnamed_addr constant [20 x i8] c"halide_copy_to_host\00", align 1
@.str.7.18 = private unnamed_addr constant [22 x i8] c"halide_copy_to_device\00", align 1
@.str.9.19 = private unnamed_addr constant [61 x i8] c"halide_copy_to_device does not support switching interfaces\0A\00", align 1
@.str.17.20 = private unnamed_addr constant [21 x i8] c"halide_device_malloc\00", align 1
@.str.20.21 = private unnamed_addr constant [59 x i8] c"halide_device_malloc doesn't support switching interfaces\0A\00", align 1
@.str.16.22 = private unnamed_addr constant [19 x i8] c"halide_device_sync\00", align 1
@.str.21.23 = private unnamed_addr constant [19 x i8] c"halide_device_free\00", align 1
@.str.22.24 = private unnamed_addr constant [157 x i8] c"/home/arnoor2/Racket/TensorSynth/Rosette-experiments/frontends/halide/src/runtime/device_interface.cpp:252 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.23.25 = private unnamed_addr constant [30 x i8] c"halide_device_and_host_malloc\00", align 1
@.str.25.26 = private unnamed_addr constant [68 x i8] c"halide_device_and_host_malloc doesn't support switching interfaces\0A\00", align 1
@.str.26 = private unnamed_addr constant [42 x i8] c"allocating host and device memory failed\0A\00", align 1
@.str.27 = private unnamed_addr constant [28 x i8] c"halide_device_and_host_free\00", align 1
@.str.28 = private unnamed_addr constant [157 x i8] c"/home/arnoor2/Racket/TensorSynth/Rosette-experiments/frontends/halide/src/runtime/device_interface.cpp:317 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.29 = private unnamed_addr constant [38 x i8] c"halide_default_device_and_host_malloc\00", align 1
@.str.30 = private unnamed_addr constant [36 x i8] c"halide_default_device_and_host_free\00", align 1
@.str.31 = private unnamed_addr constant [26 x i8] c"halide_device_wrap_native\00", align 1
@.str.32 = private unnamed_addr constant [64 x i8] c"halide_device_wrap_native doesn't support switching interfaces\0A\00", align 1
@.str.33 = private unnamed_addr constant [28 x i8] c"halide_device_detach_native\00", align 1
@.str.34 = private unnamed_addr constant [157 x i8] c"/home/arnoor2/Racket/TensorSynth/Rosette-experiments/frontends/halide/src/runtime/device_interface.cpp:403 halide_abort_if_false() failed: buf->device == 0\0A\00", align 1
@.str.35 = private unnamed_addr constant [36 x i8] c"halide_default_device_detach_native\00", align 1
@.str.41 = private unnamed_addr constant [64 x i8] c"halide_buffer_copy does not support switching device interfaces\00", align 1
@.str.58 = private unnamed_addr constant [44 x i8] c"device_interface does not support cropping\0A\00", align 1
@.str.59 = private unnamed_addr constant [43 x i8] c"device_interface does not support slicing\0A\00", align 1
@.str.60 = private unnamed_addr constant [52 x i8] c"destination buffer already has a device allocation\0A\00", align 1
@.str.61 = private unnamed_addr constant [48 x i8] c"src and dst must have identical dimensionality\0A\00", align 1
@.str.64 = private unnamed_addr constant [52 x i8] c"dst must have exactly one fewer dimension than src\0A\00", align 1
@.str.36 = private unnamed_addr constant [41 x i8] c"Bounds inference call to external stage \00", align 1
@.str.1.37 = private unnamed_addr constant [27 x i8] c" returned non-zero value: \00", align 1
@.str.2.38 = private unnamed_addr constant [24 x i8] c"Call to external stage \00", align 1
@.str.3.39 = private unnamed_addr constant [18 x i8] c"Bounds given for \00", align 1
@.str.4.40 = private unnamed_addr constant [5 x i8] c" in \00", align 1
@.str.5.41 = private unnamed_addr constant [8 x i8] c" (from \00", align 1
@.str.6.42 = private unnamed_addr constant [5 x i8] c" to \00", align 1
@.str.7.43 = private unnamed_addr constant [38 x i8] c") do not cover required region (from \00", align 1
@.str.8.44 = private unnamed_addr constant [2 x i8] c")\00", align 1
@.str.9.45 = private unnamed_addr constant [11 x i8] c" has type \00", align 1
@.str.10.46 = private unnamed_addr constant [38 x i8] c" but type of the buffer passed in is \00", align 1
@.str.11.47 = private unnamed_addr constant [31 x i8] c" requires a buffer of exactly \00", align 1
@.str.12.48 = private unnamed_addr constant [43 x i8] c" dimensions, but the buffer passed in has \00", align 1
@.str.13.49 = private unnamed_addr constant [12 x i8] c" dimensions\00", align 1
@.str.14.50 = private unnamed_addr constant [17 x i8] c" is accessed at \00", align 1
@.str.15.51 = private unnamed_addr constant [28 x i8] c", which is before the min (\00", align 1
@.str.16.52 = private unnamed_addr constant [16 x i8] c") in dimension \00", align 1
@.str.17.53 = private unnamed_addr constant [28 x i8] c", which is beyond the max (\00", align 1
@.str.18.54 = private unnamed_addr constant [29 x i8] c"Total allocation for buffer \00", align 1
@.str.19.55 = private unnamed_addr constant [5 x i8] c" is \00", align 1
@.str.20.56 = private unnamed_addr constant [37 x i8] c", which exceeds the maximum size of \00", align 1
@.str.21.57 = private unnamed_addr constant [24 x i8] c"The extents for buffer \00", align 1
@.str.22.58 = private unnamed_addr constant [12 x i8] c" dimension \00", align 1
@.str.23.59 = private unnamed_addr constant [15 x i8] c" is negative (\00", align 1
@.str.24.60 = private unnamed_addr constant [31 x i8] c"Product of extents for buffer \00", align 1
@.str.25.61 = private unnamed_addr constant [29 x i8] c"Applying the constraints on \00", align 1
@.str.26.62 = private unnamed_addr constant [54 x i8] c" to the required region made it smaller in dimension \00", align 1
@.str.27.63 = private unnamed_addr constant [3 x i8] c". \00", align 1
@.str.28.64 = private unnamed_addr constant [16 x i8] c"Required size: \00", align 1
@.str.29.65 = private unnamed_addr constant [19 x i8] c"Constrained size: \00", align 1
@.str.30.66 = private unnamed_addr constant [2 x i8] c".\00", align 1
@.str.31.67 = private unnamed_addr constant [22 x i8] c"Constraint violated: \00", align 1
@.str.32.68 = private unnamed_addr constant [3 x i8] c" (\00", align 1
@.str.33.69 = private unnamed_addr constant [6 x i8] c") == \00", align 1
@.str.34.70 = private unnamed_addr constant [11 x i8] c"Parameter \00", align 1
@.str.35.71 = private unnamed_addr constant [23 x i8] c" but must be at least \00", align 1
@.str.36.72 = private unnamed_addr constant [22 x i8] c" but must be at most \00", align 1
@.str.37 = private unnamed_addr constant [47 x i8] c"Out of memory (halide_malloc returned nullptr)\00", align 1
@.str.38 = private unnamed_addr constant [17 x i8] c"Buffer argument \00", align 1
@.str.39 = private unnamed_addr constant [12 x i8] c" is nullptr\00", align 1
@.str.40 = private unnamed_addr constant [25 x i8] c"Failed to dump function \00", align 1
@.str.41.73 = private unnamed_addr constant [10 x i8] c" to file \00", align 1
@.str.42 = private unnamed_addr constant [13 x i8] c" with error \00", align 1
@.str.43 = private unnamed_addr constant [21 x i8] c"The host pointer of \00", align 1
@.str.44 = private unnamed_addr constant [22 x i8] c" is not aligned to a \00", align 1
@.str.45 = private unnamed_addr constant [17 x i8] c" bytes boundary.\00", align 1
@.str.46 = private unnamed_addr constant [12 x i8] c"The buffer \00", align 1
@.str.47 = private unnamed_addr constant [53 x i8] c" is dirty on device, but this pipeline was compiled \00", align 1
@.str.48 = private unnamed_addr constant [43 x i8] c"with no support for device to host copies.\00", align 1
@.str.49 = private unnamed_addr constant [55 x i8] c" is null, but the pipeline will access it on the host.\00", align 1
@.str.50 = private unnamed_addr constant [30 x i8] c"The folded storage dimension \00", align 1
@.str.51 = private unnamed_addr constant [5 x i8] c" of \00", align 1
@.str.52 = private unnamed_addr constant [36 x i8] c" was accessed out of order by loop \00", align 1
@.str.53 = private unnamed_addr constant [23 x i8] c"Cannot fold dimension \00", align 1
@.str.54 = private unnamed_addr constant [36 x i8] c" because an extern stage accesses [\00", align 1
@.str.55 = private unnamed_addr constant [3 x i8] c", \00", align 1
@.str.56 = private unnamed_addr constant [3 x i8] c"],\00", align 1
@.str.57 = private unnamed_addr constant [47 x i8] c" which is outside the range currently valid: [\00", align 1
@.str.58.74 = private unnamed_addr constant [3 x i8] c"].\00", align 1
@.str.59.75 = private unnamed_addr constant [47 x i8] c" which wraps around the boundary of the fold, \00", align 1
@.str.60.76 = private unnamed_addr constant [30 x i8] c"which occurs at multiples of \00", align 1
@.str.61.77 = private unnamed_addr constant [18 x i8] c"The fold factor (\00", align 1
@.str.62 = private unnamed_addr constant [16 x i8] c") of dimension \00", align 1
@.str.63 = private unnamed_addr constant [61 x i8] c" is too small to store the required region accessed by loop \00", align 1
@.str.64.78 = private unnamed_addr constant [3 x i8] c").\00", align 1
@.str.65 = private unnamed_addr constant [22 x i8] c"Requirement Failed: (\00", align 1
@.str.66 = private unnamed_addr constant [3 x i8] c") \00", align 1
@.str.67 = private unnamed_addr constant [59 x i8] c"A schedule specialized with specialize_fail() was chosen: \00", align 1
@.str.68 = private unnamed_addr constant [55 x i8] c"Buffer has a non-zero device but no device interface.\0A\00", align 1
@.str.69 = private unnamed_addr constant [57 x i8] c"Buffer has a non-null device_interface but device is 0.\0A\00", align 1
@.str.70 = private unnamed_addr constant [49 x i8] c"Buffer has both host and device dirty bits set.\0A\00", align 1
@.str.71 = private unnamed_addr constant [26 x i8] c"Buffer pointer passed to \00", align 1
@.str.72 = private unnamed_addr constant [11 x i8] c" is null.\0A\00", align 1
@.str.73 = private unnamed_addr constant [32 x i8] c"The explicit allocation bound (\00", align 1
@.str.74 = private unnamed_addr constant [45 x i8] c" is too small to store the required region (\00", align 1
@.str.75 = private unnamed_addr constant [77 x i8] c"Buffer could not be cropped (runtime error or unimplemented device option).\0A\00", align 1
@.str.4.91 = private unnamed_addr constant [22 x i8] c"qurt_hvx_lock failed\0A\00", align 1
@.str.7.92 = private unnamed_addr constant [35 x i8] c"Printer buffer allocation failed.\0A\00", align 1
@.str.6.93 = private unnamed_addr constant [24 x i8] c"qurt_hvx_unlock failed\0A\00", align 1
@_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE = linkonce local_unnamed_addr global i32 (i32, i64*)* @halide_default_can_use_target_features, align 4
@_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE = linkonce global %struct.halide_mutex zeroinitializer, align 4
@_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE = linkonce local_unnamed_addr global i8 0, align 1
@_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE = linkonce global [4 x i64] zeroinitializer, align 8
@.str.94 = private unnamed_addr constant [81 x i8] c"Internal error: wrong structure size passed to halide_can_use_target_features()\0A\00", align 1
@0 = private constant i64 0
@1 = private constant [8 x i64*] [i64* @0, i64* null, i64* null, i64* null, i64* null, i64* null, i64* null, i64* null]
@str = private constant [6 x i8] c"input\00", align 32
@str.102 = private constant [11 x i8] c"input_zero\00", align 32
@2 = private constant i64 0
@3 = private constant i64 4
@4 = private constant i64 0
@5 = private constant i64 32
@6 = private constant i64 0
@7 = private constant i64 0
@8 = private constant i64 0
@9 = private constant i64 0
@10 = private constant [12 x i64*] [i64* @2, i64* @3, i64* @4, i64* @5, i64* @6, i64* null, i64* @7, i64* null, i64* @8, i64* null, i64* @9, i64* null]
@str.103 = private constant [7 x i8] c"filter\00", align 32
@str.104 = private constant [12 x i8] c"filter_zero\00", align 32
@11 = private constant i64 0
@12 = private constant [2 x i64*] [i64* @11, i64* null]
@str.105 = private constant [5 x i8] c"bias\00", align 32
@str.106 = private constant [9 x i8] c"stride_x\00", align 32
@str.107 = private constant [9 x i8] c"stride_y\00", align 32
@str.108 = private constant [11 x i8] c"dilation_x\00", align 32
@str.109 = private constant [11 x i8] c"dilation_y\00", align 32
@str.110 = private constant [18 x i8] c"output_multiplier\00", align 32
@str.111 = private constant [13 x i8] c"output_shift\00", align 32
@str.112 = private constant [12 x i8] c"output_zero\00", align 32
@str.113 = private constant [11 x i8] c"output_min\00", align 32
@str.114 = private constant [11 x i8] c"output_max\00", align 32
@13 = private constant i64 0
@14 = private constant [8 x i64*] [i64* @13, i64* null, i64* null, i64* null, i64* null, i64* null, i64* null, i64* null]
@str.115 = private constant [7 x i8] c"output\00", align 32
@15 = private constant [15 x %struct.halide_filter_argument_t] [%struct.halide_filter_argument_t { i8* getelementptr inbounds ([6 x i8], [6 x i8]* @str, i32 0, i32 0), i32 1, i32 4, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([8 x i64*], [8 x i64*]* @1, i32 0, i32 0) }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.102, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str.103, i32 0, i32 0), i32 1, i32 6, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([12 x i64*], [12 x i64*]* @10, i32 0, i32 0) }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([12 x i8], [12 x i8]* @str.104, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([5 x i8], [5 x i8]* @str.105, i32 0, i32 0), i32 1, i32 1, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([2 x i64*], [2 x i64*]* @12, i32 0, i32 0) }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str.106, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str.107, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.108, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.109, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([18 x i8], [18 x i8]* @str.110, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([13 x i8], [13 x i8]* @str.111, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([12 x i8], [12 x i8]* @str.112, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.113, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([11 x i8], [11 x i8]* @str.114, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([7 x i8], [7 x i8]* @str.115, i32 0, i32 0), i32 2, i32 4, %struct.halide_type_t { i8 1, i8 8, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([8 x i64*], [8 x i64*]* @14, i32 0, i32 0) }]
@str.116 = private constant [63 x i8] c"hexagon-32-noos-hvx-hvx_128-hvx_v66-no_asserts-no_bounds_query\00", align 128
@str.117 = private constant [15 x i8] c"conv_nn_hvx128\00", align 32
@conv_nn_hvx128_metadata_storage = private constant %struct.halide_filter_metadata_t { i32 1, i32 15, %struct.halide_filter_argument_t* getelementptr inbounds ([15 x %struct.halide_filter_argument_t], [15 x %struct.halide_filter_argument_t]* @15, i32 0, i32 0), i8* getelementptr inbounds ([63 x i8], [63 x i8]* @str.116, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @str.117, i32 0, i32 0) }
@switch.table.halide_type_to_string = private unnamed_addr constant [4 x i8*] [i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.14, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.15, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.16, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.17, i32 0, i32 0)], align 4

; Function Attrs: nounwind mustprogress
define linkonce i8* @_ZN6Halide7Runtime8Internal14aligned_mallocEjj(i32 %alignment, i32 %size) local_unnamed_addr #0 {
entry:
  %add = add i32 %alignment, -1
  %sub = add i32 %add, %size
  %neg = sub i32 0, %alignment
  %and = and i32 %sub, %neg
  %add2 = add i32 %and, %alignment
  %call = tail call i8* @malloc(i32 %add2) #14
  %cmp = icmp eq i8* %call, null
  br i1 %cmp, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %0 = ptrtoint i8* %call to i32
  %add3 = add i32 %alignment, 3
  %sub5 = add i32 %add3, %0
  %and8 = and i32 %sub5, %neg
  %1 = inttoptr i32 %and8 to i8*
  %2 = inttoptr i32 %and8 to i8**
  %arrayidx = getelementptr inbounds i8*, i8** %2, i32 -1
  store i8* %call, i8** %arrayidx, align 4, !tbaa !10
  br label %cleanup

cleanup:                                          ; preds = %if.end, %entry
  %retval.0 = phi i8* [ %1, %if.end ], [ null, %entry ]
  ret i8* %retval.0
}

declare i8* @malloc(i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %ptr) local_unnamed_addr #0 {
entry:
  %tobool.not = icmp eq i8* %ptr, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %arrayidx = getelementptr inbounds i8, i8* %ptr, i32 -4
  %0 = bitcast i8* %arrayidx to i8**
  %1 = load i8*, i8** %0, align 4, !tbaa !10
  tail call void @free(i8* %1) #14
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret void
}

declare void @free(i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal24halide_allocator_cleanupEv() #0 {
entry:
  %0 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 0), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %0) #15
  %1 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 1), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %1) #15
  %2 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 2), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %2) #15
  %3 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 3), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %3) #15
  %4 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 4), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %4) #15
  %5 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 5), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %5) #15
  %6 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 6), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %6) #15
  %7 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 7), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %7) #15
  %8 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 8), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %8) #15
  %9 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 9), align 4, !tbaa !10
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %9) #15
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_default_malloc(i8* %user_context, i32 %x) #0 {
entry:
  %cmp = icmp ult i32 %x, 65537
  br i1 %cmp, label %for.body.preheader, label %if.end9

for.body.preheader:                               ; preds = %entry
  %0 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 0), i32 0, i32 1 seq_cst seq_cst
  %cmp2 = extractvalue { i32, i1 } %0, 1
  br i1 %cmp2, label %for.body.preheader.if.then3_crit_edge, label %for.inc

for.body.preheader.if.then3_crit_edge:            ; preds = %for.body.preheader
  %arrayidx.0 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 0
  br label %if.then3

if.then3:                                         ; preds = %for.inc.8.if.then3_crit_edge, %for.inc.7.if.then3_crit_edge, %for.inc.6.if.then3_crit_edge, %for.inc.5.if.then3_crit_edge, %for.inc.4.if.then3_crit_edge, %for.inc.3.if.then3_crit_edge, %for.inc.2.if.then3_crit_edge, %for.inc.1.if.then3_crit_edge, %for.inc.if.then3_crit_edge, %for.body.preheader.if.then3_crit_edge
  %arrayidx.phi = phi i8** [ %arrayidx.0, %for.body.preheader.if.then3_crit_edge ], [ %arrayidx.1, %for.inc.if.then3_crit_edge ], [ %arrayidx.2, %for.inc.1.if.then3_crit_edge ], [ %arrayidx.3, %for.inc.2.if.then3_crit_edge ], [ %arrayidx.4, %for.inc.3.if.then3_crit_edge ], [ %arrayidx.5, %for.inc.4.if.then3_crit_edge ], [ %arrayidx.6, %for.inc.5.if.then3_crit_edge ], [ %arrayidx.7, %for.inc.6.if.then3_crit_edge ], [ %arrayidx.8, %for.inc.7.if.then3_crit_edge ], [ %arrayidx.9, %for.inc.8.if.then3_crit_edge ]
  %1 = load i8*, i8** %arrayidx.phi, align 4, !tbaa !10
  %cmp4 = icmp eq i8* %1, null
  br i1 %cmp4, label %if.then5, label %cleanup11

if.then5:                                         ; preds = %if.then3
  %call = tail call i8* @_ZN6Halide7Runtime8Internal14aligned_mallocEjj(i32 128, i32 65536) #15
  store i8* %call, i8** %arrayidx.phi, align 4, !tbaa !10
  br label %cleanup11

for.inc:                                          ; preds = %for.body.preheader
  %2 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 1), i32 0, i32 1 seq_cst seq_cst
  %cmp2.1 = extractvalue { i32, i1 } %2, 1
  br i1 %cmp2.1, label %for.inc.if.then3_crit_edge, label %for.inc.1

for.inc.if.then3_crit_edge:                       ; preds = %for.inc
  %arrayidx.1 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 1
  br label %if.then3

if.end9:                                          ; preds = %for.inc.8, %entry
  %call10 = tail call i8* @_ZN6Halide7Runtime8Internal14aligned_mallocEjj(i32 128, i32 %x) #15
  br label %cleanup11

cleanup11:                                        ; preds = %if.end9, %if.then5, %if.then3
  %retval.1 = phi i8* [ %call10, %if.end9 ], [ %1, %if.then3 ], [ %call, %if.then5 ]
  ret i8* %retval.1

for.inc.1:                                        ; preds = %for.inc
  %3 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 2), i32 0, i32 1 seq_cst seq_cst
  %cmp2.2 = extractvalue { i32, i1 } %3, 1
  br i1 %cmp2.2, label %for.inc.1.if.then3_crit_edge, label %for.inc.2

for.inc.1.if.then3_crit_edge:                     ; preds = %for.inc.1
  %arrayidx.2 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 2
  br label %if.then3

for.inc.2:                                        ; preds = %for.inc.1
  %4 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 3), i32 0, i32 1 seq_cst seq_cst
  %cmp2.3 = extractvalue { i32, i1 } %4, 1
  br i1 %cmp2.3, label %for.inc.2.if.then3_crit_edge, label %for.inc.3

for.inc.2.if.then3_crit_edge:                     ; preds = %for.inc.2
  %arrayidx.3 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 3
  br label %if.then3

for.inc.3:                                        ; preds = %for.inc.2
  %5 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 4), i32 0, i32 1 seq_cst seq_cst
  %cmp2.4 = extractvalue { i32, i1 } %5, 1
  br i1 %cmp2.4, label %for.inc.3.if.then3_crit_edge, label %for.inc.4

for.inc.3.if.then3_crit_edge:                     ; preds = %for.inc.3
  %arrayidx.4 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 4
  br label %if.then3

for.inc.4:                                        ; preds = %for.inc.3
  %6 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 5), i32 0, i32 1 seq_cst seq_cst
  %cmp2.5 = extractvalue { i32, i1 } %6, 1
  br i1 %cmp2.5, label %for.inc.4.if.then3_crit_edge, label %for.inc.5

for.inc.4.if.then3_crit_edge:                     ; preds = %for.inc.4
  %arrayidx.5 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 5
  br label %if.then3

for.inc.5:                                        ; preds = %for.inc.4
  %7 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 6), i32 0, i32 1 seq_cst seq_cst
  %cmp2.6 = extractvalue { i32, i1 } %7, 1
  br i1 %cmp2.6, label %for.inc.5.if.then3_crit_edge, label %for.inc.6

for.inc.5.if.then3_crit_edge:                     ; preds = %for.inc.5
  %arrayidx.6 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 6
  br label %if.then3

for.inc.6:                                        ; preds = %for.inc.5
  %8 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 7), i32 0, i32 1 seq_cst seq_cst
  %cmp2.7 = extractvalue { i32, i1 } %8, 1
  br i1 %cmp2.7, label %for.inc.6.if.then3_crit_edge, label %for.inc.7

for.inc.6.if.then3_crit_edge:                     ; preds = %for.inc.6
  %arrayidx.7 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 7
  br label %if.then3

for.inc.7:                                        ; preds = %for.inc.6
  %9 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 8), i32 0, i32 1 seq_cst seq_cst
  %cmp2.8 = extractvalue { i32, i1 } %9, 1
  br i1 %cmp2.8, label %for.inc.7.if.then3_crit_edge, label %for.inc.8

for.inc.7.if.then3_crit_edge:                     ; preds = %for.inc.7
  %arrayidx.8 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 8
  br label %if.then3

for.inc.8:                                        ; preds = %for.inc.7
  %10 = cmpxchg i32* getelementptr inbounds ([10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 9), i32 0, i32 1 seq_cst seq_cst
  %cmp2.9 = extractvalue { i32, i1 } %10, 1
  br i1 %cmp2.9, label %for.inc.8.if.then3_crit_edge, label %if.end9

for.inc.8.if.then3_crit_edge:                     ; preds = %for.inc.8
  %arrayidx.9 = getelementptr inbounds [10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 9
  br label %if.then3
}

; Function Attrs: nounwind mustprogress
define weak void @halide_default_free(i8* %user_context, i8* %ptr) #0 {
entry:
  %0 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 0), align 4, !tbaa !10
  %cmp1 = icmp eq i8* %0, %ptr
  br i1 %cmp1, label %entry.if.then_crit_edge, label %for.inc

entry.if.then_crit_edge:                          ; preds = %entry
  %arrayidx2.0 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 0
  br label %if.then

if.then:                                          ; preds = %for.inc.8.if.then_crit_edge, %for.inc.7.if.then_crit_edge, %for.inc.6.if.then_crit_edge, %for.inc.5.if.then_crit_edge, %for.inc.4.if.then_crit_edge, %for.inc.3.if.then_crit_edge, %for.inc.2.if.then_crit_edge, %for.inc.1.if.then_crit_edge, %for.inc.if.then_crit_edge, %entry.if.then_crit_edge
  %arrayidx2.phi = phi i32* [ %arrayidx2.0, %entry.if.then_crit_edge ], [ %arrayidx2.1, %for.inc.if.then_crit_edge ], [ %arrayidx2.2, %for.inc.1.if.then_crit_edge ], [ %arrayidx2.3, %for.inc.2.if.then_crit_edge ], [ %arrayidx2.4, %for.inc.3.if.then_crit_edge ], [ %arrayidx2.5, %for.inc.4.if.then_crit_edge ], [ %arrayidx2.6, %for.inc.5.if.then_crit_edge ], [ %arrayidx2.7, %for.inc.6.if.then_crit_edge ], [ %arrayidx2.8, %for.inc.7.if.then_crit_edge ], [ %arrayidx2.9, %for.inc.8.if.then_crit_edge ]
  store i32 0, i32* %arrayidx2.phi, align 4, !tbaa !14
  br label %return

for.inc:                                          ; preds = %entry
  %1 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 1), align 4, !tbaa !10
  %cmp1.1 = icmp eq i8* %1, %ptr
  br i1 %cmp1.1, label %for.inc.if.then_crit_edge, label %for.inc.1

for.inc.if.then_crit_edge:                        ; preds = %for.inc
  %arrayidx2.1 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 1
  br label %if.then

return:                                           ; preds = %for.inc.9, %if.then
  ret void

for.inc.1:                                        ; preds = %for.inc
  %2 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 2), align 4, !tbaa !10
  %cmp1.2 = icmp eq i8* %2, %ptr
  br i1 %cmp1.2, label %for.inc.1.if.then_crit_edge, label %for.inc.2

for.inc.1.if.then_crit_edge:                      ; preds = %for.inc.1
  %arrayidx2.2 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 2
  br label %if.then

for.inc.2:                                        ; preds = %for.inc.1
  %3 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 3), align 4, !tbaa !10
  %cmp1.3 = icmp eq i8* %3, %ptr
  br i1 %cmp1.3, label %for.inc.2.if.then_crit_edge, label %for.inc.3

for.inc.2.if.then_crit_edge:                      ; preds = %for.inc.2
  %arrayidx2.3 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 3
  br label %if.then

for.inc.3:                                        ; preds = %for.inc.2
  %4 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 4), align 4, !tbaa !10
  %cmp1.4 = icmp eq i8* %4, %ptr
  br i1 %cmp1.4, label %for.inc.3.if.then_crit_edge, label %for.inc.4

for.inc.3.if.then_crit_edge:                      ; preds = %for.inc.3
  %arrayidx2.4 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 4
  br label %if.then

for.inc.4:                                        ; preds = %for.inc.3
  %5 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 5), align 4, !tbaa !10
  %cmp1.5 = icmp eq i8* %5, %ptr
  br i1 %cmp1.5, label %for.inc.4.if.then_crit_edge, label %for.inc.5

for.inc.4.if.then_crit_edge:                      ; preds = %for.inc.4
  %arrayidx2.5 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 5
  br label %if.then

for.inc.5:                                        ; preds = %for.inc.4
  %6 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 6), align 4, !tbaa !10
  %cmp1.6 = icmp eq i8* %6, %ptr
  br i1 %cmp1.6, label %for.inc.5.if.then_crit_edge, label %for.inc.6

for.inc.5.if.then_crit_edge:                      ; preds = %for.inc.5
  %arrayidx2.6 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 6
  br label %if.then

for.inc.6:                                        ; preds = %for.inc.5
  %7 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 7), align 4, !tbaa !10
  %cmp1.7 = icmp eq i8* %7, %ptr
  br i1 %cmp1.7, label %for.inc.6.if.then_crit_edge, label %for.inc.7

for.inc.6.if.then_crit_edge:                      ; preds = %for.inc.6
  %arrayidx2.7 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 7
  br label %if.then

for.inc.7:                                        ; preds = %for.inc.6
  %8 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 8), align 4, !tbaa !10
  %cmp1.8 = icmp eq i8* %8, %ptr
  br i1 %cmp1.8, label %for.inc.7.if.then_crit_edge, label %for.inc.8

for.inc.7.if.then_crit_edge:                      ; preds = %for.inc.7
  %arrayidx2.8 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 8
  br label %if.then

for.inc.8:                                        ; preds = %for.inc.7
  %9 = load i8*, i8** getelementptr inbounds ([10 x i8*], [10 x i8*]* @_ZN6Halide7Runtime8Internal7mem_bufE, i32 0, i32 9), align 4, !tbaa !10
  %cmp1.9 = icmp eq i8* %9, %ptr
  br i1 %cmp1.9, label %for.inc.8.if.then_crit_edge, label %for.inc.9

for.inc.8.if.then_crit_edge:                      ; preds = %for.inc.8
  %arrayidx2.9 = getelementptr inbounds [10 x i32], [10 x i32]* @_ZN6Halide7Runtime8Internal11buf_is_usedE, i32 0, i32 9
  br label %if.then

for.inc.9:                                        ; preds = %for.inc.8
  tail call void @_ZN6Halide7Runtime8Internal12aligned_freeEPv(i8* %ptr) #15
  br label %return
}

; Function Attrs: nounwind mustprogress
define weak i8* (i8*, i32)* @halide_set_custom_malloc(i8* (i8*, i32)* %user_malloc) local_unnamed_addr #0 {
entry:
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str, i32 0, i32 0)) #14
  %0 = load i8* (i8*, i32)*, i8* (i8*, i32)** @_ZN6Halide7Runtime8Internal13custom_mallocE, align 4, !tbaa !10
  store i8* (i8*, i32)* %user_malloc, i8* (i8*, i32)** @_ZN6Halide7Runtime8Internal13custom_mallocE, align 4, !tbaa !10
  ret i8* (i8*, i32)* %0
}

declare void @halide_print(i8*, i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void (i8*, i8*)* @halide_set_custom_free(void (i8*, i8*)* %user_free) local_unnamed_addr #0 {
entry:
  tail call void @halide_print(i8* null, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str, i32 0, i32 0)) #14
  %0 = load void (i8*, i8*)*, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal11custom_freeE, align 4, !tbaa !10
  store void (i8*, i8*)* %user_free, void (i8*, i8*)** @_ZN6Halide7Runtime8Internal11custom_freeE, align 4, !tbaa !10
  ret void (i8*, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak noalias i8* @halide_malloc(i8* %user_context, i32 %x) local_unnamed_addr #0 {
entry:
  %call = tail call i8* @halide_default_malloc(i8* %user_context, i32 %x) #15
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak void @halide_free(i8* %user_context, i8* %ptr) local_unnamed_addr #0 {
entry:
  tail call void @halide_default_free(i8* %user_context, i8* %ptr) #15
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_task(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) #0 {
entry:
  %call = tail call i32 %f(i8* %user_context, i32 %idx, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_loop_task(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %extent, i8* %closure, i8* %task_parent) #0 {
entry:
  %call = tail call i32 %f(i8* %user_context, i32 %min, i32 %extent, i8* %closure, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_par_for(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) #0 {
entry:
  %add = add nsw i32 %size, %min
  %cmp11 = icmp sgt i32 %size, 0
  br i1 %cmp11, label %for.body, label %cleanup1

for.cond:                                         ; preds = %for.body
  %cmp = icmp slt i32 %inc, %add
  br i1 %cmp, label %for.body, label %cleanup1, !llvm.loop !16

for.body:                                         ; preds = %entry, %for.cond
  %x.012 = phi i32 [ %inc, %for.cond ], [ %min, %entry ]
  %call = tail call i32 @halide_do_task(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %x.012, i8* %closure) #15
  %tobool.not = icmp eq i32 %call, 0
  %inc = add nsw i32 %x.012, 1
  br i1 %tobool.not, label %for.cond, label %cleanup1

cleanup1:                                         ; preds = %for.body, %for.cond, %entry
  %spec.select = phi i32 [ 0, %entry ], [ %call, %for.body ], [ 0, %for.cond ]
  ret i32 %spec.select
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_task(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 4, !tbaa !10
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %idx, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_do_parallel_tasks(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([67 x i8], [67 x i8]* @.str.1, i32 0, i32 0)) #14
  ret i32 -1
}

declare void @halide_error(i8*, i8*) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_semaphore_init(%struct.halide_semaphore_t* %s, i32 %n) #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.1.2, i32 0, i32 0)) #14
  ret i32 0
}

; Function Attrs: nounwind mustprogress
define weak zeroext i1 @halide_default_semaphore_try_acquire(%struct.halide_semaphore_t* %s, i32 %n) #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.3, i32 0, i32 0)) #14
  ret i1 false
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_semaphore_release(%struct.halide_semaphore_t* %s, i32 %n) #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([67 x i8], [67 x i8]* @.str.2, i32 0, i32 0)) #14
  ret i32 0
}

; Function Attrs: nounwind mustprogress
define weak %struct.halide_thread* @halide_spawn_thread(void (i8*)* %f, i8* %closure) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([54 x i8], [54 x i8]* @.str.4, i32 0, i32 0)) #14
  ret %struct.halide_thread* null
}

; Function Attrs: nounwind mustprogress
define weak void @halide_join_thread(%struct.halide_thread* %thread_arg) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.5, i32 0, i32 0)) #14
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_mutex_lock(%struct.halide_mutex* %mutex) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_mutex_unlock(%struct.halide_mutex* %mutex) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak %struct.halide_mutex_array* @halide_mutex_array_create(i32 %sz) local_unnamed_addr #2 {
entry:
  ret %struct.halide_mutex_array* @_ZN6Halide7Runtime8Internal23halide_fake_mutex_arrayE
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_mutex_array_destroy(i8* %user_context, i8* %array) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_mutex_array_lock(%struct.halide_mutex_array* %array, i32 %entry1) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_mutex_array_unlock(%struct.halide_mutex_array* %array, i32 %entry1) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_shutdown_thread_pool() local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_set_num_threads(i32 %n) local_unnamed_addr #0 {
entry:
  %cmp.not = icmp eq i32 %n, 1
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_error(i8* null, i8* getelementptr inbounds ([69 x i8], [69 x i8]* @.str.6, i32 0, i32 0)) #14
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret i32 1
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* @halide_set_custom_do_task(i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 4, !tbaa !10
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %f, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)** @_ZN6Halide7Runtime8Internal14custom_do_taskE, align 4, !tbaa !10
  ret i32 (i8*, i32 (i8*, i32, i8*)*, i32, i8*)* %0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* @halide_set_custom_do_par_for(i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %f) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 4, !tbaa !10
  store i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %f, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 4, !tbaa !10
  ret i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_par_for(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)*, i32 (i8*, i32 (i8*, i32, i8*)*, i32, i32, i8*)** @_ZN6Halide7Runtime8Internal17custom_do_par_forE, align 4, !tbaa !10
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i8*)* %f, i32 %min, i32 %size, i8* %closure) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_loop_task(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %size, i8* %closure, i8* %task_parent) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)*, i32 (i8*, i32 (i8*, i32, i32, i8*, i8*)*, i32, i32, i8*, i8*)** @_ZN6Halide7Runtime8Internal19custom_do_loop_taskE, align 4, !tbaa !10
  %call = tail call i32 %0(i8* %user_context, i32 (i8*, i32, i32, i8*, i8*)* %f, i32 %min, i32 %size, i8* %closure, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_do_parallel_tasks(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)*, i32 (i8*, i32, %struct.halide_parallel_task_t*, i8*)** @_ZN6Halide7Runtime8Internal24custom_do_parallel_tasksE, align 4, !tbaa !10
  %call = tail call i32 %0(i8* %user_context, i32 %num_tasks, %struct.halide_parallel_task_t* %tasks, i8* %task_parent) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_semaphore_init(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i32 (%struct.halide_semaphore_t*, i32)*, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal21custom_semaphore_initE, align 4, !tbaa !10
  %call = tail call i32 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_semaphore_release(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i32 (%struct.halide_semaphore_t*, i32)*, i32 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal24custom_semaphore_releaseE, align 4, !tbaa !10
  %call = tail call i32 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak zeroext i1 @halide_semaphore_try_acquire(%struct.halide_semaphore_t* %sema, i32 %count) local_unnamed_addr #0 {
entry:
  %0 = load i1 (%struct.halide_semaphore_t*, i32)*, i1 (%struct.halide_semaphore_t*, i32)** @_ZN6Halide7Runtime8Internal28custom_semaphore_try_acquireE, align 4, !tbaa !10
  %call = tail call zeroext i1 %0(%struct.halide_semaphore_t* %sema, i32 %count) #14
  ret i1 %call
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.memcpy.p0i8.p0i8.i32(i8* noalias nocapture writeonly, i8* noalias nocapture readonly, i32, i1 immarg) #3

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_set_gpu_device(i32 %d) local_unnamed_addr #2 {
entry:
  store i32 %d, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !14
  store i8 1, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !18
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_get_gpu_device(i8* %user_context) local_unnamed_addr #4 {
entry:
  br label %while.cond.i

while.cond.i:                                     ; preds = %while.cond.i, %entry
  %0 = atomicrmw volatile xchg i8* @_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE, i8 1 acquire
  %tobool.not.i = icmp eq i8 %0, 0
  br i1 %tobool.not.i, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit, label %while.cond.i, !llvm.loop !20

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit: ; preds = %while.cond.i
  %1 = load i8, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !18, !range !21
  %tobool.not = icmp eq i8 %1, 0
  br i1 %tobool.not, label %if.then, label %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge

_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge: ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %.pre = load i32, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !14
  br label %if.end4

if.then:                                          ; preds = %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit
  %call = tail call i8* @getenv(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.7, i32 0, i32 0)) #14
  %tobool1.not = icmp eq i8* %call, null
  br i1 %tobool1.not, label %if.end, label %if.then2

if.then2:                                         ; preds = %if.then
  %call3 = tail call i32 @atoi(i8* nonnull %call) #14
  br label %if.end

if.end:                                           ; preds = %if.then2, %if.then
  %storemerge = phi i32 [ %call3, %if.then2 ], [ -1, %if.then ]
  store i32 %storemerge, i32* @_ZN6Halide7Runtime8Internal17halide_gpu_deviceE, align 4, !tbaa !14
  store i8 1, i8* @_ZN6Halide7Runtime8Internal29halide_gpu_device_initializedE, align 1, !tbaa !18
  br label %if.end4

if.end4:                                          ; preds = %if.end, %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge
  %2 = phi i32 [ %.pre, %_ZN6Halide7Runtime8Internal14ScopedSpinLockC2EPVc.exit.if.end4_crit_edge ], [ %storemerge, %if.end ]
  store atomic volatile i8 0, i8* @_ZN6Halide7Runtime8Internal22halide_gpu_device_lockE release, align 1
  ret i32 %2
}

declare i8* @getenv(i8*) local_unnamed_addr #1

declare i32 @atoi(i8*) local_unnamed_addr #1

; Function Attrs: nounwind
define weak i8* @halide_string_to_string(i8* %dst, i8* %end, i8* %arg) local_unnamed_addr #4 {
entry:
  %cmp.not = icmp ult i8* %dst, %end
  br i1 %cmp.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %tobool.not = icmp eq i8* %arg, null
  %spec.select = select i1 %tobool.not, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.8, i32 0, i32 0), i8* %arg
  br label %if.end5

if.then4:                                         ; preds = %if.end8
  store i8 0, i8* %dst.addr.023, align 1, !tbaa !22
  br label %return

if.end5:                                          ; preds = %if.end8, %if.end
  %arg.addr.124 = phi i8* [ %spec.select, %if.end ], [ %incdec.ptr9, %if.end8 ]
  %dst.addr.023 = phi i8* [ %dst, %if.end ], [ %incdec.ptr, %if.end8 ]
  %0 = load i8, i8* %arg.addr.124, align 1, !tbaa !22
  store i8 %0, i8* %dst.addr.023, align 1, !tbaa !22
  %cmp6 = icmp eq i8 %0, 0
  br i1 %cmp6, label %return, label %if.end8

if.end8:                                          ; preds = %if.end5
  %incdec.ptr = getelementptr inbounds i8, i8* %dst.addr.023, i32 1
  %incdec.ptr9 = getelementptr inbounds i8, i8* %arg.addr.124, i32 1
  %cmp3 = icmp eq i8* %incdec.ptr, %end
  br i1 %cmp3, label %if.then4, label %if.end5

return:                                           ; preds = %if.end5, %if.then4, %entry
  %retval.0 = phi i8* [ %end, %if.then4 ], [ %dst, %entry ], [ %dst.addr.023, %if.end5 ]
  ret i8* %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_uint64_to_string(i8* %dst, i8* %end, i64 %arg, i32 %min_digits) local_unnamed_addr #0 {
entry:
  %buf = alloca [32 x i8], align 1
  %0 = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i32 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %0) #11
  %arrayidx = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i32 0, i32 31
  store i8 0, i8* %arrayidx, align 1, !tbaa !22
  %add.ptr = getelementptr inbounds [32 x i8], [32 x i8]* %buf, i32 0, i32 30
  %cmp13 = icmp sgt i32 %min_digits, 0
  %tobool14 = icmp ne i64 %arg, 0
  %1 = or i1 %tobool14, %cmp13
  br i1 %1, label %entry.for.body_crit_edge, label %for.cond.cleanup

entry.for.body_crit_edge:                         ; preds = %entry
  %inc.1 = add nuw nsw i32 0, 1
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  %digits.0.lcssa = phi i8* [ %add.ptr, %entry ], [ %incdec.ptr, %for.body ]
  %incdec.ptr1 = getelementptr inbounds i8, i8* %digits.0.lcssa, i32 1
  %call = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %incdec.ptr1) #15
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %0) #11
  ret i8* %call

for.body:                                         ; preds = %entry.for.body_crit_edge, %for.body.for.body_crit_edge
  %arg.addr.017 = phi i64 [ %div, %for.body.for.body_crit_edge ], [ %arg, %entry.for.body_crit_edge ]
  %digits.016 = phi i8* [ %incdec.ptr, %for.body.for.body_crit_edge ], [ %add.ptr, %entry.for.body_crit_edge ]
  %inc.phi = phi i32 [ %inc.0, %for.body.for.body_crit_edge ], [ %inc.1, %entry.for.body_crit_edge ]
  %div = udiv i64 %arg.addr.017, 10
  %mul.neg = mul i64 %div, -10
  %sub = add i64 %mul.neg, %arg.addr.017
  %2 = trunc i64 %sub to i8
  %conv = add i8 %2, 48
  store i8 %conv, i8* %digits.016, align 1, !tbaa !22
  %incdec.ptr = getelementptr inbounds i8, i8* %digits.016, i32 -1
  %cmp = icmp slt i32 %inc.phi, %min_digits
  %3 = icmp ugt i64 %arg.addr.017, 9
  %4 = or i1 %3, %cmp
  br i1 %4, label %for.body.for.body_crit_edge, label %for.cond.cleanup, !llvm.loop !23

for.body.for.body_crit_edge:                      ; preds = %for.body
  %inc.0 = add nuw nsw i32 %inc.phi, 1
  br label %for.body
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #3

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #3

; Function Attrs: nounwind mustprogress
define weak i8* @halide_int64_to_string(i8* %dst, i8* %end, i64 %arg, i32 %min_digits) local_unnamed_addr #0 {
entry:
  %cmp = icmp slt i64 %arg, 0
  %cmp1 = icmp ult i8* %dst, %end
  %or.cond = and i1 %cmp1, %cmp
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %incdec.ptr = getelementptr inbounds i8, i8* %dst, i32 1
  store i8 45, i8* %dst, align 1, !tbaa !22
  %sub = sub nsw i64 0, %arg
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %arg.addr.0 = phi i64 [ %sub, %if.then ], [ %arg, %entry ]
  %dst.addr.0 = phi i8* [ %incdec.ptr, %if.then ], [ %dst, %entry ]
  %call = tail call i8* @halide_uint64_to_string(i8* %dst.addr.0, i8* %end, i64 %arg.addr.0, i32 %min_digits) #15
  ret i8* %call
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_double_to_string(i8* %dst, i8* %end, double %arg, i32 %scientific) local_unnamed_addr #0 {
entry:
  %arg.addr = alloca double, align 8
  %bits = alloca i64, align 8
  %buf = alloca [512 x i8], align 1
  store double %arg, double* %arg.addr, align 8, !tbaa !24
  %0 = bitcast i64* %bits to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %0) #11
  store i64 0, i64* %bits, align 8, !tbaa !26
  %1 = bitcast double* %arg.addr to i8*
  %call = call i8* @memcpy(i8* nonnull %0, i8* nonnull %1, i32 8) #14
  %2 = load i64, i64* %bits, align 8, !tbaa !26
  %and = and i64 %2, 4503599627370495
  %shr = lshr i64 %2, 52
  %3 = trunc i64 %shr to i32
  %conv = and i32 %3, 2047
  %cmp = icmp eq i32 %conv, 2047
  br i1 %cmp, label %if.then, label %if.else15

if.then:                                          ; preds = %entry
  %tobool.not = icmp eq i64 %and, 0
  %tobool10.not = icmp sgt i64 %2, -1
  br i1 %tobool.not, label %if.else9, label %if.then4

if.then4:                                         ; preds = %if.then
  br i1 %tobool10.not, label %if.else, label %if.then6

if.then6:                                         ; preds = %if.then4
  %call7 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.1.9, i32 0, i32 0)) #15
  br label %cleanup147

if.else:                                          ; preds = %if.then4
  %call8 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.2.10, i32 0, i32 0)) #15
  br label %cleanup147

if.else9:                                         ; preds = %if.then
  br i1 %tobool10.not, label %if.else13, label %if.then11

if.then11:                                        ; preds = %if.else9
  %call12 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.3.11, i32 0, i32 0)) #15
  br label %cleanup147

if.else13:                                        ; preds = %if.else9
  %call14 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.4.12, i32 0, i32 0)) #15
  br label %cleanup147

if.else15:                                        ; preds = %entry
  %cmp16 = icmp eq i32 %conv, 0
  %cmp17 = icmp eq i64 %and, 0
  %or.cond = and i1 %cmp17, %cmp16
  br i1 %or.cond, label %if.then18, label %if.end32

if.then18:                                        ; preds = %if.else15
  %tobool19.not = icmp eq i32 %scientific, 0
  %tobool27.not = icmp sgt i64 %2, -1
  br i1 %tobool19.not, label %if.else26, label %if.then20

if.then20:                                        ; preds = %if.then18
  br i1 %tobool27.not, label %if.else24, label %if.then22

if.then22:                                        ; preds = %if.then20
  %call23 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.5.13, i32 0, i32 0)) #15
  br label %cleanup147

if.else24:                                        ; preds = %if.then20
  %call25 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.6.14, i32 0, i32 0)) #15
  br label %cleanup147

if.else26:                                        ; preds = %if.then18
  br i1 %tobool27.not, label %if.else30, label %if.then28

if.then28:                                        ; preds = %if.else26
  %call29 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.7.15, i32 0, i32 0)) #15
  br label %cleanup147

if.else30:                                        ; preds = %if.else26
  %call31 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.8.16, i32 0, i32 0)) #15
  br label %cleanup147

if.end32:                                         ; preds = %if.else15
  %tobool33.not = icmp sgt i64 %2, -1
  br i1 %tobool33.not, label %if.end36, label %if.then34

if.then34:                                        ; preds = %if.end32
  %call35 = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.9, i32 0, i32 0)) #15
  %4 = load double, double* %arg.addr, align 8, !tbaa !24
  %fneg = fneg double %4
  store double %fneg, double* %arg.addr, align 8, !tbaa !24
  br label %if.end36

if.end36:                                         ; preds = %if.then34, %if.end32
  %dst.addr.0 = phi i8* [ %call35, %if.then34 ], [ %dst, %if.end32 ]
  %tobool37.not = icmp eq i32 %scientific, 0
  br i1 %tobool37.not, label %if.else61, label %while.condthread-pre-split

while.condthread-pre-split:                       ; preds = %if.end36
  %.pr = load double, double* %arg.addr, align 8, !tbaa !24
  %cmp39276 = fcmp olt double %.pr, 1.000000e+00
  br i1 %cmp39276, label %while.condthread-pre-split.while.body_crit_edge, label %while.cond40thread-pre-split

while.condthread-pre-split.while.body_crit_edge:  ; preds = %while.condthread-pre-split
  %dec.1 = add nsw i32 0, -1
  br label %while.body

while.body:                                       ; preds = %while.condthread-pre-split.while.body_crit_edge, %while.body.while.body_crit_edge
  %dec.phi = phi i32 [ %dec.0, %while.body.while.body_crit_edge ], [ %dec.1, %while.condthread-pre-split.while.body_crit_edge ]
  %5 = phi double [ %mul, %while.body.while.body_crit_edge ], [ %.pr, %while.condthread-pre-split.while.body_crit_edge ]
  %mul = fmul double %5, 1.000000e+01
  %cmp39 = fcmp olt double %mul, 1.000000e+00
  br i1 %cmp39, label %while.body.while.body_crit_edge, label %while.cond.while.cond40thread-pre-split_crit_edge, !llvm.loop !28

while.body.while.body_crit_edge:                  ; preds = %while.body
  %dec.0 = add nsw i32 %dec.phi, -1
  br label %while.body

while.cond.while.cond40thread-pre-split_crit_edge: ; preds = %while.body
  store double %mul, double* %arg.addr, align 8, !tbaa !24
  br label %while.cond40thread-pre-split

while.cond40thread-pre-split:                     ; preds = %while.cond.while.cond40thread-pre-split_crit_edge, %while.condthread-pre-split
  %.pr260 = phi double [ %mul, %while.cond.while.cond40thread-pre-split_crit_edge ], [ %.pr, %while.condthread-pre-split ]
  %exponent_base_10.0.lcssa = phi i32 [ %dec.phi, %while.cond.while.cond40thread-pre-split_crit_edge ], [ 0, %while.condthread-pre-split ]
  %cmp41272 = fcmp ult double %.pr260, 1.000000e+01
  br i1 %cmp41272, label %while.end43, label %while.body42

while.body42:                                     ; preds = %while.cond40thread-pre-split, %while.body42
  %exponent_base_10.1273 = phi i32 [ %inc, %while.body42 ], [ %exponent_base_10.0.lcssa, %while.cond40thread-pre-split ]
  %6 = phi double [ %div, %while.body42 ], [ %.pr260, %while.cond40thread-pre-split ]
  %div = fdiv double %6, 1.000000e+01
  %inc = add nsw i32 %exponent_base_10.1273, 1
  %cmp41 = fcmp ult double %div, 1.000000e+01
  br i1 %cmp41, label %while.cond40.while.end43_crit_edge, label %while.body42, !llvm.loop !29

while.cond40.while.end43_crit_edge:               ; preds = %while.body42
  store double %div, double* %arg.addr, align 8, !tbaa !24
  br label %while.end43

while.end43:                                      ; preds = %while.cond40.while.end43_crit_edge, %while.cond40thread-pre-split
  %.lcssa = phi double [ %div, %while.cond40.while.end43_crit_edge ], [ %.pr260, %while.cond40thread-pre-split ]
  %exponent_base_10.1.lcssa = phi i32 [ %inc, %while.cond40.while.end43_crit_edge ], [ %exponent_base_10.0.lcssa, %while.cond40thread-pre-split ]
  %mul44 = fmul double %.lcssa, 1.000000e+06
  %add = fadd double %mul44, 5.000000e-01
  %conv45 = fptoui double %add to i64
  %div46 = udiv i64 %conv45, 1000000
  %mul47.neg = mul i64 %div46, -1000000
  %sub48 = add i64 %mul47.neg, %conv45
  %call49 = call i8* @halide_int64_to_string(i8* %dst.addr.0, i8* %end, i64 %div46, i32 1) #15
  %call50 = call i8* @halide_string_to_string(i8* %call49, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.66, i32 0, i32 0)) #15
  %call51 = call i8* @halide_int64_to_string(i8* %call50, i8* %end, i64 %sub48, i32 6) #15
  %cmp52 = icmp sgt i32 %exponent_base_10.1.lcssa, -1
  br i1 %cmp52, label %if.then53, label %if.else55

if.then53:                                        ; preds = %while.end43
  %call54 = call i8* @halide_string_to_string(i8* %call51, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.11, i32 0, i32 0)) #15
  br label %if.end58

if.else55:                                        ; preds = %while.end43
  %call56 = call i8* @halide_string_to_string(i8* %call51, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.12, i32 0, i32 0)) #15
  %sub57 = sub nsw i32 0, %exponent_base_10.1.lcssa
  br label %if.end58

if.end58:                                         ; preds = %if.else55, %if.then53
  %exponent_base_10.2 = phi i32 [ %exponent_base_10.1.lcssa, %if.then53 ], [ %sub57, %if.else55 ]
  %dst.addr.1 = phi i8* [ %call54, %if.then53 ], [ %call56, %if.else55 ]
  %conv59261 = zext i32 %exponent_base_10.2 to i64
  %call60 = call i8* @halide_int64_to_string(i8* %dst.addr.1, i8* %end, i64 %conv59261, i32 2) #15
  br label %cleanup147

if.else61:                                        ; preds = %if.end36
  br i1 %cmp16, label %if.then63, label %if.end65

if.then63:                                        ; preds = %if.else61
  %call64 = call i8* @halide_double_to_string(i8* %dst.addr.0, i8* %end, double 0.000000e+00, i32 0) #15
  br label %cleanup147

if.end65:                                         ; preds = %if.else61
  %add67 = or i64 %and, 4503599627370496
  %sub69 = add nsw i32 %conv, -1075
  %cmp70 = icmp ult i32 %conv, 1075
  br i1 %cmp70, label %if.then71, label %if.end104

if.then71:                                        ; preds = %if.end65
  %cmp72 = icmp ult i32 %conv, 1023
  br i1 %cmp72, label %if.end83, label %if.else75

if.else75:                                        ; preds = %if.then71
  %sub76 = sub nuw nsw i32 1075, %conv
  %sh_prom = zext i32 %sub76 to i64
  %shr77 = lshr i64 %add67, %sh_prom
  %shl80 = shl i64 %shr77, %sh_prom
  %sub81 = sub i64 %add67, %shl80
  br label %if.end83

if.end83:                                         ; preds = %if.else75, %if.then71
  %integer_part.0 = phi i64 [ %shr77, %if.else75 ], [ 0, %if.then71 ]
  %f.0.in = phi i64 [ %sub81, %if.else75 ], [ %add67, %if.then71 ]
  %f.0 = uitofp i64 %f.0.in to double
  %conv84257 = zext i32 %sub69 to i64
  %shl85 = shl i64 %conv84257, 52
  %add87 = add i64 %shl85, 4696837146684686336
  %7 = bitcast i64 %add87 to double
  %mul89 = fmul double %7, %f.0
  %add90 = fadd double %mul89, 5.000000e-01
  %conv91 = fptoui double %add90 to i64
  %conv92 = uitofp i64 %conv91 to double
  %cmp93 = fcmp oeq double %add90, %conv92
  %and95 = and i64 %conv91, 1
  %tobool96.not = icmp ne i64 %and95, 0
  %not.or.cond258 = and i1 %cmp93, %tobool96.not
  %dec98 = sext i1 %not.or.cond258 to i64
  %fractional_part.0 = add i64 %dec98, %conv91
  %cmp100 = icmp eq i64 %fractional_part.0, 1000000
  %inc102 = zext i1 %cmp100 to i64
  %spec.select = add nuw i64 %integer_part.0, %inc102
  %spec.select259 = select i1 %cmp100, i64 0, i64 %fractional_part.0
  br label %if.end104

if.end104:                                        ; preds = %if.end83, %if.end65
  %integer_part.2 = phi i64 [ %spec.select, %if.end83 ], [ %add67, %if.end65 ]
  %integer_exponent.0 = phi i32 [ 0, %if.end83 ], [ %sub69, %if.end65 ]
  %fractional_part.2 = phi i64 [ %spec.select259, %if.end83 ], [ 0, %if.end65 ]
  %8 = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i32 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #11
  %add.ptr = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i32 0, i32 512
  %add.ptr105 = getelementptr inbounds [512 x i8], [512 x i8]* %buf, i32 0, i32 480
  %call108 = call i8* @halide_int64_to_string(i8* nonnull %add.ptr105, i8* nonnull %add.ptr, i64 %integer_part.2, i32 1) #15
  %cmp109267 = icmp sgt i32 %integer_exponent.0, 0
  br i1 %cmp109267, label %for.cond111.preheader.preheader, label %for.cond.cleanup

for.cond111.preheader.preheader:                  ; preds = %if.end104
  %9 = add nsw i32 %integer_exponent.0, -1
  %xtraiter = and i32 %integer_exponent.0, 3
  %10 = icmp ult i32 %9, 3
  br i1 %10, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.cond111.preheader.preheader.new

for.cond111.preheader.preheader.new:              ; preds = %for.cond111.preheader.preheader
  %unroll_iter = and i32 %integer_exponent.0, -4
  br label %for.cond111.preheader

for.cond111.preheader:                            ; preds = %if.end137.3, %for.cond111.preheader.preheader.new
  %int_part_ptr.0268 = phi i8* [ %add.ptr105, %for.cond111.preheader.preheader.new ], [ %int_part_ptr.1.3, %if.end137.3 ]
  %niter = phi i32 [ %unroll_iter, %for.cond111.preheader.preheader.new ], [ %niter.nsub.3, %if.end137.3 ]
  %add.ptr112 = getelementptr inbounds i8, i8* %int_part_ptr.0268, i32 -1
  %cmp113.not263 = icmp eq i8* %call108, %int_part_ptr.0268
  br i1 %cmp113.not263, label %if.end137, label %for.body115

for.cond.cleanup.loopexit.unr-lcssa:              ; preds = %if.end137.3, %for.cond111.preheader.preheader
  %int_part_ptr.1.lcssa.ph = phi i8* [ undef, %for.cond111.preheader.preheader ], [ %int_part_ptr.1.3, %if.end137.3 ]
  %int_part_ptr.0268.unr = phi i8* [ %add.ptr105, %for.cond111.preheader.preheader ], [ %int_part_ptr.1.3, %if.end137.3 ]
  %lcmp.mod.not = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod.not, label %for.cond.cleanup, label %for.cond111.preheader.epil

for.cond111.preheader.epil:                       ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %if.end137.epil
  %int_part_ptr.0268.epil = phi i8* [ %int_part_ptr.1.epil, %if.end137.epil ], [ %int_part_ptr.0268.unr, %for.cond.cleanup.loopexit.unr-lcssa ]
  %epil.iter = phi i32 [ %epil.iter.sub, %if.end137.epil ], [ %xtraiter, %for.cond.cleanup.loopexit.unr-lcssa ]
  %add.ptr112.epil = getelementptr inbounds i8, i8* %int_part_ptr.0268.epil, i32 -1
  %cmp113.not263.epil = icmp eq i8* %call108, %int_part_ptr.0268.epil
  br i1 %cmp113.not263.epil, label %if.end137.epil, label %for.body115.epil

for.body115.epil:                                 ; preds = %for.cond111.preheader.epil, %for.body115.epil
  %p.0265.pn.epil = phi i8* [ %p.0265.epil, %for.body115.epil ], [ %call108, %for.cond111.preheader.epil ]
  %carry.0264.epil = phi i8 [ %carry.1.epil, %for.body115.epil ], [ 0, %for.cond111.preheader.epil ]
  %p.0265.epil = getelementptr inbounds i8, i8* %p.0265.pn.epil, i32 -1
  %11 = load i8, i8* %p.0265.epil, align 1, !tbaa !22
  %sub117.epil = shl i8 %11, 1
  %mul120.epil = add i8 %sub117.epil, -96
  %add121.epil = or i8 %mul120.epil, %carry.0264.epil
  %cmp124.epil = icmp sgt i8 %add121.epil, 9
  %sub127.epil = add i8 %add121.epil, -10
  %carry.1.epil = zext i1 %cmp124.epil to i8
  %new_digit.0.epil = select i1 %cmp124.epil, i8 %sub127.epil, i8 %add121.epil
  %add132.epil = add i8 %new_digit.0.epil, 48
  store i8 %add132.epil, i8* %p.0265.epil, align 1, !tbaa !22
  %cmp113.not.epil = icmp eq i8* %p.0265.epil, %int_part_ptr.0268.epil
  br i1 %cmp113.not.epil, label %for.cond.cleanup114.epil, label %for.body115.epil, !llvm.loop !30

for.cond.cleanup114.epil:                         ; preds = %for.body115.epil
  br i1 %cmp124.epil, label %if.then135.epil, label %if.end137.epil

if.then135.epil:                                  ; preds = %for.cond.cleanup114.epil
  store i8 49, i8* %add.ptr112.epil, align 1, !tbaa !22
  br label %if.end137.epil

if.end137.epil:                                   ; preds = %if.then135.epil, %for.cond.cleanup114.epil, %for.cond111.preheader.epil
  %int_part_ptr.1.epil = phi i8* [ %add.ptr112.epil, %if.then135.epil ], [ %int_part_ptr.0268.epil, %for.cond.cleanup114.epil ], [ %call108, %for.cond111.preheader.epil ]
  %epil.iter.sub = add i32 %epil.iter, -1
  %epil.iter.cmp.not = icmp eq i32 %epil.iter.sub, 0
  br i1 %epil.iter.cmp.not, label %for.cond.cleanup, label %for.cond111.preheader.epil, !llvm.loop !31

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %if.end137.epil, %if.end104
  %int_part_ptr.0.lcssa = phi i8* [ %add.ptr105, %if.end104 ], [ %int_part_ptr.1.lcssa.ph, %for.cond.cleanup.loopexit.unr-lcssa ], [ %int_part_ptr.1.epil, %if.end137.epil ]
  %call141 = call i8* @halide_string_to_string(i8* %dst.addr.0, i8* %end, i8* %int_part_ptr.0.lcssa) #15
  %call142 = call i8* @halide_string_to_string(i8* %call141, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.66, i32 0, i32 0)) #15
  %call143 = call i8* @halide_int64_to_string(i8* %call142, i8* %end, i64 %fractional_part.2, i32 6) #15
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #11
  br label %cleanup147

for.cond.cleanup114:                              ; preds = %for.body115
  br i1 %cmp124, label %if.then135, label %if.end137

for.body115:                                      ; preds = %for.cond111.preheader, %for.body115
  %p.0265.pn = phi i8* [ %p.0265, %for.body115 ], [ %call108, %for.cond111.preheader ]
  %carry.0264 = phi i8 [ %carry.1, %for.body115 ], [ 0, %for.cond111.preheader ]
  %p.0265 = getelementptr inbounds i8, i8* %p.0265.pn, i32 -1
  %12 = load i8, i8* %p.0265, align 1, !tbaa !22
  %sub117 = shl i8 %12, 1
  %mul120 = add i8 %sub117, -96
  %add121 = or i8 %mul120, %carry.0264
  %cmp124 = icmp sgt i8 %add121, 9
  %sub127 = add i8 %add121, -10
  %carry.1 = zext i1 %cmp124 to i8
  %new_digit.0 = select i1 %cmp124, i8 %sub127, i8 %add121
  %add132 = add i8 %new_digit.0, 48
  store i8 %add132, i8* %p.0265, align 1, !tbaa !22
  %cmp113.not = icmp eq i8* %p.0265, %int_part_ptr.0268
  br i1 %cmp113.not, label %for.cond.cleanup114, label %for.body115, !llvm.loop !30

if.then135:                                       ; preds = %for.cond.cleanup114
  store i8 49, i8* %add.ptr112, align 1, !tbaa !22
  br label %if.end137

if.end137:                                        ; preds = %if.then135, %for.cond.cleanup114, %for.cond111.preheader
  %int_part_ptr.1 = phi i8* [ %add.ptr112, %if.then135 ], [ %int_part_ptr.0268, %for.cond.cleanup114 ], [ %call108, %for.cond111.preheader ]
  %add.ptr112.1 = getelementptr inbounds i8, i8* %int_part_ptr.1, i32 -1
  %cmp113.not263.1 = icmp eq i8* %call108, %int_part_ptr.1
  br i1 %cmp113.not263.1, label %if.end137.1, label %for.body115.1

cleanup147:                                       ; preds = %for.cond.cleanup, %if.then63, %if.end58, %if.else30, %if.then28, %if.else24, %if.then22, %if.else13, %if.then11, %if.else, %if.then6
  %retval.1 = phi i8* [ %call7, %if.then6 ], [ %call8, %if.else ], [ %call12, %if.then11 ], [ %call14, %if.else13 ], [ %call23, %if.then22 ], [ %call25, %if.else24 ], [ %call29, %if.then28 ], [ %call31, %if.else30 ], [ %call64, %if.then63 ], [ %call60, %if.end58 ], [ %call143, %for.cond.cleanup ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %0) #11
  ret i8* %retval.1

for.body115.1:                                    ; preds = %if.end137, %for.body115.1
  %p.0265.pn.1 = phi i8* [ %p.0265.1, %for.body115.1 ], [ %call108, %if.end137 ]
  %carry.0264.1 = phi i8 [ %carry.1.1, %for.body115.1 ], [ 0, %if.end137 ]
  %p.0265.1 = getelementptr inbounds i8, i8* %p.0265.pn.1, i32 -1
  %13 = load i8, i8* %p.0265.1, align 1, !tbaa !22
  %sub117.1 = shl i8 %13, 1
  %mul120.1 = add i8 %sub117.1, -96
  %add121.1 = or i8 %mul120.1, %carry.0264.1
  %cmp124.1 = icmp sgt i8 %add121.1, 9
  %sub127.1 = add i8 %add121.1, -10
  %carry.1.1 = zext i1 %cmp124.1 to i8
  %new_digit.0.1 = select i1 %cmp124.1, i8 %sub127.1, i8 %add121.1
  %add132.1 = add i8 %new_digit.0.1, 48
  store i8 %add132.1, i8* %p.0265.1, align 1, !tbaa !22
  %cmp113.not.1 = icmp eq i8* %p.0265.1, %int_part_ptr.1
  br i1 %cmp113.not.1, label %for.cond.cleanup114.1, label %for.body115.1, !llvm.loop !30

for.cond.cleanup114.1:                            ; preds = %for.body115.1
  br i1 %cmp124.1, label %if.then135.1, label %if.end137.1

if.then135.1:                                     ; preds = %for.cond.cleanup114.1
  store i8 49, i8* %add.ptr112.1, align 1, !tbaa !22
  br label %if.end137.1

if.end137.1:                                      ; preds = %if.then135.1, %for.cond.cleanup114.1, %if.end137
  %int_part_ptr.1.1 = phi i8* [ %add.ptr112.1, %if.then135.1 ], [ %int_part_ptr.1, %for.cond.cleanup114.1 ], [ %call108, %if.end137 ]
  %add.ptr112.2 = getelementptr inbounds i8, i8* %int_part_ptr.1.1, i32 -1
  %cmp113.not263.2 = icmp eq i8* %call108, %int_part_ptr.1.1
  br i1 %cmp113.not263.2, label %if.end137.2, label %for.body115.2

for.body115.2:                                    ; preds = %if.end137.1, %for.body115.2
  %p.0265.pn.2 = phi i8* [ %p.0265.2, %for.body115.2 ], [ %call108, %if.end137.1 ]
  %carry.0264.2 = phi i8 [ %carry.1.2, %for.body115.2 ], [ 0, %if.end137.1 ]
  %p.0265.2 = getelementptr inbounds i8, i8* %p.0265.pn.2, i32 -1
  %14 = load i8, i8* %p.0265.2, align 1, !tbaa !22
  %sub117.2 = shl i8 %14, 1
  %mul120.2 = add i8 %sub117.2, -96
  %add121.2 = or i8 %mul120.2, %carry.0264.2
  %cmp124.2 = icmp sgt i8 %add121.2, 9
  %sub127.2 = add i8 %add121.2, -10
  %carry.1.2 = zext i1 %cmp124.2 to i8
  %new_digit.0.2 = select i1 %cmp124.2, i8 %sub127.2, i8 %add121.2
  %add132.2 = add i8 %new_digit.0.2, 48
  store i8 %add132.2, i8* %p.0265.2, align 1, !tbaa !22
  %cmp113.not.2 = icmp eq i8* %p.0265.2, %int_part_ptr.1.1
  br i1 %cmp113.not.2, label %for.cond.cleanup114.2, label %for.body115.2, !llvm.loop !30

for.cond.cleanup114.2:                            ; preds = %for.body115.2
  br i1 %cmp124.2, label %if.then135.2, label %if.end137.2

if.then135.2:                                     ; preds = %for.cond.cleanup114.2
  store i8 49, i8* %add.ptr112.2, align 1, !tbaa !22
  br label %if.end137.2

if.end137.2:                                      ; preds = %if.then135.2, %for.cond.cleanup114.2, %if.end137.1
  %int_part_ptr.1.2 = phi i8* [ %add.ptr112.2, %if.then135.2 ], [ %int_part_ptr.1.1, %for.cond.cleanup114.2 ], [ %call108, %if.end137.1 ]
  %add.ptr112.3 = getelementptr inbounds i8, i8* %int_part_ptr.1.2, i32 -1
  %cmp113.not263.3 = icmp eq i8* %call108, %int_part_ptr.1.2
  br i1 %cmp113.not263.3, label %if.end137.3, label %for.body115.3

for.body115.3:                                    ; preds = %if.end137.2, %for.body115.3
  %p.0265.pn.3 = phi i8* [ %p.0265.3, %for.body115.3 ], [ %call108, %if.end137.2 ]
  %carry.0264.3 = phi i8 [ %carry.1.3, %for.body115.3 ], [ 0, %if.end137.2 ]
  %p.0265.3 = getelementptr inbounds i8, i8* %p.0265.pn.3, i32 -1
  %15 = load i8, i8* %p.0265.3, align 1, !tbaa !22
  %sub117.3 = shl i8 %15, 1
  %mul120.3 = add i8 %sub117.3, -96
  %add121.3 = or i8 %mul120.3, %carry.0264.3
  %cmp124.3 = icmp sgt i8 %add121.3, 9
  %sub127.3 = add i8 %add121.3, -10
  %carry.1.3 = zext i1 %cmp124.3 to i8
  %new_digit.0.3 = select i1 %cmp124.3, i8 %sub127.3, i8 %add121.3
  %add132.3 = add i8 %new_digit.0.3, 48
  store i8 %add132.3, i8* %p.0265.3, align 1, !tbaa !22
  %cmp113.not.3 = icmp eq i8* %p.0265.3, %int_part_ptr.1.2
  br i1 %cmp113.not.3, label %for.cond.cleanup114.3, label %for.body115.3, !llvm.loop !30

for.cond.cleanup114.3:                            ; preds = %for.body115.3
  br i1 %cmp124.3, label %if.then135.3, label %if.end137.3

if.then135.3:                                     ; preds = %for.cond.cleanup114.3
  store i8 49, i8* %add.ptr112.3, align 1, !tbaa !22
  br label %if.end137.3

if.end137.3:                                      ; preds = %if.then135.3, %for.cond.cleanup114.3, %if.end137.2
  %int_part_ptr.1.3 = phi i8* [ %add.ptr112.3, %if.then135.3 ], [ %int_part_ptr.1.2, %for.cond.cleanup114.3 ], [ %call108, %if.end137.2 ]
  %niter.nsub.3 = add i32 %niter, -4
  %niter.ncmp.3 = icmp eq i32 %niter.nsub.3, 0
  br i1 %niter.ncmp.3, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.cond111.preheader, !llvm.loop !33
}

declare i8* @memcpy(i8*, i8*, i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak i8* @halide_pointer_to_string(i8* %dst, i8* %end, i8* %arg) local_unnamed_addr #0 {
entry:
  %buf = alloca [20 x i8], align 1
  %0 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %0) #11
  call void @llvm.memset.p0i8.i32(i8* nonnull align 1 dereferenceable(20) %0, i8 0, i32 20, i1 false)
  %add.ptr = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 18
  %1 = ptrtoint i8* %arg to i32
  %idxprom = and i32 %1, 15
  %arrayidx = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom
  %2 = load i8, i8* %arrayidx, align 1, !tbaa !22
  %incdec.ptr = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 17
  store i8 %2, i8* %add.ptr, align 1, !tbaa !22
  %3 = lshr i32 %1, 4
  %tobool.not = icmp eq i32 %3, 0
  br i1 %tobool.not, label %cleanup, label %for.cond

for.cond:                                         ; preds = %entry
  %idxprom.1 = and i32 %3, 15
  %arrayidx.1 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.1
  %4 = load i8, i8* %arrayidx.1, align 1, !tbaa !22
  %incdec.ptr.1 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 16
  store i8 %4, i8* %incdec.ptr, align 1, !tbaa !22
  %5 = lshr i32 %1, 8
  %tobool.not.1 = icmp eq i32 %5, 0
  br i1 %tobool.not.1, label %cleanup, label %for.cond.1

cleanup:                                          ; preds = %for.cond.6, %for.cond.5, %for.cond.4, %for.cond.3, %for.cond.2, %for.cond.1, %for.cond, %entry
  %buf_ptr.016.lcssa = phi i8* [ %add.ptr, %entry ], [ %incdec.ptr, %for.cond ], [ %incdec.ptr.1, %for.cond.1 ], [ %incdec.ptr.2, %for.cond.2 ], [ %incdec.ptr.3, %for.cond.3 ], [ %incdec.ptr.4, %for.cond.4 ], [ %incdec.ptr.5, %for.cond.5 ], [ %incdec.ptr.6, %for.cond.6 ]
  %incdec.ptr.lcssa = phi i8* [ %incdec.ptr, %entry ], [ %incdec.ptr.1, %for.cond ], [ %incdec.ptr.2, %for.cond.1 ], [ %incdec.ptr.3, %for.cond.2 ], [ %incdec.ptr.4, %for.cond.3 ], [ %incdec.ptr.5, %for.cond.4 ], [ %incdec.ptr.6, %for.cond.5 ], [ %incdec.ptr.7, %for.cond.6 ]
  %incdec.ptr1 = getelementptr inbounds i8, i8* %buf_ptr.016.lcssa, i32 -2
  store i8 120, i8* %incdec.ptr.lcssa, align 1, !tbaa !22
  store i8 48, i8* %incdec.ptr1, align 1, !tbaa !22
  %call = call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %incdec.ptr1) #15
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %0) #11
  ret i8* %call

for.cond.1:                                       ; preds = %for.cond
  %idxprom.2 = and i32 %5, 15
  %arrayidx.2 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.2
  %6 = load i8, i8* %arrayidx.2, align 1, !tbaa !22
  %incdec.ptr.2 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 15
  store i8 %6, i8* %incdec.ptr.1, align 1, !tbaa !22
  %7 = lshr i32 %1, 12
  %tobool.not.2 = icmp eq i32 %7, 0
  br i1 %tobool.not.2, label %cleanup, label %for.cond.2

for.cond.2:                                       ; preds = %for.cond.1
  %idxprom.3 = and i32 %7, 15
  %arrayidx.3 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.3
  %8 = load i8, i8* %arrayidx.3, align 1, !tbaa !22
  %incdec.ptr.3 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 14
  store i8 %8, i8* %incdec.ptr.2, align 1, !tbaa !22
  %9 = lshr i32 %1, 16
  %tobool.not.3 = icmp eq i32 %9, 0
  br i1 %tobool.not.3, label %cleanup, label %for.cond.3

for.cond.3:                                       ; preds = %for.cond.2
  %idxprom.4 = and i32 %9, 15
  %arrayidx.4 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.4
  %10 = load i8, i8* %arrayidx.4, align 1, !tbaa !22
  %incdec.ptr.4 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 13
  store i8 %10, i8* %incdec.ptr.3, align 1, !tbaa !22
  %11 = lshr i32 %1, 20
  %tobool.not.4 = icmp eq i32 %11, 0
  br i1 %tobool.not.4, label %cleanup, label %for.cond.4

for.cond.4:                                       ; preds = %for.cond.3
  %idxprom.5 = and i32 %11, 15
  %arrayidx.5 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.5
  %12 = load i8, i8* %arrayidx.5, align 1, !tbaa !22
  %incdec.ptr.5 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 12
  store i8 %12, i8* %incdec.ptr.4, align 1, !tbaa !22
  %13 = lshr i32 %1, 24
  %tobool.not.5 = icmp eq i32 %13, 0
  br i1 %tobool.not.5, label %cleanup, label %for.cond.5

for.cond.5:                                       ; preds = %for.cond.4
  %idxprom.6 = and i32 %13, 15
  %arrayidx.6 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %idxprom.6
  %14 = load i8, i8* %arrayidx.6, align 1, !tbaa !22
  %incdec.ptr.6 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 11
  store i8 %14, i8* %incdec.ptr.5, align 1, !tbaa !22
  %15 = lshr i32 %1, 28
  %tobool.not.6 = icmp eq i32 %15, 0
  br i1 %tobool.not.6, label %cleanup, label %for.cond.6

for.cond.6:                                       ; preds = %for.cond.5
  %arrayidx.7 = getelementptr inbounds [17 x i8], [17 x i8]* @.str.13, i32 0, i32 %15
  %16 = load i8, i8* %arrayidx.7, align 1, !tbaa !22
  %incdec.ptr.7 = getelementptr inbounds [20 x i8], [20 x i8]* %buf, i32 0, i32 10
  store i8 %16, i8* %incdec.ptr.6, align 1, !tbaa !22
  br label %cleanup
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn writeonly
declare void @llvm.memset.p0i8.i32(i8* nocapture writeonly, i8, i32, i1 immarg) #5

; Function Attrs: nounwind mustprogress
define weak i8* @halide_type_to_string(i8* %dst, i8* %end, %struct.halide_type_t* %t) local_unnamed_addr #0 {
entry:
  %code = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i32 0, i32 0
  %0 = load i8, i8* %code, align 2, !tbaa !34
  %1 = icmp ult i8 %0, 4
  br i1 %1, label %switch.lookup, label %sw.epilog

switch.lookup:                                    ; preds = %entry
  %2 = sext i8 %0 to i32
  %switch.gep = getelementptr inbounds [4 x i8*], [4 x i8*]* @switch.table.halide_type_to_string, i32 0, i32 %2
  %switch.load = load i8*, i8** %switch.gep, align 4
  br label %sw.epilog

sw.epilog:                                        ; preds = %entry, %switch.lookup
  %code_name.0 = phi i8* [ %switch.load, %switch.lookup ], [ getelementptr inbounds ([14 x i8], [14 x i8]* @.str.18, i32 0, i32 0), %entry ]
  %call = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* nonnull %code_name.0) #15
  %bits = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i32 0, i32 1
  %3 = load i8, i8* %bits, align 1, !tbaa !38
  %conv4 = zext i8 %3 to i64
  %call5 = tail call i8* @halide_uint64_to_string(i8* %call, i8* %end, i64 %conv4, i32 1) #15
  %lanes = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %t, i32 0, i32 2
  %4 = load i16, i16* %lanes, align 2, !tbaa !39
  %cmp.not = icmp eq i16 %4, 1
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %sw.epilog
  %call7 = tail call i8* @halide_string_to_string(i8* %call5, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.19, i32 0, i32 0)) #15
  %5 = load i16, i16* %lanes, align 2, !tbaa !39
  %conv9 = zext i16 %5 to i64
  %call10 = tail call i8* @halide_uint64_to_string(i8* %call7, i8* %end, i64 %conv9, i32 1) #15
  br label %if.end

if.end:                                           ; preds = %if.then, %sw.epilog
  %dst.addr.0 = phi i8* [ %call10, %if.then ], [ %call5, %sw.epilog ]
  ret i8* %dst.addr.0
}

; Function Attrs: nounwind mustprogress
define weak i8* @halide_buffer_to_string(i8* %dst, i8* %end, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %call = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.20, i32 0, i32 0)) #15
  br label %return

if.end:                                           ; preds = %entry
  %call1 = tail call i8* @halide_string_to_string(i8* %dst, i8* %end, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.21, i32 0, i32 0)) #15
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %call2 = tail call i8* @halide_uint64_to_string(i8* %call1, i8* %end, i64 %0, i32 1) #15
  %call3 = tail call i8* @halide_string_to_string(i8* %call2, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %1 = bitcast %struct.halide_device_interface_t** %device_interface to i8**
  %2 = load i8*, i8** %1, align 8, !tbaa !42
  %call4 = tail call i8* @halide_pointer_to_string(i8* %call3, i8* %end, i8* %2) #15
  %call5 = tail call i8* @halide_string_to_string(i8* %call4, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 2
  %3 = load i8*, i8** %host, align 4, !tbaa !43
  %call6 = tail call i8* @halide_pointer_to_string(i8* %call5, i8* %end, i8* %3) #15
  %call7 = tail call i8* @halide_string_to_string(i8* %call6, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %flags = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %4 = load i64, i64* %flags, align 8, !tbaa !44
  %call8 = tail call i8* @halide_uint64_to_string(i8* %call7, i8* %end, i64 %4, i32 1) #15
  %call9 = tail call i8* @halide_string_to_string(i8* %call8, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %type = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 4
  %call10 = tail call i8* @halide_type_to_string(i8* %call9, i8* %end, %struct.halide_type_t* nonnull %type) #15
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 5
  %5 = load i32, i32* %dimensions, align 4, !tbaa !45
  %cmp1177 = icmp sgt i32 %5, 0
  br i1 %cmp1177, label %for.body.lr.ph, label %for.cond.cleanup

for.body.lr.ph:                                   ; preds = %if.end
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 6
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %if.end
  %dst.addr.0.lcssa = phi i8* [ %call10, %if.end ], [ %call24, %for.body ]
  %call25 = tail call i8* @halide_string_to_string(i8* %dst.addr.0.lcssa, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.44, i32 0, i32 0)) #15
  br label %return

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %i.079 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body ]
  %dst.addr.078 = phi i8* [ %call10, %for.body.lr.ph ], [ %call24, %for.body ]
  %call12 = tail call i8* @halide_string_to_string(i8* %dst.addr.078, i8* %end, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.23, i32 0, i32 0)) #15
  %6 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !46
  %min = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 %i.079, i32 0
  %7 = load i32, i32* %min, align 4, !tbaa !47
  %conv = sext i32 %7 to i64
  %call13 = tail call i8* @halide_int64_to_string(i8* %call12, i8* %end, i64 %conv, i32 1) #15
  %call14 = tail call i8* @halide_string_to_string(i8* %call13, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %8 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !46
  %extent = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %8, i32 %i.079, i32 1
  %9 = load i32, i32* %extent, align 4, !tbaa !49
  %conv17 = sext i32 %9 to i64
  %call18 = tail call i8* @halide_int64_to_string(i8* %call14, i8* %end, i64 %conv17, i32 1) #15
  %call19 = tail call i8* @halide_string_to_string(i8* %call18, i8* %end, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #15
  %10 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !46
  %stride = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %10, i32 %i.079, i32 2
  %11 = load i32, i32* %stride, align 4, !tbaa !50
  %conv22 = sext i32 %11 to i64
  %call23 = tail call i8* @halide_int64_to_string(i8* %call19, i8* %end, i64 %conv22, i32 1) #15
  %call24 = tail call i8* @halide_string_to_string(i8* %call23, i8* %end, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.24, i32 0, i32 0)) #15
  %inc = add nuw nsw i32 %i.079, 1
  %12 = load i32, i32* %dimensions, align 4, !tbaa !45
  %cmp11 = icmp slt i32 %inc, %12
  br i1 %cmp11, label %for.body, label %for.cond.cleanup, !llvm.loop !51

return:                                           ; preds = %for.cond.cleanup, %if.then
  %retval.0 = phi i8* [ %call, %if.then ], [ %call25, %for.cond.cleanup ]
  ret i8* %retval.0
}

; Function Attrs: alwaysinline nounwind willreturn mustprogress
define weak i32 @halide_malloc_alignment() local_unnamed_addr #6 {
entry:
  ret i32 128
}

; Function Attrs: nounwind
define weak i32 @halide_reuse_device_allocations(i8* %user_context, i1 zeroext %flag) local_unnamed_addr #4 {
entry:
  %frombool = zext i1 %flag to i8
  store i8 %frombool, i8* @_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE, align 1, !tbaa !18
  br i1 %flag, label %if.end5, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  %p.014 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 4, !tbaa !10
  %cmp.not15 = icmp eq %struct.halide_device_allocation_pool* %p.014, null
  br i1 %cmp.not15, label %for.cond.cleanup, label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %if.then
  %err.0.lcssa = phi i32 [ 0, %if.then ], [ %spec.select, %for.body ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  br label %if.end5

for.body:                                         ; preds = %if.then, %for.body
  %p.017 = phi %struct.halide_device_allocation_pool* [ %p.0, %for.body ], [ %p.014, %if.then ]
  %err.016 = phi i32 [ %spec.select, %for.body ], [ 0, %if.then ]
  %release_unused = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %p.017, i32 0, i32 0
  %0 = load i32 (i8*)*, i32 (i8*)** %release_unused, align 4, !tbaa !52
  %call = tail call i32 %0(i8* %user_context) #14
  %tobool3.not = icmp eq i32 %call, 0
  %spec.select = select i1 %tobool3.not, i32 %err.016, i32 %call
  %next = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %p.017, i32 0, i32 1
  %p.0 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** %next, align 4, !tbaa !10
  %cmp.not = icmp eq %struct.halide_device_allocation_pool* %p.0, null
  br i1 %cmp.not, label %for.cond.cleanup, label %for.body, !llvm.loop !54

if.end5:                                          ; preds = %for.cond.cleanup, %entry
  %err.2 = phi i32 [ 0, %entry ], [ %err.0.lcssa, %for.cond.cleanup ]
  ret i32 %err.2
}

; Function Attrs: nounwind willreturn mustprogress
define weak zeroext i1 @halide_can_reuse_device_allocations(i8* %user_context) local_unnamed_addr #2 {
entry:
  %0 = load i8, i8* @_ZN6Halide7Runtime8Internal36halide_reuse_device_allocations_flagE, align 1, !tbaa !18, !range !21
  %tobool = icmp ne i8 %0, 0
  ret i1 %tobool
}

; Function Attrs: nounwind willreturn
define weak void @halide_register_device_allocation_pool(%struct.halide_device_allocation_pool* %pool) local_unnamed_addr #7 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  %0 = load %struct.halide_device_allocation_pool*, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 4, !tbaa !10
  %next = getelementptr inbounds %struct.halide_device_allocation_pool, %struct.halide_device_allocation_pool* %pool, i32 0, i32 1
  store %struct.halide_device_allocation_pool* %0, %struct.halide_device_allocation_pool** %next, align 4, !tbaa !55
  store %struct.halide_device_allocation_pool* %pool, %struct.halide_device_allocation_pool** @_ZN6Halide7Runtime8Internal23device_allocation_poolsE, align 4, !tbaa !10
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal21allocation_pools_lockE) #14
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 %d, i64 %src_off, i64 %dst_off) local_unnamed_addr #0 {
entry:
  %cmp39 = icmp sgt i32 %d, -1
  br i1 %cmp39, label %land.rhs, label %while.end

land.rhs:                                         ; preds = %entry, %while.body
  %d.addr.040 = phi i32 [ %dec, %while.body ], [ %d, %entry ]
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 3, i32 %d.addr.040
  %0 = load i64, i64* %arrayidx, align 8, !tbaa !26
  %cmp1 = icmp eq i64 %0, 1
  br i1 %cmp1, label %while.body, label %while.end

while.body:                                       ; preds = %land.rhs
  %dec = add nsw i32 %d.addr.040, -1
  %cmp = icmp sgt i32 %d.addr.040, 0
  br i1 %cmp, label %land.rhs, label %if.then, !llvm.loop !56

while.end:                                        ; preds = %land.rhs, %entry
  %d.addr.0.lcssa = phi i32 [ %d, %entry ], [ %d.addr.040, %land.rhs ]
  %cmp2 = icmp eq i32 %d.addr.0.lcssa, -1
  br i1 %cmp2, label %if.then, label %for.cond.preheader

for.cond.preheader:                               ; preds = %while.end
  %arrayidx7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 3, i32 %d.addr.0.lcssa
  %1 = load i64, i64* %arrayidx7, align 8, !tbaa !26
  %cmp835.not = icmp eq i64 %1, 0
  br i1 %cmp835.not, label %if.end, label %for.body.lr.ph

for.body.lr.ph:                                   ; preds = %for.cond.preheader
  %sub = add nsw i32 %d.addr.0.lcssa, -1
  %arrayidx9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 4, i32 %d.addr.0.lcssa
  %arrayidx11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 5, i32 %d.addr.0.lcssa
  %inc.0 = add nuw i64 0, 1
  br label %for.body

if.then:                                          ; preds = %while.body, %while.end
  %src = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 0
  %2 = load i64, i64* %src, align 8, !tbaa !57
  %add = add i64 %2, %src_off
  %conv = trunc i64 %add to i32
  %3 = inttoptr i32 %conv to i8*
  %dst = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 1
  %4 = load i64, i64* %dst, align 8, !tbaa !59
  %add3 = add i64 %4, %dst_off
  %conv4 = trunc i64 %add3 to i32
  %5 = inttoptr i32 %conv4 to i8*
  %chunk_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 6
  %6 = load i64, i64* %chunk_size, align 8, !tbaa !60
  %conv5 = trunc i64 %6 to i32
  %call = tail call i8* @memcpy(i8* %5, i8* %3, i32 %conv5) #14
  br label %if.end

for.body:                                         ; preds = %for.body.for.body_crit_edge, %for.body.lr.ph
  %inc.phi = phi i64 [ %inc.0, %for.body.lr.ph ], [ %inc.1, %for.body.for.body_crit_edge ]
  %src_off.addr.037 = phi i64 [ %src_off, %for.body.lr.ph ], [ %add10, %for.body.for.body_crit_edge ]
  %dst_off.addr.036 = phi i64 [ %dst_off, %for.body.lr.ph ], [ %add12, %for.body.for.body_crit_edge ]
  tail call void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 %sub, i64 %src_off.addr.037, i64 %dst_off.addr.036) #15
  %7 = load i64, i64* %arrayidx9, align 8, !tbaa !26
  %add10 = add i64 %7, %src_off.addr.037
  %8 = load i64, i64* %arrayidx11, align 8, !tbaa !26
  %add12 = add i64 %8, %dst_off.addr.036
  %9 = load i64, i64* %arrayidx7, align 8, !tbaa !26
  %cmp8 = icmp ult i64 %inc.phi, %9
  br i1 %cmp8, label %for.body.for.body_crit_edge, label %if.end, !llvm.loop !61

for.body.for.body_crit_edge:                      ; preds = %for.body
  %inc.1 = add nuw i64 %inc.phi, 1
  br label %for.body

if.end:                                           ; preds = %for.body, %if.then, %for.cond.preheader
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal11copy_memoryERKNS1_11device_copyEPv(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i8* %user_context) local_unnamed_addr #0 {
entry:
  %src = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 0
  %0 = load i64, i64* %src, align 8, !tbaa !57
  %dst = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 1
  %1 = load i64, i64* %dst, align 8, !tbaa !59
  %cmp.not = icmp eq i64 %0, %1
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %src_begin = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %copy, i32 0, i32 2
  %2 = load i64, i64* %src_begin, align 8, !tbaa !62
  tail call void @_ZN6Halide7Runtime8Internal18copy_memory_helperERKNS1_11device_copyEixx(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %copy, i32 15, i64 %2, i64 0) #15
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce void @_ZN6Halide7Runtime8Internal16make_buffer_copyEPK15halide_buffer_tbS4_b(%"struct.Halide::Runtime::Internal::device_copy"* noalias sret(%"struct.Halide::Runtime::Internal::device_copy") align 8 %agg.result, %struct.halide_buffer_t* %src, i1 zeroext %src_host, %struct.halide_buffer_t* %dst, i1 zeroext %dst_host) local_unnamed_addr #0 {
entry:
  %c = alloca %"struct.Halide::Runtime::Internal::device_copy", align 8
  %0 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %c to i8*
  call void @llvm.lifetime.start.p0i8(i64 416, i8* nonnull %0) #11
  br i1 %src_host, label %cond.true, label %cond.false

cond.true:                                        ; preds = %entry
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 2
  %1 = load i8*, i8** %host, align 4, !tbaa !43
  %2 = ptrtoint i8* %1 to i32
  %3 = zext i32 %2 to i64
  br label %cond.end

cond.false:                                       ; preds = %entry
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 0
  %4 = load i64, i64* %device, align 8, !tbaa !40
  br label %cond.end

cond.end:                                         ; preds = %cond.false, %cond.true
  %cond = phi i64 [ %3, %cond.true ], [ %4, %cond.false ]
  %src2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 0
  store i64 %cond, i64* %src2, align 8, !tbaa !57
  br i1 %dst_host, label %cond.true4, label %cond.false6

cond.true4:                                       ; preds = %cond.end
  %host5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 2
  %5 = load i8*, i8** %host5, align 4, !tbaa !43
  %6 = ptrtoint i8* %5 to i32
  %7 = zext i32 %6 to i64
  br label %cond.end8

cond.false6:                                      ; preds = %cond.end
  %device7 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 0
  %8 = load i64, i64* %device7, align 8, !tbaa !40
  br label %cond.end8

cond.end8:                                        ; preds = %cond.false6, %cond.true4
  %cond9 = phi i64 [ %7, %cond.true4 ], [ %8, %cond.false6 ]
  %dst10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 1
  store i64 %cond9, i64* %dst10, align 8, !tbaa !59
  %bits.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 4, i32 1
  %9 = load i8, i8* %bits.i, align 1, !tbaa !38
  %conv.i = zext i8 %9 to i32
  %add.i = add nuw nsw i32 %conv.i, 7
  %div.i = lshr i32 %add.i, 3
  %conv = zext i32 %div.i to i64
  %chunk_size = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 6
  store i64 %conv, i64* %chunk_size, align 8, !tbaa !60
  %arrayidx = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 0
  store i64 1, i64* %arrayidx, align 8, !tbaa !26
  %arrayidx11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 0
  store i64 0, i64* %arrayidx11, align 8, !tbaa !26
  %arrayidx12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 0
  store i64 0, i64* %arrayidx12, align 8, !tbaa !26
  %arrayidx.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 1
  store i64 1, i64* %arrayidx.1, align 8, !tbaa !26
  %arrayidx11.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 1
  store i64 0, i64* %arrayidx11.1, align 8, !tbaa !26
  %arrayidx12.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 1
  store i64 0, i64* %arrayidx12.1, align 8, !tbaa !26
  %arrayidx.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 2
  store i64 1, i64* %arrayidx.2, align 8, !tbaa !26
  %arrayidx11.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 2
  store i64 0, i64* %arrayidx11.2, align 8, !tbaa !26
  %arrayidx12.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 2
  store i64 0, i64* %arrayidx12.2, align 8, !tbaa !26
  %arrayidx.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 3
  store i64 1, i64* %arrayidx.3, align 8, !tbaa !26
  %arrayidx11.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 3
  store i64 0, i64* %arrayidx11.3, align 8, !tbaa !26
  %arrayidx12.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 3
  store i64 0, i64* %arrayidx12.3, align 8, !tbaa !26
  %arrayidx.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 4
  store i64 1, i64* %arrayidx.4, align 8, !tbaa !26
  %arrayidx11.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 4
  store i64 0, i64* %arrayidx11.4, align 8, !tbaa !26
  %arrayidx12.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 4
  store i64 0, i64* %arrayidx12.4, align 8, !tbaa !26
  %arrayidx.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 5
  store i64 1, i64* %arrayidx.5, align 8, !tbaa !26
  %arrayidx11.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 5
  store i64 0, i64* %arrayidx11.5, align 8, !tbaa !26
  %arrayidx12.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 5
  store i64 0, i64* %arrayidx12.5, align 8, !tbaa !26
  %arrayidx.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 6
  store i64 1, i64* %arrayidx.6, align 8, !tbaa !26
  %arrayidx11.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 6
  store i64 0, i64* %arrayidx11.6, align 8, !tbaa !26
  %arrayidx12.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 6
  store i64 0, i64* %arrayidx12.6, align 8, !tbaa !26
  %arrayidx.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 7
  store i64 1, i64* %arrayidx.7, align 8, !tbaa !26
  %arrayidx11.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 7
  store i64 0, i64* %arrayidx11.7, align 8, !tbaa !26
  %arrayidx12.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 7
  store i64 0, i64* %arrayidx12.7, align 8, !tbaa !26
  %arrayidx.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 8
  store i64 1, i64* %arrayidx.8, align 8, !tbaa !26
  %arrayidx11.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 8
  store i64 0, i64* %arrayidx11.8, align 8, !tbaa !26
  %arrayidx12.8 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 8
  store i64 0, i64* %arrayidx12.8, align 8, !tbaa !26
  %arrayidx.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 9
  store i64 1, i64* %arrayidx.9, align 8, !tbaa !26
  %arrayidx11.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 9
  store i64 0, i64* %arrayidx11.9, align 8, !tbaa !26
  %arrayidx12.9 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 9
  store i64 0, i64* %arrayidx12.9, align 8, !tbaa !26
  %arrayidx.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 10
  store i64 1, i64* %arrayidx.10, align 8, !tbaa !26
  %arrayidx11.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 10
  store i64 0, i64* %arrayidx11.10, align 8, !tbaa !26
  %arrayidx12.10 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 10
  store i64 0, i64* %arrayidx12.10, align 8, !tbaa !26
  %arrayidx.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 11
  store i64 1, i64* %arrayidx.11, align 8, !tbaa !26
  %arrayidx11.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 11
  store i64 0, i64* %arrayidx11.11, align 8, !tbaa !26
  %arrayidx12.11 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 11
  store i64 0, i64* %arrayidx12.11, align 8, !tbaa !26
  %arrayidx.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 12
  store i64 1, i64* %arrayidx.12, align 8, !tbaa !26
  %arrayidx11.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 12
  store i64 0, i64* %arrayidx11.12, align 8, !tbaa !26
  %arrayidx12.12 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 12
  store i64 0, i64* %arrayidx12.12, align 8, !tbaa !26
  %arrayidx.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 13
  store i64 1, i64* %arrayidx.13, align 8, !tbaa !26
  %arrayidx11.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 13
  store i64 0, i64* %arrayidx11.13, align 8, !tbaa !26
  %arrayidx12.13 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 13
  store i64 0, i64* %arrayidx12.13, align 8, !tbaa !26
  %arrayidx.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 14
  store i64 1, i64* %arrayidx.14, align 8, !tbaa !26
  %arrayidx11.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 14
  store i64 0, i64* %arrayidx11.14, align 8, !tbaa !26
  %arrayidx12.14 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 14
  store i64 0, i64* %arrayidx12.14, align 8, !tbaa !26
  %arrayidx.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 15
  store i64 1, i64* %arrayidx.15, align 8, !tbaa !26
  %arrayidx11.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 15
  store i64 0, i64* %arrayidx11.15, align 8, !tbaa !26
  %arrayidx12.15 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 15
  store i64 0, i64* %arrayidx12.15, align 8, !tbaa !26
  %src_begin = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 2
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 5
  %10 = load i32, i32* %dimensions, align 4, !tbaa !45
  %cmp15248 = icmp sgt i32 %10, 0
  br i1 %cmp15248, label %for.body17.lr.ph, label %for.cond.cleanup16

for.body17.lr.ph:                                 ; preds = %cond.end8
  %dim = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 6
  %11 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim, align 8, !tbaa !46
  %dim20 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 6
  %12 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim20, align 8, !tbaa !46
  %13 = add i32 %10, -1
  %xtraiter = and i32 %10, 7
  %14 = icmp ult i32 %13, 7
  br i1 %14, label %for.cond.cleanup16.loopexit.unr-lcssa, label %for.body17.lr.ph.new

for.body17.lr.ph.new:                             ; preds = %for.body17.lr.ph
  %unroll_iter = and i32 %10, -8
  br label %for.body17

for.cond.cleanup16.loopexit.unr-lcssa:            ; preds = %for.body17, %for.body17.lr.ph
  %add.lcssa.ph = phi i64 [ undef, %for.body17.lr.ph ], [ %add.7, %for.body17 ]
  %.unr = phi i64 [ 0, %for.body17.lr.ph ], [ %add.7, %for.body17 ]
  %i13.0249.unr = phi i32 [ 0, %for.body17.lr.ph ], [ %inc28.7, %for.body17 ]
  %lcmp.mod.not = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod.not, label %for.cond.cleanup16, label %for.body17.epil

for.body17.epil:                                  ; preds = %for.cond.cleanup16.loopexit.unr-lcssa, %for.body17.epil
  %15 = phi i64 [ %add.epil, %for.body17.epil ], [ %.unr, %for.cond.cleanup16.loopexit.unr-lcssa ]
  %i13.0249.epil = phi i32 [ %inc28.epil, %for.body17.epil ], [ %i13.0249.unr, %for.cond.cleanup16.loopexit.unr-lcssa ]
  %epil.iter = phi i32 [ %epil.iter.sub, %for.body17.epil ], [ %xtraiter, %for.cond.cleanup16.loopexit.unr-lcssa ]
  %stride.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %i13.0249.epil, i32 2
  %16 = load i32, i32* %stride.epil, align 4, !tbaa !50
  %conv19.epil = sext i32 %16 to i64
  %min.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %i13.0249.epil, i32 0
  %17 = load i32, i32* %min.epil, align 4, !tbaa !47
  %min24.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %i13.0249.epil, i32 0
  %18 = load i32, i32* %min24.epil, align 4, !tbaa !47
  %sub.epil = sub nsw i32 %17, %18
  %conv25.epil = sext i32 %sub.epil to i64
  %mul.epil = mul nsw i64 %conv25.epil, %conv19.epil
  %add.epil = add i64 %mul.epil, %15
  %inc28.epil = add nuw nsw i32 %i13.0249.epil, 1
  %epil.iter.sub = add i32 %epil.iter, -1
  %epil.iter.cmp.not = icmp eq i32 %epil.iter.sub, 0
  br i1 %epil.iter.cmp.not, label %for.cond.cleanup16, label %for.body17.epil, !llvm.loop !63

for.cond.cleanup16:                               ; preds = %for.cond.cleanup16.loopexit.unr-lcssa, %for.body17.epil, %cond.end8
  %19 = phi i64 [ 0, %cond.end8 ], [ %add.lcssa.ph, %for.cond.cleanup16.loopexit.unr-lcssa ], [ %add.epil, %for.body17.epil ]
  %mul32 = mul i64 %19, %conv
  store i64 %mul32, i64* %src_begin, align 8, !tbaa !62
  %dimensions34 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 5
  %20 = load i32, i32* %dimensions34, align 4, !tbaa !45
  %cmp35.not = icmp eq i32 %10, %20
  br i1 %cmp35.not, label %lor.lhs.false, label %if.then

for.body17:                                       ; preds = %for.body17, %for.body17.lr.ph.new
  %21 = phi i64 [ 0, %for.body17.lr.ph.new ], [ %add.7, %for.body17 ]
  %i13.0249 = phi i32 [ 0, %for.body17.lr.ph.new ], [ %inc28.7, %for.body17 ]
  %niter = phi i32 [ %unroll_iter, %for.body17.lr.ph.new ], [ %niter.nsub.7, %for.body17 ]
  %stride = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %i13.0249, i32 2
  %22 = load i32, i32* %stride, align 4, !tbaa !50
  %conv19 = sext i32 %22 to i64
  %min = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %i13.0249, i32 0
  %23 = load i32, i32* %min, align 4, !tbaa !47
  %min24 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %i13.0249, i32 0
  %24 = load i32, i32* %min24, align 4, !tbaa !47
  %sub = sub nsw i32 %23, %24
  %conv25 = sext i32 %sub to i64
  %mul = mul nsw i64 %conv25, %conv19
  %add = add i64 %mul, %21
  %inc28 = or i32 %i13.0249, 1
  %stride.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28, i32 2
  %25 = load i32, i32* %stride.1, align 4, !tbaa !50
  %conv19.1 = sext i32 %25 to i64
  %min.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28, i32 0
  %26 = load i32, i32* %min.1, align 4, !tbaa !47
  %min24.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28, i32 0
  %27 = load i32, i32* %min24.1, align 4, !tbaa !47
  %sub.1 = sub nsw i32 %26, %27
  %conv25.1 = sext i32 %sub.1 to i64
  %mul.1 = mul nsw i64 %conv25.1, %conv19.1
  %add.1 = add i64 %mul.1, %add
  %inc28.1 = or i32 %i13.0249, 2
  %stride.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.1, i32 2
  %28 = load i32, i32* %stride.2, align 4, !tbaa !50
  %conv19.2 = sext i32 %28 to i64
  %min.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.1, i32 0
  %29 = load i32, i32* %min.2, align 4, !tbaa !47
  %min24.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.1, i32 0
  %30 = load i32, i32* %min24.2, align 4, !tbaa !47
  %sub.2 = sub nsw i32 %29, %30
  %conv25.2 = sext i32 %sub.2 to i64
  %mul.2 = mul nsw i64 %conv25.2, %conv19.2
  %add.2 = add i64 %mul.2, %add.1
  %inc28.2 = or i32 %i13.0249, 3
  %stride.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.2, i32 2
  %31 = load i32, i32* %stride.3, align 4, !tbaa !50
  %conv19.3 = sext i32 %31 to i64
  %min.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.2, i32 0
  %32 = load i32, i32* %min.3, align 4, !tbaa !47
  %min24.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.2, i32 0
  %33 = load i32, i32* %min24.3, align 4, !tbaa !47
  %sub.3 = sub nsw i32 %32, %33
  %conv25.3 = sext i32 %sub.3 to i64
  %mul.3 = mul nsw i64 %conv25.3, %conv19.3
  %add.3 = add i64 %mul.3, %add.2
  %inc28.3 = or i32 %i13.0249, 4
  %stride.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.3, i32 2
  %34 = load i32, i32* %stride.4, align 4, !tbaa !50
  %conv19.4 = sext i32 %34 to i64
  %min.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.3, i32 0
  %35 = load i32, i32* %min.4, align 4, !tbaa !47
  %min24.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.3, i32 0
  %36 = load i32, i32* %min24.4, align 4, !tbaa !47
  %sub.4 = sub nsw i32 %35, %36
  %conv25.4 = sext i32 %sub.4 to i64
  %mul.4 = mul nsw i64 %conv25.4, %conv19.4
  %add.4 = add i64 %mul.4, %add.3
  %inc28.4 = or i32 %i13.0249, 5
  %stride.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.4, i32 2
  %37 = load i32, i32* %stride.5, align 4, !tbaa !50
  %conv19.5 = sext i32 %37 to i64
  %min.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.4, i32 0
  %38 = load i32, i32* %min.5, align 4, !tbaa !47
  %min24.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.4, i32 0
  %39 = load i32, i32* %min24.5, align 4, !tbaa !47
  %sub.5 = sub nsw i32 %38, %39
  %conv25.5 = sext i32 %sub.5 to i64
  %mul.5 = mul nsw i64 %conv25.5, %conv19.5
  %add.5 = add i64 %mul.5, %add.4
  %inc28.5 = or i32 %i13.0249, 6
  %stride.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.5, i32 2
  %40 = load i32, i32* %stride.6, align 4, !tbaa !50
  %conv19.6 = sext i32 %40 to i64
  %min.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.5, i32 0
  %41 = load i32, i32* %min.6, align 4, !tbaa !47
  %min24.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.5, i32 0
  %42 = load i32, i32* %min24.6, align 4, !tbaa !47
  %sub.6 = sub nsw i32 %41, %42
  %conv25.6 = sext i32 %sub.6 to i64
  %mul.6 = mul nsw i64 %conv25.6, %conv19.6
  %add.6 = add i64 %mul.6, %add.5
  %inc28.6 = or i32 %i13.0249, 7
  %stride.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.6, i32 2
  %43 = load i32, i32* %stride.7, align 4, !tbaa !50
  %conv19.7 = sext i32 %43 to i64
  %min.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %12, i32 %inc28.6, i32 0
  %44 = load i32, i32* %min.7, align 4, !tbaa !47
  %min24.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %11, i32 %inc28.6, i32 0
  %45 = load i32, i32* %min24.7, align 4, !tbaa !47
  %sub.7 = sub nsw i32 %44, %45
  %conv25.7 = sext i32 %sub.7 to i64
  %mul.7 = mul nsw i64 %conv25.7, %conv19.7
  %add.7 = add i64 %mul.7, %add.6
  %inc28.7 = add nuw nsw i32 %i13.0249, 8
  %niter.nsub.7 = add i32 %niter, -8
  %niter.ncmp.7 = icmp eq i32 %niter.nsub.7, 0
  br i1 %niter.ncmp.7, label %for.cond.cleanup16.loopexit.unr-lcssa, label %for.body17, !llvm.loop !64

lor.lhs.false:                                    ; preds = %for.cond.cleanup16
  %bits.i229 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 4, i32 1
  %46 = load i8, i8* %bits.i229, align 1, !tbaa !38
  %conv.i230 = zext i8 %46 to i32
  %add.i231 = add nuw nsw i32 %conv.i230, 7
  %div.i232 = lshr i32 %add.i231, 3
  %cmp40.not = icmp ne i32 %div.i, %div.i232
  %cmp43 = icmp sgt i32 %10, 16
  %or.cond237 = or i1 %cmp43, %cmp40.not
  br i1 %or.cond237, label %if.then, label %if.end

if.then:                                          ; preds = %lor.lhs.false, %for.cond.cleanup16
  %47 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  tail call void @llvm.memset.p0i8.i32(i8* nonnull align 8 dereferenceable(416) %47, i8 0, i32 416, i1 false)
  br label %cleanup

if.end:                                           ; preds = %lor.lhs.false
  %cmp45 = icmp eq i32 %div.i, 0
  br i1 %cmp45, label %if.then46, label %for.cond49.preheader

for.cond49.preheader:                             ; preds = %if.end
  br i1 %cmp15248, label %for.body53.lr.ph, label %while.end

for.body53.lr.ph:                                 ; preds = %for.cond49.preheader
  %dim55 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 6
  %48 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim55, align 8, !tbaa !46
  %dim64 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 6
  %49 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim64, align 8, !tbaa !46
  br label %for.body53

if.then46:                                        ; preds = %if.end
  %50 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  tail call void @llvm.memset.p0i8.i32(i8* nonnull align 8 dereferenceable(416) %50, i8 0, i32 416, i1 false)
  br label %cleanup

while.cond.preheader:                             ; preds = %for.cond.cleanup86
  %.pre = load i64, i64* %chunk_size, align 8, !tbaa !60
  %.pre253 = load i64, i64* %arrayidx11, align 8, !tbaa !26
  %cmp121239 = icmp eq i64 %.pre, %.pre253
  br i1 %cmp121239, label %land.rhs.lr.ph, label %while.end

land.rhs.lr.ph:                                   ; preds = %while.cond.preheader
  %.pre254 = load i64, i64* %arrayidx12, align 8, !tbaa !26
  br label %land.rhs

for.body53:                                       ; preds = %for.cond.cleanup86, %for.body53.lr.ph
  %i48.0246 = phi i32 [ 0, %for.body53.lr.ph ], [ %inc116, %for.cond.cleanup86 ]
  %stride57 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %48, i32 %i48.0246, i32 2
  %51 = load i32, i32* %stride57, align 4, !tbaa !50
  %conv58 = sext i32 %51 to i64
  %mul62 = mul nsw i64 %conv58, %conv
  %stride66 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %49, i32 %i48.0246, i32 2
  %52 = load i32, i32* %stride66, align 4, !tbaa !50
  %conv67 = sext i32 %52 to i64
  %mul71 = mul nsw i64 %conv67, %conv
  %cmp73240.not = icmp eq i32 %i48.0246, 0
  br i1 %cmp73240.not, label %for.end83, label %for.body74.lr.ph

for.body74.lr.ph:                                 ; preds = %for.body53
  %cmp78.not = icmp eq i64 %mul62, 0
  br i1 %cmp78.not, label %for.end83, label %for.body74.us

for.body74.us:                                    ; preds = %for.body74.lr.ph, %for.inc81.us
  %insert.0241.us = phi i32 [ %inc82.us, %for.inc81.us ], [ 0, %for.body74.lr.ph ]
  %arrayidx76.us = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %insert.0241.us
  %53 = load i64, i64* %arrayidx76.us, align 8, !tbaa !26
  %cmp77.us = icmp ult i64 %mul62, %53
  br i1 %cmp77.us, label %for.end83, label %for.inc81.us

for.inc81.us:                                     ; preds = %for.body74.us
  %inc82.us = add nuw nsw i32 %insert.0241.us, 1
  %exitcond2.not = icmp eq i32 %inc82.us, %i48.0246
  br i1 %exitcond2.not, label %for.end83, label %for.body74.us, !llvm.loop !65

for.end83:                                        ; preds = %for.inc81.us, %for.body74.us, %for.body74.lr.ph, %for.body53
  %insert.0.lcssa = phi i32 [ 0, %for.body53 ], [ %i48.0246, %for.body74.lr.ph ], [ %i48.0246, %for.inc81.us ], [ %insert.0241.us, %for.body74.us ]
  %cmp85243 = icmp ugt i32 %i48.0246, %insert.0.lcssa
  br i1 %cmp85243, label %for.body87.preheader, label %for.cond.cleanup86

for.body87.preheader:                             ; preds = %for.end83
  %54 = sub i32 %i48.0246, %insert.0.lcssa
  %55 = xor i32 %insert.0.lcssa, -1
  %56 = add i32 %i48.0246, %55
  %xtraiter5 = and i32 %54, 7
  %lcmp.mod6.not = icmp eq i32 %xtraiter5, 0
  br i1 %lcmp.mod6.not, label %for.body87.prol.loopexit, label %for.body87.prol

for.body87.prol:                                  ; preds = %for.body87.preheader, %for.body87.prol
  %j.0244.prol = phi i32 [ %sub89.prol, %for.body87.prol ], [ %i48.0246, %for.body87.preheader ]
  %prol.iter = phi i32 [ %prol.iter.sub, %for.body87.prol ], [ %xtraiter5, %for.body87.preheader ]
  %sub89.prol = add nsw i32 %j.0244.prol, -1
  %arrayidx90.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.prol
  %57 = load i64, i64* %arrayidx90.prol, align 8, !tbaa !26
  %arrayidx92.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %j.0244.prol
  store i64 %57, i64* %arrayidx92.prol, align 8, !tbaa !26
  %arrayidx95.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.prol
  %58 = load i64, i64* %arrayidx95.prol, align 8, !tbaa !26
  %arrayidx97.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %j.0244.prol
  store i64 %58, i64* %arrayidx97.prol, align 8, !tbaa !26
  %arrayidx100.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.prol
  %59 = load i64, i64* %arrayidx100.prol, align 8, !tbaa !26
  %arrayidx102.prol = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %j.0244.prol
  store i64 %59, i64* %arrayidx102.prol, align 8, !tbaa !26
  %prol.iter.sub = add i32 %prol.iter, -1
  %prol.iter.cmp.not = icmp eq i32 %prol.iter.sub, 0
  br i1 %prol.iter.cmp.not, label %for.body87.prol.loopexit, label %for.body87.prol, !llvm.loop !66

for.body87.prol.loopexit:                         ; preds = %for.body87.prol, %for.body87.preheader
  %j.0244.unr = phi i32 [ %i48.0246, %for.body87.preheader ], [ %sub89.prol, %for.body87.prol ]
  %60 = icmp ult i32 %56, 7
  br i1 %60, label %for.cond.cleanup86, label %for.body87

for.cond.cleanup86:                               ; preds = %for.body87.prol.loopexit, %for.body87, %for.end83
  %extent107 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %48, i32 %i48.0246, i32 1
  %61 = load i32, i32* %extent107, align 4, !tbaa !49
  %conv108 = sext i32 %61 to i64
  %arrayidx110 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %insert.0.lcssa
  store i64 %conv108, i64* %arrayidx110, align 8, !tbaa !26
  %arrayidx112 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %insert.0.lcssa
  store i64 %mul62, i64* %arrayidx112, align 8, !tbaa !26
  %arrayidx114 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %insert.0.lcssa
  store i64 %mul71, i64* %arrayidx114, align 8, !tbaa !26
  %inc116 = add nuw nsw i32 %i48.0246, 1
  %exitcond3.not = icmp eq i32 %inc116, %10
  br i1 %exitcond3.not, label %while.cond.preheader, label %for.body53, !llvm.loop !67

for.body87:                                       ; preds = %for.body87.prol.loopexit, %for.body87
  %j.0244 = phi i32 [ %sub89.7, %for.body87 ], [ %j.0244.unr, %for.body87.prol.loopexit ]
  %sub89 = add nsw i32 %j.0244, -1
  %arrayidx90 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89
  %62 = load i64, i64* %arrayidx90, align 8, !tbaa !26
  %arrayidx92 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %j.0244
  store i64 %62, i64* %arrayidx92, align 8, !tbaa !26
  %arrayidx95 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89
  %63 = load i64, i64* %arrayidx95, align 8, !tbaa !26
  %arrayidx97 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %j.0244
  store i64 %63, i64* %arrayidx97, align 8, !tbaa !26
  %arrayidx100 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89
  %64 = load i64, i64* %arrayidx100, align 8, !tbaa !26
  %arrayidx102 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %j.0244
  store i64 %64, i64* %arrayidx102, align 8, !tbaa !26
  %sub89.1 = add nsw i32 %j.0244, -2
  %arrayidx90.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.1
  %65 = load i64, i64* %arrayidx90.1, align 8, !tbaa !26
  %arrayidx92.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89
  store i64 %65, i64* %arrayidx92.1, align 8, !tbaa !26
  %arrayidx95.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.1
  %66 = load i64, i64* %arrayidx95.1, align 8, !tbaa !26
  %arrayidx97.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89
  store i64 %66, i64* %arrayidx97.1, align 8, !tbaa !26
  %arrayidx100.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.1
  %67 = load i64, i64* %arrayidx100.1, align 8, !tbaa !26
  %arrayidx102.1 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89
  store i64 %67, i64* %arrayidx102.1, align 8, !tbaa !26
  %sub89.2 = add nsw i32 %j.0244, -3
  %arrayidx90.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.2
  %68 = load i64, i64* %arrayidx90.2, align 8, !tbaa !26
  %arrayidx92.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.1
  store i64 %68, i64* %arrayidx92.2, align 8, !tbaa !26
  %arrayidx95.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.2
  %69 = load i64, i64* %arrayidx95.2, align 8, !tbaa !26
  %arrayidx97.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.1
  store i64 %69, i64* %arrayidx97.2, align 8, !tbaa !26
  %arrayidx100.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.2
  %70 = load i64, i64* %arrayidx100.2, align 8, !tbaa !26
  %arrayidx102.2 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.1
  store i64 %70, i64* %arrayidx102.2, align 8, !tbaa !26
  %sub89.3 = add nsw i32 %j.0244, -4
  %arrayidx90.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.3
  %71 = load i64, i64* %arrayidx90.3, align 8, !tbaa !26
  %arrayidx92.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.2
  store i64 %71, i64* %arrayidx92.3, align 8, !tbaa !26
  %arrayidx95.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.3
  %72 = load i64, i64* %arrayidx95.3, align 8, !tbaa !26
  %arrayidx97.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.2
  store i64 %72, i64* %arrayidx97.3, align 8, !tbaa !26
  %arrayidx100.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.3
  %73 = load i64, i64* %arrayidx100.3, align 8, !tbaa !26
  %arrayidx102.3 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.2
  store i64 %73, i64* %arrayidx102.3, align 8, !tbaa !26
  %sub89.4 = add nsw i32 %j.0244, -5
  %arrayidx90.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.4
  %74 = load i64, i64* %arrayidx90.4, align 8, !tbaa !26
  %arrayidx92.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.3
  store i64 %74, i64* %arrayidx92.4, align 8, !tbaa !26
  %arrayidx95.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.4
  %75 = load i64, i64* %arrayidx95.4, align 8, !tbaa !26
  %arrayidx97.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.3
  store i64 %75, i64* %arrayidx97.4, align 8, !tbaa !26
  %arrayidx100.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.4
  %76 = load i64, i64* %arrayidx100.4, align 8, !tbaa !26
  %arrayidx102.4 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.3
  store i64 %76, i64* %arrayidx102.4, align 8, !tbaa !26
  %sub89.5 = add nsw i32 %j.0244, -6
  %arrayidx90.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.5
  %77 = load i64, i64* %arrayidx90.5, align 8, !tbaa !26
  %arrayidx92.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.4
  store i64 %77, i64* %arrayidx92.5, align 8, !tbaa !26
  %arrayidx95.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.5
  %78 = load i64, i64* %arrayidx95.5, align 8, !tbaa !26
  %arrayidx97.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.4
  store i64 %78, i64* %arrayidx97.5, align 8, !tbaa !26
  %arrayidx100.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.5
  %79 = load i64, i64* %arrayidx100.5, align 8, !tbaa !26
  %arrayidx102.5 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.4
  store i64 %79, i64* %arrayidx102.5, align 8, !tbaa !26
  %sub89.6 = add nsw i32 %j.0244, -7
  %arrayidx90.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.6
  %80 = load i64, i64* %arrayidx90.6, align 8, !tbaa !26
  %arrayidx92.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.5
  store i64 %80, i64* %arrayidx92.6, align 8, !tbaa !26
  %arrayidx95.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.6
  %81 = load i64, i64* %arrayidx95.6, align 8, !tbaa !26
  %arrayidx97.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.5
  store i64 %81, i64* %arrayidx97.6, align 8, !tbaa !26
  %arrayidx100.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.6
  %82 = load i64, i64* %arrayidx100.6, align 8, !tbaa !26
  %arrayidx102.6 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.5
  store i64 %82, i64* %arrayidx102.6, align 8, !tbaa !26
  %sub89.7 = add nsw i32 %j.0244, -8
  %arrayidx90.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.7
  %83 = load i64, i64* %arrayidx90.7, align 8, !tbaa !26
  %arrayidx92.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 3, i32 %sub89.6
  store i64 %83, i64* %arrayidx92.7, align 8, !tbaa !26
  %arrayidx95.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.7
  %84 = load i64, i64* %arrayidx95.7, align 8, !tbaa !26
  %arrayidx97.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 5, i32 %sub89.6
  store i64 %84, i64* %arrayidx97.7, align 8, !tbaa !26
  %arrayidx100.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.7
  %85 = load i64, i64* %arrayidx100.7, align 8, !tbaa !26
  %arrayidx102.7 = getelementptr inbounds %"struct.Halide::Runtime::Internal::device_copy", %"struct.Halide::Runtime::Internal::device_copy"* %c, i32 0, i32 4, i32 %sub89.6
  store i64 %85, i64* %arrayidx102.7, align 8, !tbaa !26
  %cmp85.7 = icmp sgt i32 %sub89.7, %insert.0.lcssa
  br i1 %cmp85.7, label %for.body87, label %for.cond.cleanup86, !llvm.loop !68

land.rhs:                                         ; preds = %while.body, %land.rhs.lr.ph
  %86 = phi i64 [ %.pre254, %land.rhs.lr.ph ], [ %91, %while.body ]
  %87 = phi i64 [ %.pre, %land.rhs.lr.ph ], [ %mul129, %while.body ]
  %cmp125 = icmp eq i64 %87, %86
  br i1 %cmp125, label %while.body, label %while.end

while.body:                                       ; preds = %land.rhs
  %88 = load i64, i64* %arrayidx, align 8, !tbaa !26
  %mul129 = mul i64 %88, %86
  store i64 %mul129, i64* %chunk_size, align 8, !tbaa !60
  %89 = load i64, i64* %arrayidx.1, align 8, !tbaa !26
  store i64 %89, i64* %arrayidx, align 8, !tbaa !26
  %90 = load i64, i64* %arrayidx11.1, align 8, !tbaa !26
  store i64 %90, i64* %arrayidx11, align 8, !tbaa !26
  %91 = load i64, i64* %arrayidx12.1, align 8, !tbaa !26
  store i64 %91, i64* %arrayidx12, align 8, !tbaa !26
  %92 = load i64, i64* %arrayidx.2, align 8, !tbaa !26
  store i64 %92, i64* %arrayidx.1, align 8, !tbaa !26
  %93 = load i64, i64* %arrayidx11.2, align 8, !tbaa !26
  store i64 %93, i64* %arrayidx11.1, align 8, !tbaa !26
  %94 = load i64, i64* %arrayidx12.2, align 8, !tbaa !26
  store i64 %94, i64* %arrayidx12.1, align 8, !tbaa !26
  %95 = load i64, i64* %arrayidx.3, align 8, !tbaa !26
  store i64 %95, i64* %arrayidx.2, align 8, !tbaa !26
  %96 = load i64, i64* %arrayidx11.3, align 8, !tbaa !26
  store i64 %96, i64* %arrayidx11.2, align 8, !tbaa !26
  %97 = load i64, i64* %arrayidx12.3, align 8, !tbaa !26
  store i64 %97, i64* %arrayidx12.2, align 8, !tbaa !26
  %98 = load i64, i64* %arrayidx.4, align 8, !tbaa !26
  store i64 %98, i64* %arrayidx.3, align 8, !tbaa !26
  %99 = load i64, i64* %arrayidx11.4, align 8, !tbaa !26
  store i64 %99, i64* %arrayidx11.3, align 8, !tbaa !26
  %100 = load i64, i64* %arrayidx12.4, align 8, !tbaa !26
  store i64 %100, i64* %arrayidx12.3, align 8, !tbaa !26
  %101 = load i64, i64* %arrayidx.5, align 8, !tbaa !26
  store i64 %101, i64* %arrayidx.4, align 8, !tbaa !26
  %102 = load i64, i64* %arrayidx11.5, align 8, !tbaa !26
  store i64 %102, i64* %arrayidx11.4, align 8, !tbaa !26
  %103 = load i64, i64* %arrayidx12.5, align 8, !tbaa !26
  store i64 %103, i64* %arrayidx12.4, align 8, !tbaa !26
  %104 = load i64, i64* %arrayidx.6, align 8, !tbaa !26
  store i64 %104, i64* %arrayidx.5, align 8, !tbaa !26
  %105 = load i64, i64* %arrayidx11.6, align 8, !tbaa !26
  store i64 %105, i64* %arrayidx11.5, align 8, !tbaa !26
  %106 = load i64, i64* %arrayidx12.6, align 8, !tbaa !26
  store i64 %106, i64* %arrayidx12.5, align 8, !tbaa !26
  %107 = load i64, i64* %arrayidx.7, align 8, !tbaa !26
  store i64 %107, i64* %arrayidx.6, align 8, !tbaa !26
  %108 = load i64, i64* %arrayidx11.7, align 8, !tbaa !26
  store i64 %108, i64* %arrayidx11.6, align 8, !tbaa !26
  %109 = load i64, i64* %arrayidx12.7, align 8, !tbaa !26
  store i64 %109, i64* %arrayidx12.6, align 8, !tbaa !26
  %110 = load i64, i64* %arrayidx.8, align 8, !tbaa !26
  store i64 %110, i64* %arrayidx.7, align 8, !tbaa !26
  %111 = load i64, i64* %arrayidx11.8, align 8, !tbaa !26
  store i64 %111, i64* %arrayidx11.7, align 8, !tbaa !26
  %112 = load i64, i64* %arrayidx12.8, align 8, !tbaa !26
  store i64 %112, i64* %arrayidx12.7, align 8, !tbaa !26
  %113 = load i64, i64* %arrayidx.9, align 8, !tbaa !26
  store i64 %113, i64* %arrayidx.8, align 8, !tbaa !26
  %114 = load i64, i64* %arrayidx11.9, align 8, !tbaa !26
  store i64 %114, i64* %arrayidx11.8, align 8, !tbaa !26
  %115 = load i64, i64* %arrayidx12.9, align 8, !tbaa !26
  store i64 %115, i64* %arrayidx12.8, align 8, !tbaa !26
  %116 = load i64, i64* %arrayidx.10, align 8, !tbaa !26
  store i64 %116, i64* %arrayidx.9, align 8, !tbaa !26
  %117 = load i64, i64* %arrayidx11.10, align 8, !tbaa !26
  store i64 %117, i64* %arrayidx11.9, align 8, !tbaa !26
  %118 = load i64, i64* %arrayidx12.10, align 8, !tbaa !26
  store i64 %118, i64* %arrayidx12.9, align 8, !tbaa !26
  %119 = load i64, i64* %arrayidx.11, align 8, !tbaa !26
  store i64 %119, i64* %arrayidx.10, align 8, !tbaa !26
  %120 = load i64, i64* %arrayidx11.11, align 8, !tbaa !26
  store i64 %120, i64* %arrayidx11.10, align 8, !tbaa !26
  %121 = load i64, i64* %arrayidx12.11, align 8, !tbaa !26
  store i64 %121, i64* %arrayidx12.10, align 8, !tbaa !26
  %122 = load i64, i64* %arrayidx.12, align 8, !tbaa !26
  store i64 %122, i64* %arrayidx.11, align 8, !tbaa !26
  %123 = load i64, i64* %arrayidx11.12, align 8, !tbaa !26
  store i64 %123, i64* %arrayidx11.11, align 8, !tbaa !26
  %124 = load i64, i64* %arrayidx12.12, align 8, !tbaa !26
  store i64 %124, i64* %arrayidx12.11, align 8, !tbaa !26
  %125 = load i64, i64* %arrayidx.13, align 8, !tbaa !26
  store i64 %125, i64* %arrayidx.12, align 8, !tbaa !26
  %126 = load i64, i64* %arrayidx11.13, align 8, !tbaa !26
  store i64 %126, i64* %arrayidx11.12, align 8, !tbaa !26
  %127 = load i64, i64* %arrayidx12.13, align 8, !tbaa !26
  store i64 %127, i64* %arrayidx12.12, align 8, !tbaa !26
  %128 = load i64, i64* %arrayidx.14, align 8, !tbaa !26
  store i64 %128, i64* %arrayidx.13, align 8, !tbaa !26
  %129 = load i64, i64* %arrayidx11.14, align 8, !tbaa !26
  store i64 %129, i64* %arrayidx11.13, align 8, !tbaa !26
  %130 = load i64, i64* %arrayidx12.14, align 8, !tbaa !26
  store i64 %130, i64* %arrayidx12.13, align 8, !tbaa !26
  %131 = load i64, i64* %arrayidx.15, align 8, !tbaa !26
  store i64 %131, i64* %arrayidx.14, align 8, !tbaa !26
  %132 = load i64, i64* %arrayidx11.15, align 8, !tbaa !26
  store i64 %132, i64* %arrayidx11.14, align 8, !tbaa !26
  %133 = load i64, i64* %arrayidx12.15, align 8, !tbaa !26
  store i64 %133, i64* %arrayidx12.14, align 8, !tbaa !26
  store i64 1, i64* %arrayidx.15, align 8, !tbaa !26
  store i64 0, i64* %arrayidx11.15, align 8, !tbaa !26
  store i64 0, i64* %arrayidx12.15, align 8, !tbaa !26
  %cmp121 = icmp eq i64 %mul129, %90
  br i1 %cmp121, label %land.rhs, label %while.end, !llvm.loop !69

while.end:                                        ; preds = %while.body, %land.rhs, %while.cond.preheader, %for.cond49.preheader
  %134 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %agg.result to i8*
  call void @llvm.memcpy.p0i8.p0i8.i32(i8* nonnull align 8 dereferenceable(416) %134, i8* nonnull align 8 dereferenceable(416) %0, i32 416, i1 false), !tbaa.struct !70
  br label %cleanup

cleanup:                                          ; preds = %while.end, %if.then46, %if.then
  call void @llvm.lifetime.end.p0i8(i64 416, i8* nonnull %0) #11
  ret void
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %flags.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %0 = load i64, i64* %flags.i.i, align 8, !tbaa !44
  %and.i.i = and i64 %0, 2
  %cmp.i.i.not = icmp eq i64 %and.i.i, 0
  br i1 %cmp.i.i.not, label %return, label %if.end

if.end:                                           ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %and.i.i46 = and i64 %0, 1
  %cmp.i.i47.not = icmp eq i64 %and.i.i46, 0
  br i1 %cmp.i.i47.not, label %if.end9, label %return

if.end9:                                          ; preds = %if.end
  %cmp = icmp eq %struct.halide_device_interface_t* %1, null
  br i1 %cmp, label %return, label %if.end15

if.end15:                                         ; preds = %if.end9
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i32 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %copy_to_host = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i32 0, i32 6
  %3 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %copy_to_host, align 4, !tbaa !73
  %call16 = tail call i32 %3(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %cmp17.not = icmp eq i32 %call16, 0
  br i1 %cmp17.not, label %if.end23, label %return

if.end23:                                         ; preds = %if.end15
  %4 = load i64, i64* %flags.i.i, align 8, !tbaa !44
  %and.i.i44 = and i64 %4, -3
  store i64 %and.i.i44, i64* %flags.i.i, align 8, !tbaa !44
  %call24 = tail call i32 @halide_msan_annotate_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  br label %return

return:                                           ; preds = %if.end23, %if.end15, %if.end9, %if.end, %entry
  %retval.2 = phi i32 [ 0, %entry ], [ 0, %if.end23 ], [ -14, %if.end ], [ -19, %if.end9 ], [ -14, %if.end15 ]
  ret i32 %retval.2
}

; Function Attrs: nounwind mustprogress
define weak void @halide_device_release(i8* %user_context, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i32 0, i32 15
  %0 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_release = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %0, i32 0, i32 5
  %1 = load i32 (i8*)*, i32 (i8*)** %device_release, align 4, !tbaa !75
  %call = tail call i32 %1(i8* %user_context) #14
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_copy_to_host(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.6.17, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end16.i.split

if.end16.i.split:                                 ; preds = %if.end16.i
  %call11 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #15
  br label %cleanup

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %call12 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* %buf) #15
  br label %cleanup

cleanup:                                          ; preds = %if.end16.i.split, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ %call11, %if.end16.i.split ], [ %call12, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define linkonce i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.7.18, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %if.end, label %cleanup

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit, %if.end16.i
  %cmp1 = icmp eq %struct.halide_device_interface_t* %device_interface, null
  br i1 %cmp1, label %if.then2, label %if.end11

if.then2:                                         ; preds = %if.end
  %device_interface5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface5, align 8, !tbaa !42
  %cmp6 = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp6, label %if.then7, label %if.end11

if.then7:                                         ; preds = %if.then2
  %call8 = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %cleanup

if.end11:                                         ; preds = %if.then2, %if.end
  %device_interface.addr.0 = phi %struct.halide_device_interface_t* [ %device_interface, %if.end ], [ %4, %if.then2 ]
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %5 = load i64, i64* %device, align 8, !tbaa !40
  %tobool.not = icmp eq i64 %5, 0
  br i1 %tobool.not, label %if.then18, label %land.lhs.true

land.lhs.true:                                    ; preds = %if.end11
  %device_interface12 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %6 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface12, align 8, !tbaa !42
  %cmp13.not = icmp eq %struct.halide_device_interface_t* %6, %device_interface.addr.0
  br i1 %cmp13.not, label %if.end27, label %if.then14

if.then14:                                        ; preds = %land.lhs.true
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.9.19, i32 0, i32 0)) #14
  br label %cleanup

if.then18:                                        ; preds = %if.end11
  %call19 = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, %struct.halide_device_interface_t* nonnull %device_interface.addr.0) #15
  %cmp20.not = icmp eq i32 %call19, 0
  br i1 %cmp20.not, label %if.end27, label %cleanup

if.end27:                                         ; preds = %if.then18, %land.lhs.true
  %flags.i.i97 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %7 = load i64, i64* %flags.i.i97, align 8, !tbaa !44
  %and.i.i98 = and i64 %7, 1
  %cmp.i.i99.not = icmp eq i64 %and.i.i98, 0
  br i1 %cmp.i.i99.not, label %cleanup, label %if.then29

if.then29:                                        ; preds = %if.end27
  %and.i.i96 = and i64 %7, 2
  %cmp.i.i.not = icmp eq i64 %and.i.i96, 0
  br i1 %cmp.i.i.not, label %if.else, label %cleanup

if.else:                                          ; preds = %if.then29
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface.addr.0, i32 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %copy_to_device = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i32 0, i32 7
  %9 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %copy_to_device, align 4, !tbaa !76
  %call44 = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %cmp45 = icmp eq i32 %call44, 0
  br i1 %cmp45, label %if.then46, label %cleanup

if.then46:                                        ; preds = %if.else
  %10 = load i64, i64* %flags.i.i97, align 8, !tbaa !44
  %and.i.i = and i64 %10, -2
  store i64 %and.i.i, i64* %flags.i.i97, align 8, !tbaa !44
  br label %cleanup

cleanup:                                          ; preds = %if.then46, %if.else, %if.then29, %if.end27, %if.then18, %if.then14, %if.then7, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %call8, %if.then7 ], [ -42, %if.then14 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.then46 ], [ %call19, %if.then18 ], [ -15, %if.then29 ], [ -15, %if.else ], [ 0, %if.end27 ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.17.20, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface3.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface3.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp4.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp5.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp4.not, %cmp5.not
  br i1 %or.cond, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.20.21, i32 0, i32 0)) #14
  br label %cleanup12

if.end7:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_malloc = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 2
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_malloc, align 4, !tbaa !78
  %call9 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %tobool.not = icmp eq i32 %call9, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -16
  ret i32 %spec.select

cleanup12:                                        ; preds = %if.then6, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then6 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind
define weak i32 @halide_copy_to_device(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %call = tail call i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) #15
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_sync(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.16.22, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup8

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2 = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2, label %if.then3, label %if.end5

if.then3:                                         ; preds = %if.end
  %call4 = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %cleanup8

if.end5:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_sync = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 4
  %6 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_sync, align 4, !tbaa !80
  %call6 = tail call i32 %6(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %tobool.not = icmp eq i32 %call6, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -17
  ret i32 %spec.select

cleanup8:                                         ; preds = %if.then3, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ %call4, %if.then3 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.21.23, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %if.end11, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_free = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 3
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_free, align 4, !tbaa !81
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !40
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.22.24, i32 0, i32 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -18
  ret i32 %spec.select

if.end11:                                         ; preds = %if.end
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %12 = load i64, i64* %flags3.i.i, align 8, !tbaa !44
  %and.i.i = and i64 %12, -3
  store i64 %and.i.i, i64* %flags3.i.i, align 8, !tbaa !44
  br label %cleanup12

cleanup12:                                        ; preds = %if.end11, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end11 ]
  ret i32 %retval.1
}

declare void @abort() local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_device_free_as_destructor(i8* %user_context, i8* %obj) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %obj to %struct.halide_buffer_t*
  %call = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %0) #15
  ret void
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_and_host_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.23.25, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup14

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface3.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface3.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp4.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp5.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp4.not, %cmp5.not
  br i1 %or.cond, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.25.26, i32 0, i32 0)) #14
  br label %cleanup14

if.end7:                                          ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_and_host_malloc = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 8
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_and_host_malloc, align 4, !tbaa !82
  %call9 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %cmp11.not = icmp eq i32 %call9, 0
  br i1 %cmp11.not, label %cleanup14, label %if.then12

if.then12:                                        ; preds = %if.end7
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.26, i32 0, i32 0)) #14
  br label %cleanup14

cleanup14:                                        ; preds = %if.then12, %if.end7, %if.then6, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then6 ], [ -16, %if.then12 ], [ 0, %if.end7 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.27, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup18

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %if.else11, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_and_host_free = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 9
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_and_host_free, align 4, !tbaa !83
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !40
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.28, i32 0, i32 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -18
  ret i32 %spec.select

if.else11:                                        ; preds = %if.end
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 2
  %12 = load i8*, i8** %host, align 4, !tbaa !43
  %tobool12.not = icmp eq i8* %12, null
  br i1 %tobool12.not, label %if.end17, label %if.then13

if.then13:                                        ; preds = %if.else11
  tail call void @halide_free(i8* %user_context, i8* nonnull %12) #14
  store i8* null, i8** %host, align 4, !tbaa !43
  br label %if.end17

if.end17:                                         ; preds = %if.then13, %if.else11
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %13 = load i64, i64* %flags3.i.i, align 8, !tbaa !44
  %and.i.i = and i64 %13, -3
  store i64 %and.i.i, i64* %flags3.i.i, align 8, !tbaa !44
  br label %cleanup18

cleanup18:                                        ; preds = %if.end17, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end17 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_and_host_malloc(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.29, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %if.end, label %cleanup13

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit, %if.end16.i
  %dimensions.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 5
  %4 = load i32, i32* %dimensions.i.i, align 4, !tbaa !45
  %cmp16.i.i = icmp sgt i32 %4, 0
  br i1 %cmp16.i.i, label %for.body.lr.ph.i.i, label %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge

if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge: ; preds = %if.end
  %sub.i.0 = sub nsw i32 1, 0
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

for.body.lr.ph.i.i:                               ; preds = %if.end
  %dim.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 6
  %5 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i.i, align 8, !tbaa !46
  %6 = add i32 %4, -1
  %xtraiter = and i32 %4, 7
  %7 = icmp ult i32 %6, 7
  br i1 %7, label %for.body.i11.i.preheader.unr-lcssa, label %for.body.lr.ph.i.i.new

for.body.lr.ph.i.i.new:                           ; preds = %for.body.lr.ph.i.i
  %unroll_iter = and i32 %4, -8
  br label %for.body.i.i

for.body.i.i:                                     ; preds = %if.end.i.i.7, %for.body.lr.ph.i.i.new
  %index.019.i.i = phi i32 [ 0, %for.body.lr.ph.i.i.new ], [ %index.1.i.i.7, %if.end.i.i.7 ]
  %i.017.i.i = phi i32 [ 0, %for.body.lr.ph.i.i.new ], [ %inc.i.i.7, %if.end.i.i.7 ]
  %niter = phi i32 [ %unroll_iter, %for.body.lr.ph.i.i.new ], [ %niter.nsub.7, %if.end.i.i.7 ]
  %stride2.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.017.i.i, i32 2
  %8 = load i32, i32* %stride2.i.i, align 4, !tbaa !50
  %cmp3.i.i = icmp sgt i32 %8, 0
  br i1 %cmp3.i.i, label %if.then.i.i, label %if.end.i.i

if.then.i.i:                                      ; preds = %for.body.i.i
  %extent.i.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.017.i.i, i32 1
  %9 = load i32, i32* %extent.i.i, align 4, !tbaa !49
  %sub.i.i = add nsw i32 %9, -1
  %mul.i.i = mul nsw i32 %sub.i.i, %8
  %add.i.i = add nsw i32 %mul.i.i, %index.019.i.i
  br label %if.end.i.i

if.end.i.i:                                       ; preds = %if.then.i.i, %for.body.i.i
  %index.1.i.i = phi i32 [ %add.i.i, %if.then.i.i ], [ %index.019.i.i, %for.body.i.i ]
  %inc.i.i = or i32 %i.017.i.i, 1
  %stride2.i.i.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i, i32 2
  %10 = load i32, i32* %stride2.i.i.1, align 4, !tbaa !50
  %cmp3.i.i.1 = icmp sgt i32 %10, 0
  br i1 %cmp3.i.i.1, label %if.then.i.i.1, label %if.end.i.i.1

for.body.i11.i.preheader.unr-lcssa:               ; preds = %if.end.i.i.7, %for.body.lr.ph.i.i
  %index.1.i.i.lcssa.ph = phi i32 [ undef, %for.body.lr.ph.i.i ], [ %index.1.i.i.7, %if.end.i.i.7 ]
  %index.019.i.i.unr = phi i32 [ 0, %for.body.lr.ph.i.i ], [ %index.1.i.i.7, %if.end.i.i.7 ]
  %i.017.i.i.unr = phi i32 [ 0, %for.body.lr.ph.i.i ], [ %inc.i.i.7, %if.end.i.i.7 ]
  %lcmp.mod.not = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod.not, label %for.body.i11.i.preheader, label %for.body.i.i.epil

for.body.i.i.epil:                                ; preds = %for.body.i11.i.preheader.unr-lcssa, %if.end.i.i.epil
  %index.019.i.i.epil = phi i32 [ %index.1.i.i.epil, %if.end.i.i.epil ], [ %index.019.i.i.unr, %for.body.i11.i.preheader.unr-lcssa ]
  %i.017.i.i.epil = phi i32 [ %inc.i.i.epil, %if.end.i.i.epil ], [ %i.017.i.i.unr, %for.body.i11.i.preheader.unr-lcssa ]
  %epil.iter = phi i32 [ %epil.iter.sub, %if.end.i.i.epil ], [ %xtraiter, %for.body.i11.i.preheader.unr-lcssa ]
  %stride2.i.i.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.017.i.i.epil, i32 2
  %11 = load i32, i32* %stride2.i.i.epil, align 4, !tbaa !50
  %cmp3.i.i.epil = icmp sgt i32 %11, 0
  br i1 %cmp3.i.i.epil, label %if.then.i.i.epil, label %if.end.i.i.epil

if.then.i.i.epil:                                 ; preds = %for.body.i.i.epil
  %extent.i.i.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.017.i.i.epil, i32 1
  %12 = load i32, i32* %extent.i.i.epil, align 4, !tbaa !49
  %sub.i.i.epil = add nsw i32 %12, -1
  %mul.i.i.epil = mul nsw i32 %sub.i.i.epil, %11
  %add.i.i.epil = add nsw i32 %mul.i.i.epil, %index.019.i.i.epil
  br label %if.end.i.i.epil

if.end.i.i.epil:                                  ; preds = %if.then.i.i.epil, %for.body.i.i.epil
  %index.1.i.i.epil = phi i32 [ %add.i.i.epil, %if.then.i.i.epil ], [ %index.019.i.i.epil, %for.body.i.i.epil ]
  %inc.i.i.epil = add nuw nsw i32 %i.017.i.i.epil, 1
  %epil.iter.sub = add i32 %epil.iter, -1
  %epil.iter.cmp.not = icmp eq i32 %epil.iter.sub, 0
  br i1 %epil.iter.cmp.not, label %for.body.i11.i.preheader, label %for.body.i.i.epil, !llvm.loop !84

for.body.i11.i.preheader:                         ; preds = %if.end.i.i.epil, %for.body.i11.i.preheader.unr-lcssa
  %index.1.i.i.lcssa = phi i32 [ %index.1.i.i.lcssa.ph, %for.body.i11.i.preheader.unr-lcssa ], [ %index.1.i.i.epil, %if.end.i.i.epil ]
  %13 = add i32 %4, -1
  %xtraiter5 = and i32 %4, 7
  %14 = icmp ult i32 %13, 7
  br i1 %14, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa, label %for.body.i11.i.preheader.new

for.body.i11.i.preheader.new:                     ; preds = %for.body.i11.i.preheader
  %unroll_iter9 = and i32 %4, -8
  br label %for.body.i11.i

for.body.i11.i:                                   ; preds = %if.end.i20.i.7, %for.body.i11.i.preheader.new
  %index.017.i.i = phi i32 [ 0, %for.body.i11.i.preheader.new ], [ %index.1.i17.i.7, %if.end.i20.i.7 ]
  %i.015.i.i = phi i32 [ 0, %for.body.i11.i.preheader.new ], [ %inc.i18.i.7, %if.end.i20.i.7 ]
  %niter10 = phi i32 [ %unroll_iter9, %for.body.i11.i.preheader.new ], [ %niter10.nsub.7, %if.end.i20.i.7 ]
  %stride2.i9.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.015.i.i, i32 2
  %15 = load i32, i32* %stride2.i9.i, align 4, !tbaa !50
  %cmp3.i10.i = icmp slt i32 %15, 0
  br i1 %cmp3.i10.i, label %if.then.i16.i, label %if.end.i20.i

if.then.i16.i:                                    ; preds = %for.body.i11.i
  %extent.i12.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.015.i.i, i32 1
  %16 = load i32, i32* %extent.i12.i, align 4, !tbaa !49
  %sub.i13.i = add nsw i32 %16, -1
  %mul.i14.i = mul nsw i32 %sub.i13.i, %15
  %add.i15.i = add nsw i32 %mul.i14.i, %index.017.i.i
  br label %if.end.i20.i

if.end.i20.i:                                     ; preds = %if.then.i16.i, %for.body.i11.i
  %index.1.i17.i = phi i32 [ %add.i15.i, %if.then.i16.i ], [ %index.017.i.i, %for.body.i11.i ]
  %inc.i18.i = or i32 %i.015.i.i, 1
  %stride2.i9.i.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i, i32 2
  %17 = load i32, i32* %stride2.i9.i.1, align 4, !tbaa !50
  %cmp3.i10.i.1 = icmp slt i32 %17, 0
  br i1 %cmp3.i10.i.1, label %if.then.i16.i.1, label %if.end.i20.i.1

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa: ; preds = %if.end.i20.i.7, %for.body.i11.i.preheader
  %index.1.i17.i.lcssa.ph = phi i32 [ undef, %for.body.i11.i.preheader ], [ %index.1.i17.i.7, %if.end.i20.i.7 ]
  %index.017.i.i.unr = phi i32 [ 0, %for.body.i11.i.preheader ], [ %index.1.i17.i.7, %if.end.i20.i.7 ]
  %i.015.i.i.unr = phi i32 [ 0, %for.body.i11.i.preheader ], [ %inc.i18.i.7, %if.end.i20.i.7 ]
  %lcmp.mod7.not = icmp eq i32 %xtraiter5, 0
  br i1 %lcmp.mod7.not, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i11.i.epil

for.body.i11.i.epil:                              ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa, %if.end.i20.i.epil
  %index.017.i.i.epil = phi i32 [ %index.1.i17.i.epil, %if.end.i20.i.epil ], [ %index.017.i.i.unr, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa ]
  %i.015.i.i.epil = phi i32 [ %inc.i18.i.epil, %if.end.i20.i.epil ], [ %i.015.i.i.unr, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa ]
  %epil.iter6 = phi i32 [ %epil.iter6.sub, %if.end.i20.i.epil ], [ %xtraiter5, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa ]
  %stride2.i9.i.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.015.i.i.epil, i32 2
  %18 = load i32, i32* %stride2.i9.i.epil, align 4, !tbaa !50
  %cmp3.i10.i.epil = icmp slt i32 %18, 0
  br i1 %cmp3.i10.i.epil, label %if.then.i16.i.epil, label %if.end.i20.i.epil

if.then.i16.i.epil:                               ; preds = %for.body.i11.i.epil
  %extent.i12.i.epil = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %i.015.i.i.epil, i32 1
  %19 = load i32, i32* %extent.i12.i.epil, align 4, !tbaa !49
  %sub.i13.i.epil = add nsw i32 %19, -1
  %mul.i14.i.epil = mul nsw i32 %sub.i13.i.epil, %18
  %add.i15.i.epil = add nsw i32 %mul.i14.i.epil, %index.017.i.i.epil
  br label %if.end.i20.i.epil

if.end.i20.i.epil:                                ; preds = %if.then.i16.i.epil, %for.body.i11.i.epil
  %index.1.i17.i.epil = phi i32 [ %add.i15.i.epil, %if.then.i16.i.epil ], [ %index.017.i.i.epil, %for.body.i11.i.epil ]
  %inc.i18.i.epil = add nuw nsw i32 %i.015.i.i.epil, 1
  %epil.iter6.sub = add i32 %epil.iter6, -1
  %epil.iter6.cmp.not = icmp eq i32 %epil.iter6.sub, 0
  br i1 %epil.iter6.cmp.not, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit, label %for.body.i11.i.epil, !llvm.loop !85

_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit: ; preds = %if.end.i20.i.epil, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa
  %index.1.i17.i.lcssa = phi i32 [ %index.1.i17.i.lcssa.ph, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa ], [ %index.1.i17.i.epil, %if.end.i20.i.epil ]
  %add6.i.i = add nsw i32 %index.1.i.i.lcssa, 1
  %sub.i.1 = sub nsw i32 %add6.i.i, %index.1.i17.i.lcssa
  br label %_ZNK15halide_buffer_t13size_in_bytesEv.exit

_ZNK15halide_buffer_t13size_in_bytesEv.exit:      ; preds = %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit
  %sub.i.phi = phi i32 [ %sub.i.0, %if.end._ZNK15halide_buffer_t13size_in_bytesEv.exit_crit_edge ], [ %sub.i.1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit ]
  %bits.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 4, i32 1
  %20 = load i8, i8* %bits.i.i, align 1, !tbaa !38
  %conv.i.i = zext i8 %20 to i32
  %add.i4.i = add nuw nsw i32 %conv.i.i, 7
  %div.i.i = lshr i32 %add.i4.i, 3
  %mul.i = mul i32 %div.i.i, %sub.i.phi
  %call2 = tail call i8* @halide_malloc(i8* %user_context, i32 %mul.i) #14
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 2
  store i8* %call2, i8** %host, align 4, !tbaa !43
  %cmp4 = icmp eq i8* %call2, null
  br i1 %cmp4, label %cleanup13, label %if.end6

if.end6:                                          ; preds = %_ZNK15halide_buffer_t13size_in_bytesEv.exit
  %call7 = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, %struct.halide_device_interface_t* %device_interface) #15
  %cmp8.not = icmp eq i32 %call7, 0
  br i1 %cmp8.not, label %cleanup13, label %if.then9

if.then9:                                         ; preds = %if.end6
  %21 = load i8*, i8** %host, align 4, !tbaa !43
  tail call void @halide_free(i8* %user_context, i8* %21) #14
  store i8* null, i8** %host, align 4, !tbaa !43
  br label %cleanup13

cleanup13:                                        ; preds = %if.then9, %if.end6, %_ZNK15halide_buffer_t13size_in_bytesEv.exit, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -1, %_ZNK15halide_buffer_t13size_in_bytesEv.exit ], [ %call7, %if.then9 ], [ 0, %if.end6 ]
  ret i32 %retval.1

if.then.i.i.1:                                    ; preds = %if.end.i.i
  %extent.i.i.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i, i32 1
  %22 = load i32, i32* %extent.i.i.1, align 4, !tbaa !49
  %sub.i.i.1 = add nsw i32 %22, -1
  %mul.i.i.1 = mul nsw i32 %sub.i.i.1, %10
  %add.i.i.1 = add nsw i32 %mul.i.i.1, %index.1.i.i
  br label %if.end.i.i.1

if.end.i.i.1:                                     ; preds = %if.then.i.i.1, %if.end.i.i
  %index.1.i.i.1 = phi i32 [ %add.i.i.1, %if.then.i.i.1 ], [ %index.1.i.i, %if.end.i.i ]
  %inc.i.i.1 = or i32 %i.017.i.i, 2
  %stride2.i.i.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.1, i32 2
  %23 = load i32, i32* %stride2.i.i.2, align 4, !tbaa !50
  %cmp3.i.i.2 = icmp sgt i32 %23, 0
  br i1 %cmp3.i.i.2, label %if.then.i.i.2, label %if.end.i.i.2

if.then.i.i.2:                                    ; preds = %if.end.i.i.1
  %extent.i.i.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.1, i32 1
  %24 = load i32, i32* %extent.i.i.2, align 4, !tbaa !49
  %sub.i.i.2 = add nsw i32 %24, -1
  %mul.i.i.2 = mul nsw i32 %sub.i.i.2, %23
  %add.i.i.2 = add nsw i32 %mul.i.i.2, %index.1.i.i.1
  br label %if.end.i.i.2

if.end.i.i.2:                                     ; preds = %if.then.i.i.2, %if.end.i.i.1
  %index.1.i.i.2 = phi i32 [ %add.i.i.2, %if.then.i.i.2 ], [ %index.1.i.i.1, %if.end.i.i.1 ]
  %inc.i.i.2 = or i32 %i.017.i.i, 3
  %stride2.i.i.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.2, i32 2
  %25 = load i32, i32* %stride2.i.i.3, align 4, !tbaa !50
  %cmp3.i.i.3 = icmp sgt i32 %25, 0
  br i1 %cmp3.i.i.3, label %if.then.i.i.3, label %if.end.i.i.3

if.then.i.i.3:                                    ; preds = %if.end.i.i.2
  %extent.i.i.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.2, i32 1
  %26 = load i32, i32* %extent.i.i.3, align 4, !tbaa !49
  %sub.i.i.3 = add nsw i32 %26, -1
  %mul.i.i.3 = mul nsw i32 %sub.i.i.3, %25
  %add.i.i.3 = add nsw i32 %mul.i.i.3, %index.1.i.i.2
  br label %if.end.i.i.3

if.end.i.i.3:                                     ; preds = %if.then.i.i.3, %if.end.i.i.2
  %index.1.i.i.3 = phi i32 [ %add.i.i.3, %if.then.i.i.3 ], [ %index.1.i.i.2, %if.end.i.i.2 ]
  %inc.i.i.3 = or i32 %i.017.i.i, 4
  %stride2.i.i.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.3, i32 2
  %27 = load i32, i32* %stride2.i.i.4, align 4, !tbaa !50
  %cmp3.i.i.4 = icmp sgt i32 %27, 0
  br i1 %cmp3.i.i.4, label %if.then.i.i.4, label %if.end.i.i.4

if.then.i.i.4:                                    ; preds = %if.end.i.i.3
  %extent.i.i.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.3, i32 1
  %28 = load i32, i32* %extent.i.i.4, align 4, !tbaa !49
  %sub.i.i.4 = add nsw i32 %28, -1
  %mul.i.i.4 = mul nsw i32 %sub.i.i.4, %27
  %add.i.i.4 = add nsw i32 %mul.i.i.4, %index.1.i.i.3
  br label %if.end.i.i.4

if.end.i.i.4:                                     ; preds = %if.then.i.i.4, %if.end.i.i.3
  %index.1.i.i.4 = phi i32 [ %add.i.i.4, %if.then.i.i.4 ], [ %index.1.i.i.3, %if.end.i.i.3 ]
  %inc.i.i.4 = or i32 %i.017.i.i, 5
  %stride2.i.i.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.4, i32 2
  %29 = load i32, i32* %stride2.i.i.5, align 4, !tbaa !50
  %cmp3.i.i.5 = icmp sgt i32 %29, 0
  br i1 %cmp3.i.i.5, label %if.then.i.i.5, label %if.end.i.i.5

if.then.i.i.5:                                    ; preds = %if.end.i.i.4
  %extent.i.i.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.4, i32 1
  %30 = load i32, i32* %extent.i.i.5, align 4, !tbaa !49
  %sub.i.i.5 = add nsw i32 %30, -1
  %mul.i.i.5 = mul nsw i32 %sub.i.i.5, %29
  %add.i.i.5 = add nsw i32 %mul.i.i.5, %index.1.i.i.4
  br label %if.end.i.i.5

if.end.i.i.5:                                     ; preds = %if.then.i.i.5, %if.end.i.i.4
  %index.1.i.i.5 = phi i32 [ %add.i.i.5, %if.then.i.i.5 ], [ %index.1.i.i.4, %if.end.i.i.4 ]
  %inc.i.i.5 = or i32 %i.017.i.i, 6
  %stride2.i.i.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.5, i32 2
  %31 = load i32, i32* %stride2.i.i.6, align 4, !tbaa !50
  %cmp3.i.i.6 = icmp sgt i32 %31, 0
  br i1 %cmp3.i.i.6, label %if.then.i.i.6, label %if.end.i.i.6

if.then.i.i.6:                                    ; preds = %if.end.i.i.5
  %extent.i.i.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.5, i32 1
  %32 = load i32, i32* %extent.i.i.6, align 4, !tbaa !49
  %sub.i.i.6 = add nsw i32 %32, -1
  %mul.i.i.6 = mul nsw i32 %sub.i.i.6, %31
  %add.i.i.6 = add nsw i32 %mul.i.i.6, %index.1.i.i.5
  br label %if.end.i.i.6

if.end.i.i.6:                                     ; preds = %if.then.i.i.6, %if.end.i.i.5
  %index.1.i.i.6 = phi i32 [ %add.i.i.6, %if.then.i.i.6 ], [ %index.1.i.i.5, %if.end.i.i.5 ]
  %inc.i.i.6 = or i32 %i.017.i.i, 7
  %stride2.i.i.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.6, i32 2
  %33 = load i32, i32* %stride2.i.i.7, align 4, !tbaa !50
  %cmp3.i.i.7 = icmp sgt i32 %33, 0
  br i1 %cmp3.i.i.7, label %if.then.i.i.7, label %if.end.i.i.7

if.then.i.i.7:                                    ; preds = %if.end.i.i.6
  %extent.i.i.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i.i.6, i32 1
  %34 = load i32, i32* %extent.i.i.7, align 4, !tbaa !49
  %sub.i.i.7 = add nsw i32 %34, -1
  %mul.i.i.7 = mul nsw i32 %sub.i.i.7, %33
  %add.i.i.7 = add nsw i32 %mul.i.i.7, %index.1.i.i.6
  br label %if.end.i.i.7

if.end.i.i.7:                                     ; preds = %if.then.i.i.7, %if.end.i.i.6
  %index.1.i.i.7 = phi i32 [ %add.i.i.7, %if.then.i.i.7 ], [ %index.1.i.i.6, %if.end.i.i.6 ]
  %inc.i.i.7 = add nuw nsw i32 %i.017.i.i, 8
  %niter.nsub.7 = add i32 %niter, -8
  %niter.ncmp.7 = icmp eq i32 %niter.nsub.7, 0
  br i1 %niter.ncmp.7, label %for.body.i11.i.preheader.unr-lcssa, label %for.body.i.i, !llvm.loop !86

if.then.i16.i.1:                                  ; preds = %if.end.i20.i
  %extent.i12.i.1 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i, i32 1
  %35 = load i32, i32* %extent.i12.i.1, align 4, !tbaa !49
  %sub.i13.i.1 = add nsw i32 %35, -1
  %mul.i14.i.1 = mul nsw i32 %sub.i13.i.1, %17
  %add.i15.i.1 = add nsw i32 %mul.i14.i.1, %index.1.i17.i
  br label %if.end.i20.i.1

if.end.i20.i.1:                                   ; preds = %if.then.i16.i.1, %if.end.i20.i
  %index.1.i17.i.1 = phi i32 [ %add.i15.i.1, %if.then.i16.i.1 ], [ %index.1.i17.i, %if.end.i20.i ]
  %inc.i18.i.1 = or i32 %i.015.i.i, 2
  %stride2.i9.i.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.1, i32 2
  %36 = load i32, i32* %stride2.i9.i.2, align 4, !tbaa !50
  %cmp3.i10.i.2 = icmp slt i32 %36, 0
  br i1 %cmp3.i10.i.2, label %if.then.i16.i.2, label %if.end.i20.i.2

if.then.i16.i.2:                                  ; preds = %if.end.i20.i.1
  %extent.i12.i.2 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.1, i32 1
  %37 = load i32, i32* %extent.i12.i.2, align 4, !tbaa !49
  %sub.i13.i.2 = add nsw i32 %37, -1
  %mul.i14.i.2 = mul nsw i32 %sub.i13.i.2, %36
  %add.i15.i.2 = add nsw i32 %mul.i14.i.2, %index.1.i17.i.1
  br label %if.end.i20.i.2

if.end.i20.i.2:                                   ; preds = %if.then.i16.i.2, %if.end.i20.i.1
  %index.1.i17.i.2 = phi i32 [ %add.i15.i.2, %if.then.i16.i.2 ], [ %index.1.i17.i.1, %if.end.i20.i.1 ]
  %inc.i18.i.2 = or i32 %i.015.i.i, 3
  %stride2.i9.i.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.2, i32 2
  %38 = load i32, i32* %stride2.i9.i.3, align 4, !tbaa !50
  %cmp3.i10.i.3 = icmp slt i32 %38, 0
  br i1 %cmp3.i10.i.3, label %if.then.i16.i.3, label %if.end.i20.i.3

if.then.i16.i.3:                                  ; preds = %if.end.i20.i.2
  %extent.i12.i.3 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.2, i32 1
  %39 = load i32, i32* %extent.i12.i.3, align 4, !tbaa !49
  %sub.i13.i.3 = add nsw i32 %39, -1
  %mul.i14.i.3 = mul nsw i32 %sub.i13.i.3, %38
  %add.i15.i.3 = add nsw i32 %mul.i14.i.3, %index.1.i17.i.2
  br label %if.end.i20.i.3

if.end.i20.i.3:                                   ; preds = %if.then.i16.i.3, %if.end.i20.i.2
  %index.1.i17.i.3 = phi i32 [ %add.i15.i.3, %if.then.i16.i.3 ], [ %index.1.i17.i.2, %if.end.i20.i.2 ]
  %inc.i18.i.3 = or i32 %i.015.i.i, 4
  %stride2.i9.i.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.3, i32 2
  %40 = load i32, i32* %stride2.i9.i.4, align 4, !tbaa !50
  %cmp3.i10.i.4 = icmp slt i32 %40, 0
  br i1 %cmp3.i10.i.4, label %if.then.i16.i.4, label %if.end.i20.i.4

if.then.i16.i.4:                                  ; preds = %if.end.i20.i.3
  %extent.i12.i.4 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.3, i32 1
  %41 = load i32, i32* %extent.i12.i.4, align 4, !tbaa !49
  %sub.i13.i.4 = add nsw i32 %41, -1
  %mul.i14.i.4 = mul nsw i32 %sub.i13.i.4, %40
  %add.i15.i.4 = add nsw i32 %mul.i14.i.4, %index.1.i17.i.3
  br label %if.end.i20.i.4

if.end.i20.i.4:                                   ; preds = %if.then.i16.i.4, %if.end.i20.i.3
  %index.1.i17.i.4 = phi i32 [ %add.i15.i.4, %if.then.i16.i.4 ], [ %index.1.i17.i.3, %if.end.i20.i.3 ]
  %inc.i18.i.4 = or i32 %i.015.i.i, 5
  %stride2.i9.i.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.4, i32 2
  %42 = load i32, i32* %stride2.i9.i.5, align 4, !tbaa !50
  %cmp3.i10.i.5 = icmp slt i32 %42, 0
  br i1 %cmp3.i10.i.5, label %if.then.i16.i.5, label %if.end.i20.i.5

if.then.i16.i.5:                                  ; preds = %if.end.i20.i.4
  %extent.i12.i.5 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.4, i32 1
  %43 = load i32, i32* %extent.i12.i.5, align 4, !tbaa !49
  %sub.i13.i.5 = add nsw i32 %43, -1
  %mul.i14.i.5 = mul nsw i32 %sub.i13.i.5, %42
  %add.i15.i.5 = add nsw i32 %mul.i14.i.5, %index.1.i17.i.4
  br label %if.end.i20.i.5

if.end.i20.i.5:                                   ; preds = %if.then.i16.i.5, %if.end.i20.i.4
  %index.1.i17.i.5 = phi i32 [ %add.i15.i.5, %if.then.i16.i.5 ], [ %index.1.i17.i.4, %if.end.i20.i.4 ]
  %inc.i18.i.5 = or i32 %i.015.i.i, 6
  %stride2.i9.i.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.5, i32 2
  %44 = load i32, i32* %stride2.i9.i.6, align 4, !tbaa !50
  %cmp3.i10.i.6 = icmp slt i32 %44, 0
  br i1 %cmp3.i10.i.6, label %if.then.i16.i.6, label %if.end.i20.i.6

if.then.i16.i.6:                                  ; preds = %if.end.i20.i.5
  %extent.i12.i.6 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.5, i32 1
  %45 = load i32, i32* %extent.i12.i.6, align 4, !tbaa !49
  %sub.i13.i.6 = add nsw i32 %45, -1
  %mul.i14.i.6 = mul nsw i32 %sub.i13.i.6, %44
  %add.i15.i.6 = add nsw i32 %mul.i14.i.6, %index.1.i17.i.5
  br label %if.end.i20.i.6

if.end.i20.i.6:                                   ; preds = %if.then.i16.i.6, %if.end.i20.i.5
  %index.1.i17.i.6 = phi i32 [ %add.i15.i.6, %if.then.i16.i.6 ], [ %index.1.i17.i.5, %if.end.i20.i.5 ]
  %inc.i18.i.6 = or i32 %i.015.i.i, 7
  %stride2.i9.i.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.6, i32 2
  %46 = load i32, i32* %stride2.i9.i.7, align 4, !tbaa !50
  %cmp3.i10.i.7 = icmp slt i32 %46, 0
  br i1 %cmp3.i10.i.7, label %if.then.i16.i.7, label %if.end.i20.i.7

if.then.i16.i.7:                                  ; preds = %if.end.i20.i.6
  %extent.i12.i.7 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %5, i32 %inc.i18.i.6, i32 1
  %47 = load i32, i32* %extent.i12.i.7, align 4, !tbaa !49
  %sub.i13.i.7 = add nsw i32 %47, -1
  %mul.i14.i.7 = mul nsw i32 %sub.i13.i.7, %46
  %add.i15.i.7 = add nsw i32 %mul.i14.i.7, %index.1.i17.i.6
  br label %if.end.i20.i.7

if.end.i20.i.7:                                   ; preds = %if.then.i16.i.7, %if.end.i20.i.6
  %index.1.i17.i.7 = phi i32 [ %add.i15.i.7, %if.then.i16.i.7 ], [ %index.1.i17.i.6, %if.end.i20.i.6 ]
  %inc.i18.i.7 = add nuw nsw i32 %i.015.i.i, 8
  %niter10.nsub.7 = add i32 %niter10, -8
  %niter10.ncmp.7 = icmp eq i32 %niter10.nsub.7, 0
  br i1 %niter10.ncmp.7, label %_ZNK15halide_buffer_t13size_in_bytesEv.exit.loopexit.unr-lcssa, label %for.body.i11.i, !llvm.loop !87
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %buf, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.30, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end16.i.split

if.end16.i.split:                                 ; preds = %if.end16.i
  %call11 = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #15
  br label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %call12 = tail call i32 @halide_device_free(i8* %user_context, %struct.halide_buffer_t* %buf) #15
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split, %if.end16.i.split
  %phi.call = phi i32 [ %call11, %if.end16.i.split ], [ %call12, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.split ]
  %host = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 2
  %4 = load i8*, i8** %host, align 4, !tbaa !43
  %tobool.not = icmp eq i8* %4, null
  br i1 %tobool.not, label %if.end5, label %if.then2

if.then2:                                         ; preds = %if.end
  tail call void @halide_free(i8* %user_context, i8* nonnull %4) #14
  store i8* null, i8** %host, align 4, !tbaa !43
  br label %if.end5

if.end5:                                          ; preds = %if.then2, %if.end
  %flags3.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %5 = load i64, i64* %flags3.i.i, align 8, !tbaa !44
  %and.i.i18 = and i64 %5, -4
  store i64 %and.i.i18, i64* %flags3.i.i, align 8, !tbaa !44
  br label %cleanup

cleanup:                                          ; preds = %if.end5, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %phi.call, %if.end5 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_wrap_native(i8* %user_context, %struct.halide_buffer_t* %buf, i64 %handle, %struct.halide_device_interface_t* %device_interface) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.31, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup12

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  %cmp3.not = icmp eq %struct.halide_device_interface_t* %4, %device_interface
  %or.cond = or i1 %cmp2.not, %cmp3.not
  br i1 %or.cond, label %if.end5, label %if.then4

if.then4:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.32, i32 0, i32 0)) #14
  br label %cleanup12

if.end5:                                          ; preds = %if.end
  %device_interface1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %device_interface, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  store %struct.halide_device_interface_t* %device_interface, %struct.halide_device_interface_t** %device_interface1, align 8, !tbaa !42
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %wrap_native = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 14
  %8 = load i32 (i8*, %struct.halide_buffer_t*, i64)*, i32 (i8*, %struct.halide_buffer_t*, i64)** %wrap_native, align 4, !tbaa !88
  %call8 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf, i64 %handle) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %tobool.not = icmp eq i32 %call8, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -16
  ret i32 %spec.select

cleanup12:                                        ; preds = %if.then4, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.1 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ -42, %if.then4 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_device_detach_native(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.33, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device_interface1.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %.pre = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface1.phi.trans.insert, align 8, !tbaa !42
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi %struct.halide_device_interface_t* [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %0, %if.end16.i ]
  %cmp2.not = icmp eq %struct.halide_device_interface_t* %4, null
  br i1 %cmp2.not, label %cleanup, label %if.then3

if.then3:                                         ; preds = %if.end
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %detach_native = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %7, i32 0, i32 15
  %8 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %detach_native, align 4, !tbaa !89
  %call5 = tail call i32 %8(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  %9 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %9, i32 0, i32 1
  %10 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %10() #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %11 = load i64, i64* %device, align 8, !tbaa !40
  %cmp7 = icmp eq i64 %11, 0
  br i1 %cmp7, label %do.end, label %if.then8

if.then8:                                         ; preds = %if.then3
  tail call void @halide_print(i8* %user_context, i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.34, i32 0, i32 0)) #14
  tail call void @abort() #14
  br label %do.end

do.end:                                           ; preds = %if.then8, %if.then3
  %tobool.not = icmp eq i32 %call5, 0
  %spec.select = select i1 %tobool.not, i32 0, i32 -33
  ret i32 %spec.select

cleanup:                                          ; preds = %if.end, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_wrap_native(i8* %user_context, %struct.halide_buffer_t* %buf, i64 %handle) local_unnamed_addr #0 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %cmp.not = icmp eq i64 %0, 0
  br i1 %cmp.not, label %if.end, label %return

if.end:                                           ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i32 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i32 0, i32 0
  %3 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %3() #14
  store i64 %handle, i64* %device, align 8, !tbaa !40
  br label %return

return:                                           ; preds = %if.end, %entry
  %retval.0 = phi i32 [ 0, %if.end ], [ -32, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_detach_native(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %cmp.i = icmp eq %struct.halide_buffer_t* %buf, null
  br i1 %cmp.i, label %if.then.i, label %if.end.i

if.then.i:                                        ; preds = %entry
  %call.i = tail call i32 @halide_error_buffer_is_null(i8* %user_context, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.35, i32 0, i32 0)) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end.i:                                         ; preds = %entry
  %device_interface.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface.i, align 8, !tbaa !42
  %cmp4.not.i = icmp eq %struct.halide_device_interface_t* %0, null
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %1 = load i64, i64* %device.i, align 8, !tbaa !40
  %cmp5.not.i = icmp eq i64 %1, 0
  %cmp4.not.not.i = xor i1 %cmp4.not.i, true
  %brmerge.i = or i1 %cmp5.not.i, %cmp4.not.not.i
  br i1 %brmerge.i, label %if.end10.i, label %if.then8.i

if.then8.i:                                       ; preds = %if.end.i
  %call9.i = tail call i32 @halide_error_no_device_interface(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end10.i:                                       ; preds = %if.end.i
  %cmp5.not.not.i = xor i1 %cmp5.not.i, true
  %brmerge44.i = or i1 %cmp4.not.i, %cmp5.not.not.i
  br i1 %brmerge44.i, label %if.end16.i, label %if.then14.i

if.then14.i:                                      ; preds = %if.end10.i
  %call15.i = tail call i32 @halide_error_device_interface_no_device(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

if.end16.i:                                       ; preds = %if.end10.i
  %flags.i.i46.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 3
  %2 = load i64, i64* %flags.i.i46.i, align 8, !tbaa !44
  %3 = and i64 %2, 3
  %.not.i = icmp eq i64 %3, 3
  br i1 %.not.i, label %if.then24.i, label %if.end

if.then24.i:                                      ; preds = %if.end16.i
  %call25.i = tail call i32 @halide_error_host_and_device_dirty(i8* %user_context) #14
  br label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit: ; preds = %if.then24.i, %if.then14.i, %if.then8.i, %if.then.i
  %retval.2.i = phi i32 [ %call.i, %if.then.i ], [ %call15.i, %if.then14.i ], [ %call9.i, %if.then8.i ], [ %call25.i, %if.then24.i ]
  %cmp.not = icmp eq i32 %retval.2.i, 0
  br i1 %cmp.not, label %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, label %cleanup

_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge: ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %device.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %.pre = load i64, i64* %device.phi.trans.insert, align 8, !tbaa !40
  br label %if.end

if.end:                                           ; preds = %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge, %if.end16.i
  %4 = phi i64 [ %.pre, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit.if.end_crit_edge ], [ %1, %if.end16.i ]
  %cmp1 = icmp eq i64 %4, 0
  br i1 %cmp1, label %cleanup, label %if.end3

if.end3:                                          ; preds = %if.end
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %5 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %5, i32 0, i32 15
  %6 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %6, i32 0, i32 1
  %7 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %7() #14
  store i64 0, i64* %device, align 8, !tbaa !40
  store %struct.halide_device_interface_t* null, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  br label %cleanup

cleanup:                                          ; preds = %if.end3, %if.end, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit
  %retval.0 = phi i32 [ 0, %if.end3 ], [ %retval.2.i, %_ZN12_GLOBAL__N_126debug_log_and_validate_bufEPvPK15halide_buffer_tPKc.exit ], [ 0, %if.end ]
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak void @halide_device_and_host_free_as_destructor(i8* %user_context, i8* %obj) local_unnamed_addr #0 {
entry:
  %0 = bitcast i8* %obj to %struct.halide_buffer_t*
  %call = tail call i32 @halide_device_and_host_free(i8* %user_context, %struct.halide_buffer_t* %0) #15
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_device_host_nop_free(i8* %user_context, i8* %obj) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_default_buffer_copy(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #2 {
entry:
  ret i32 -39
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  %c = alloca %"struct.Halide::Runtime::Internal::device_copy", align 8
  %tobool.not = icmp eq %struct.halide_device_interface_t* %dst_device_interface, null
  br i1 %tobool.not, label %if.end13, label %land.lhs.true

land.lhs.true:                                    ; preds = %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 1
  %0 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %tobool1.not = icmp eq %struct.halide_device_interface_t* %0, null
  %cmp.not = icmp eq %struct.halide_device_interface_t* %0, %dst_device_interface
  %or.cond = or i1 %tobool1.not, %cmp.not
  br i1 %or.cond, label %land.lhs.true5, label %if.then

if.then:                                          ; preds = %land.lhs.true
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.41, i32 0, i32 0)) #14
  br label %cleanup143

land.lhs.true5:                                   ; preds = %land.lhs.true
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 0
  %1 = load i64, i64* %device, align 8, !tbaa !40
  %tobool6.not = icmp eq i64 %1, 0
  br i1 %tobool6.not, label %if.then7, label %if.end13

if.then7:                                         ; preds = %land.lhs.true5
  %call = tail call i32 @halide_device_malloc(i8* %user_context, %struct.halide_buffer_t* nonnull %dst, %struct.halide_device_interface_t* nonnull %dst_device_interface) #15
  %tobool10.not = icmp eq i32 %call, 0
  br i1 %tobool10.not, label %if.end13, label %cleanup143

if.end13:                                         ; preds = %if.then7, %land.lhs.true5, %entry
  %device14 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 0
  %2 = load i64, i64* %device14, align 8, !tbaa !40
  %cmp15.not = icmp eq i64 %2, 0
  %host22.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 2
  %.pre = load i8*, i8** %host22.phi.trans.insert, align 4, !tbaa !43
  %cmp23.not = icmp eq i8* %.pre, null
  br i1 %cmp15.not, label %land.end, label %land.rhs

land.rhs:                                         ; preds = %if.end13
  br i1 %cmp23.not, label %land.end32, label %land.end.thread264

land.end.thread264:                               ; preds = %land.rhs
  %flags.i.i243 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 3
  %3 = load i64, i64* %flags.i.i243, align 8, !tbaa !44
  %and.i.i244 = and i64 %3, 1
  %cmp.i.i.not = icmp ne i64 %and.i.i244, 0
  br label %land.rhs26

land.end:                                         ; preds = %if.end13
  br i1 %cmp23.not, label %land.end32, label %land.end.land.rhs26_crit_edge

land.end.land.rhs26_crit_edge:                    ; preds = %land.end
  %flags.i.i247.phi.trans.insert = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 3
  %.pre1 = load i64, i64* %flags.i.i247.phi.trans.insert, align 8, !tbaa !44
  br label %land.rhs26

land.rhs26:                                       ; preds = %land.end.land.rhs26_crit_edge, %land.end.thread264
  %4 = phi i64 [ %3, %land.end.thread264 ], [ %.pre1, %land.end.land.rhs26_crit_edge ]
  %5 = phi i1 [ %cmp.i.i.not, %land.end.thread264 ], [ true, %land.end.land.rhs26_crit_edge ]
  %and.i.i248 = and i64 %4, 2
  %cmp.i.i249.not = icmp eq i64 %and.i.i248, 0
  br i1 %cmp.i.i249.not, label %land.end32, label %lor.rhs28

lor.rhs28:                                        ; preds = %land.rhs26
  %device_interface29 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %6 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface29, align 8, !tbaa !42
  %cmp30 = icmp ne %struct.halide_device_interface_t* %6, null
  br label %land.end32

land.end32:                                       ; preds = %lor.rhs28, %land.rhs26, %land.end, %land.rhs
  %cmp23.not263 = phi i1 [ true, %land.end ], [ false, %land.rhs26 ], [ false, %lor.rhs28 ], [ true, %land.rhs ]
  %7 = phi i1 [ true, %land.end ], [ %5, %land.rhs26 ], [ %5, %lor.rhs28 ], [ false, %land.rhs ]
  %8 = phi i1 [ true, %land.end ], [ false, %land.rhs26 ], [ %cmp30, %lor.rhs28 ], [ true, %land.rhs ]
  %host34 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 2
  %9 = load i8*, i8** %host34, align 4, !tbaa !43
  %cmp35.not = icmp eq i8* %9, null
  %cmp20.not = xor i1 %tobool.not, true
  %10 = and i1 %tobool.not, %cmp35.not
  br i1 %10, label %cleanup143, label %if.end41

if.end41:                                         ; preds = %land.end32
  %brmerge229 = or i1 %tobool.not, %7
  br i1 %brmerge229, label %if.then51, label %if.end49

if.end49:                                         ; preds = %if.end41
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i32 0, i32 15
  %11 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %buffer_copy = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %11, i32 0, i32 10
  %12 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy, align 4, !tbaa !90
  %call48 = tail call i32 %12(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* nonnull %dst_device_interface, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp50 = icmp eq i32 %call48, -42
  br i1 %cmp50, label %if.then51, label %if.end117

if.then51:                                        ; preds = %if.end49, %if.end41
  %brmerge231.demorgan = and i1 %cmp23.not263, %cmp35.not
  br i1 %brmerge231.demorgan, label %cleanup143, label %if.end58

if.end58:                                         ; preds = %if.then51
  %brmerge234 = or i1 %8, %cmp20.not
  br i1 %brmerge234, label %if.else, label %if.end117.thread258

if.end117.thread258:                              ; preds = %if.end58
  %13 = bitcast %"struct.Halide::Runtime::Internal::device_copy"* %c to i8*
  call void @llvm.lifetime.start.p0i8(i64 416, i8* nonnull %13) #11
  call void @_ZN6Halide7Runtime8Internal16make_buffer_copyEPK15halide_buffer_tbS4_b(%"struct.Halide::Runtime::Internal::device_copy"* nonnull sret(%"struct.Halide::Runtime::Internal::device_copy") align 8 %c, %struct.halide_buffer_t* nonnull %src, i1 zeroext true, %struct.halide_buffer_t* nonnull %dst, i1 zeroext true) #15
  call void @_ZN6Halide7Runtime8Internal11copy_memoryERKNS1_11device_copyEPv(%"struct.Halide::Runtime::Internal::device_copy"* nonnull align 8 dereferenceable(416) %c, i8* %user_context) #15
  call void @llvm.lifetime.end.p0i8(i64 416, i8* nonnull %13) #11
  br label %land.lhs.true126

if.else:                                          ; preds = %if.end58
  %brmerge237 = or i1 %7, %cmp20.not
  br i1 %brmerge237, label %if.else81, label %if.then66

if.then66:                                        ; preds = %if.else
  %device_interface69 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %14 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface69, align 8, !tbaa !42
  %impl70 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %14, i32 0, i32 15
  %15 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl70, align 4, !tbaa !71
  %buffer_copy71 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %15, i32 0, i32 10
  %16 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy71, align 4, !tbaa !90
  %call72 = tail call i32 %16(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp73 = icmp eq i32 %call72, -42
  br i1 %cmp73, label %if.then74, label %if.end117

if.then74:                                        ; preds = %if.then66
  %call75 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %src) #15
  %tobool76.not = icmp eq i32 %call75, 0
  br i1 %tobool76.not, label %if.then77, label %cleanup143

if.then77:                                        ; preds = %if.then74
  %call78 = tail call i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #15
  br label %if.end117

if.else81:                                        ; preds = %if.else
  %brmerge239 = or i1 %7, %cmp35.not
  br i1 %brmerge239, label %if.else98, label %if.then85

if.then85:                                        ; preds = %if.else81
  %device_interface90 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %17 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface90, align 8, !tbaa !42
  %impl91 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %17, i32 0, i32 15
  %18 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl91, align 4, !tbaa !71
  %buffer_copy92 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %18, i32 0, i32 10
  %19 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy92, align 4, !tbaa !90
  %call93 = tail call i32 %19(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* null, %struct.halide_buffer_t* nonnull %dst) #14
  %cmp94 = icmp eq i32 %call93, 0
  br i1 %cmp94, label %if.then95, label %cleanup143

if.then95:                                        ; preds = %if.then85
  %flags.i.i245 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 3
  %20 = load i64, i64* %flags.i.i245, align 8, !tbaa !44
  %or.i.i246 = or i64 %20, 1
  store i64 %or.i.i246, i64* %flags.i.i245, align 8, !tbaa !44
  %call96 = tail call i32 @copy_to_device_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %dst, %struct.halide_device_interface_t* %dst_device_interface) #15
  br label %if.end117

if.else98:                                        ; preds = %if.else81
  br i1 %tobool.not, label %cleanup143, label %if.then100

if.then100:                                       ; preds = %if.else98
  %call103 = tail call i32 @_ZN6Halide7Runtime8Internal27copy_to_host_already_lockedEPvP15halide_buffer_t(i8* %user_context, %struct.halide_buffer_t* nonnull %src) #15
  %cmp104 = icmp eq i32 %call103, 0
  br i1 %cmp104, label %if.then105, label %cleanup143

if.then105:                                       ; preds = %if.then100
  %impl106 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i32 0, i32 15
  %21 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl106, align 4, !tbaa !71
  %buffer_copy107 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %21, i32 0, i32 10
  %22 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)** %buffer_copy107, align 4, !tbaa !90
  %call108 = tail call i32 %22(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* nonnull %dst_device_interface, %struct.halide_buffer_t* nonnull %dst) #14
  br label %if.end117

if.end117:                                        ; preds = %if.then105, %if.then95, %if.then77, %if.then66, %if.end49
  %err.1 = phi i32 [ %call78, %if.then77 ], [ %call72, %if.then66 ], [ %call96, %if.then95 ], [ %call108, %if.then105 ], [ %call48, %if.end49 ]
  %cond = icmp eq i32 %err.1, 0
  br i1 %cond, label %land.lhs.true126, label %cleanup143

land.lhs.true126:                                 ; preds = %if.end117, %if.end117.thread258
  %cmp127.not.old = icmp eq %struct.halide_buffer_t* %dst, %src
  br i1 %cmp127.not.old, label %cleanup143, label %if.then128

if.then128:                                       ; preds = %land.lhs.true126
  %flags.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 3
  %23 = load i64, i64* %flags.i.i, align 8, !tbaa !44
  %or.i.i = and i64 %23, -4
  br i1 %tobool.not, label %if.else133, label %if.then130

if.then130:                                       ; preds = %if.then128
  %or.i.i242 = or i64 %or.i.i, 2
  store i64 %or.i.i242, i64* %flags.i.i, align 8, !tbaa !44
  br label %cleanup143

if.else133:                                       ; preds = %if.then128
  %and.i.i251 = or i64 %or.i.i, 1
  store i64 %and.i.i251, i64* %flags.i.i, align 8, !tbaa !44
  br label %cleanup143

cleanup143:                                       ; preds = %if.else133, %if.then130, %land.lhs.true126, %if.end117, %if.then100, %if.else98, %if.then85, %if.then74, %if.then51, %land.end32, %if.then7, %if.then
  %retval.1 = phi i32 [ -42, %if.then ], [ %call, %if.then7 ], [ -34, %land.end32 ], [ 0, %if.then130 ], [ 0, %if.else133 ], [ 0, %land.lhs.true126 ], [ -42, %if.then51 ], [ %err.1, %if.end117 ], [ -42, %if.else98 ], [ %call103, %if.then100 ], [ %call93, %if.then85 ], [ %call75, %if.then74 ]
  ret i32 %retval.1
}

; Function Attrs: nounwind
define weak i32 @halide_buffer_copy(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %tobool.not = icmp eq %struct.halide_device_interface_t* %dst_device_interface, null
  br i1 %tobool.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i32 0, i32 15
  %0 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %0, i32 0, i32 0
  %1 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %1() #14
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %2 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %tobool11.not = icmp eq %struct.halide_device_interface_t* %2, null
  br i1 %tobool11.not, label %if.end16, label %if.then12

if.then12:                                        ; preds = %if.end
  %impl14 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %2, i32 0, i32 15
  %3 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl14, align 4, !tbaa !71
  %use_module15 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %3, i32 0, i32 0
  %4 = load void ()*, void ()** %use_module15, align 4, !tbaa !77
  tail call void %4() #14
  br label %if.end16

if.end16:                                         ; preds = %if.then12, %if.end
  %call = tail call i32 @halide_buffer_copy_already_locked(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_device_interface_t* %dst_device_interface, %struct.halide_buffer_t* %dst) #15
  br i1 %tobool.not, label %if.end20, label %if.then18

if.then18:                                        ; preds = %if.end16
  %impl19 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %dst_device_interface, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl19, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 1
  %6 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %6() #14
  br label %if.end20

if.end20:                                         ; preds = %if.then18, %if.end16
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %tobool22.not = icmp eq %struct.halide_device_interface_t* %7, null
  br i1 %tobool22.not, label %if.end27, label %if.then23

if.then23:                                        ; preds = %if.end20
  %impl25 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i32 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl25, align 4, !tbaa !71
  %release_module26 = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i32 0, i32 1
  %9 = load void ()*, void ()** %release_module26, align 4, !tbaa !79
  tail call void %9() #14
  br label %if.end27

if.end27:                                         ; preds = %if.then23, %if.end20
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %call
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_crop(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.58, i32 0, i32 0)) #14
  ret i32 -40
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_slice(i8* %user_context, %struct.halide_buffer_t* %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* %dst) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.59, i32 0, i32 0)) #14
  ret i32 -40
}

; Function Attrs: nounwind
define weak i32 @halide_device_crop(i8* %user_context, %struct.halide_buffer_t* %src, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %device1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 0
  %1 = load i64, i64* %device1, align 8, !tbaa !40
  %tobool2.not = icmp eq i64 %1, 0
  br i1 %tobool2.not, label %if.end4, label %if.then3

if.then3:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.60, i32 0, i32 0)) #14
  br label %cleanup

if.end4:                                          ; preds = %if.end
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 5
  %2 = load i32, i32* %dimensions, align 4, !tbaa !45
  %dimensions5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 5
  %3 = load i32, i32* %dimensions5, align 4, !tbaa !45
  %cmp.not = icmp eq i32 %2, %3
  br i1 %cmp.not, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end4
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([48 x i8], [48 x i8]* @.str.61, i32 0, i32 0)) #14
  br label %cleanup

if.end7:                                          ; preds = %if.end4
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl9 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i32 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl9, align 4, !tbaa !71
  %device_crop = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i32 0, i32 11
  %9 = load i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)** %device_crop, align 4, !tbaa !91
  %call = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %src, %struct.halide_buffer_t* nonnull %dst) #14
  br label %cleanup

cleanup:                                          ; preds = %if.end7, %if.then6, %if.then3, %entry
  %retval.0 = phi i32 [ -41, %if.then3 ], [ -41, %if.then6 ], [ %call, %if.end7 ], [ 0, %entry ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind
define weak i32 @halide_device_slice(i8* %user_context, %struct.halide_buffer_t* %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* %dst) local_unnamed_addr #4 {
entry:
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %cleanup, label %if.end

if.end:                                           ; preds = %entry
  %device1 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 0
  %1 = load i64, i64* %device1, align 8, !tbaa !40
  %tobool2.not = icmp eq i64 %1, 0
  br i1 %tobool2.not, label %if.end4, label %if.then3

if.then3:                                         ; preds = %if.end
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.60, i32 0, i32 0)) #14
  br label %cleanup

if.end4:                                          ; preds = %if.end
  %dimensions = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 5
  %2 = load i32, i32* %dimensions, align 4, !tbaa !45
  %dimensions5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %dst, i32 0, i32 5
  %3 = load i32, i32* %dimensions5, align 4, !tbaa !45
  %add = add nsw i32 %3, 1
  %cmp.not = icmp eq i32 %2, %add
  br i1 %cmp.not, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end4
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.64, i32 0, i32 0)) #14
  br label %cleanup

if.end7:                                          ; preds = %if.end4
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %src, i32 0, i32 1
  %4 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %4, i32 0, i32 15
  %5 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %use_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %5, i32 0, i32 0
  %6 = load void ()*, void ()** %use_module, align 4, !tbaa !77
  tail call void %6() #14
  %7 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl9 = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %7, i32 0, i32 15
  %8 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl9, align 4, !tbaa !71
  %device_slice = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %8, i32 0, i32 12
  %9 = load i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)** %device_slice, align 4, !tbaa !92
  %call = tail call i32 %9(i8* %user_context, %struct.halide_buffer_t* nonnull %src, i32 %slice_dim, i32 %slice_pos, %struct.halide_buffer_t* nonnull %dst) #14
  br label %cleanup

cleanup:                                          ; preds = %if.end7, %if.then6, %if.then3, %entry
  %retval.0 = phi i32 [ -41, %if.then3 ], [ -41, %if.then6 ], [ %call, %if.end7 ], [ 0, %entry ]
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  ret i32 %retval.0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_default_device_release_crop(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #0 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %return, label %if.end

if.end:                                           ; preds = %entry
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.58, i32 0, i32 0)) #14
  br label %return

return:                                           ; preds = %if.end, %entry
  %retval.0 = phi i32 [ -40, %if.end ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind
define weak i32 @halide_device_release_crop(i8* %user_context, %struct.halide_buffer_t* %buf) local_unnamed_addr #4 {
entry:
  %device = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 0
  %0 = load i64, i64* %device, align 8, !tbaa !40
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %return, label %if.then

if.then:                                          ; preds = %entry
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  %device_interface = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %buf, i32 0, i32 1
  %1 = load %struct.halide_device_interface_t*, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  %impl = getelementptr inbounds %struct.halide_device_interface_t, %struct.halide_device_interface_t* %1, i32 0, i32 15
  %2 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %device_release_crop = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %2, i32 0, i32 13
  %3 = load i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)** %device_release_crop, align 4, !tbaa !93
  %call = tail call i32 %3(i8* %user_context, %struct.halide_buffer_t* nonnull %buf) #14
  store i64 0, i64* %device, align 8, !tbaa !40
  %4 = load %struct.halide_device_interface_impl_t*, %struct.halide_device_interface_impl_t** %impl, align 4, !tbaa !71
  %release_module = getelementptr inbounds %struct.halide_device_interface_impl_t, %struct.halide_device_interface_impl_t* %4, i32 0, i32 1
  %5 = load void ()*, void ()** %release_module, align 4, !tbaa !79
  tail call void %5() #14
  store %struct.halide_device_interface_t* null, %struct.halide_device_interface_t** %device_interface, align 8, !tbaa !42
  tail call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal17device_copy_mutexE) #14
  br label %return

return:                                           ; preds = %if.then, %entry
  %retval.0 = phi i32 [ %call, %if.then ], [ 0, %entry ]
  ret i32 %retval.0
}

; Function Attrs: nounwind willreturn mustprogress
define weak float @halide_float16_bits_to_float(i16 zeroext %bits) local_unnamed_addr #2 {
entry:
  %conv = zext i16 %bits to i32
  %and2 = and i32 %conv, 1023
  %and4 = lshr i32 %conv, 10
  %0 = and i32 %and4, 31
  %cmp = icmp eq i32 %0, 0
  %cmp5 = icmp ne i32 %and2, 0
  %or.cond = and i1 %cmp5, %cmp
  br i1 %or.cond, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %1 = tail call i32 @llvm.ctlz.i32(i32 %and2, i1 true), !range !94
  %sub6 = xor i32 %1, 31
  %shl7 = shl nuw i32 1, %sub6
  %neg = xor i32 %shl7, -1
  %and8 = and i32 %and2, %neg
  %sub9 = sub nsw i32 23, %sub6
  %shl10 = shl i32 %and8, %sub9
  %add11.neg = mul nsw i32 %1, -8388608
  %shl12 = add i32 %add11.neg, 1124073472
  br label %if.end28

if.else:                                          ; preds = %entry
  %shl14 = shl nuw nsw i32 %and2, 13
  br i1 %cmp, label %if.end28, label %if.else18

if.else18:                                        ; preds = %if.else
  %cmp19 = icmp eq i32 %0, 31
  br i1 %cmp19, label %if.end28, label %if.else21

if.else21:                                        ; preds = %if.else18
  %add22 = shl nuw nsw i32 %0, 23
  %phi.bo = add nuw nsw i32 %add22, 939524096
  br label %if.end28

if.end28:                                         ; preds = %if.else21, %if.else18, %if.else, %if.then
  %shl14.sink = phi i32 [ %shl12, %if.then ], [ %shl14, %if.else18 ], [ %shl14, %if.else ], [ %shl14, %if.else21 ]
  %reEncodedExponent15.0.sink = phi i32 [ %shl10, %if.then ], [ 2139095040, %if.else18 ], [ 0, %if.else ], [ %phi.bo, %if.else21 ]
  %bits.signext = sext i16 %bits to i32
  %shl = and i32 %bits.signext, -2147483648
  %or25 = or i32 %shl14.sink, %shl
  %or26 = or i32 %or25, %reEncodedExponent15.0.sink
  %result.sroa.0.0 = bitcast i32 %or26 to float
  ret float %result.sroa.0.0
}

; Function Attrs: nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #8

; Function Attrs: nounwind willreturn mustprogress
define weak double @halide_float16_bits_to_double(i16 zeroext %bits) local_unnamed_addr #2 {
entry:
  %call = tail call float @halide_float16_bits_to_float(i16 zeroext %bits) #15
  %conv = fpext float %call to double
  ret double %conv
}

; Function Attrs: nounwind
define weak i32 @halide_error_bounds_inference_call_failed(i8* %user_context, i8* %extern_stage_name, i32 %result) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.36, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.36, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %extern_stage_name) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.1.37, i32 0, i32 0)) #14
  %conv.i = sext i32 %result to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.16.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i16 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 %result
}

; Function Attrs: nounwind
define weak i32 @halide_error_extern_stage_failed(i8* %user_context, i8* %extern_stage_name, i32 %result) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.2.38, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.2.38, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %extern_stage_name) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.1.37, i32 0, i32 0)) #14
  %conv.i = sext i32 %result to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.16.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i16 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 %result
}

; Function Attrs: nounwind
define weak i32 @halide_error_explicit_bounds_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %min_bound, i32 %max_bound, i32 %min_required, i32 %max_required) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i151 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.3.39, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i152 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.3.39, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i151, %entry.split ], [ %call.i152, %if.then6.i ]
  %ref.tmp.sroa.34.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i18 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.34.0, i8* %var_name) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.4.40, i32 0, i32 0)) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.34.0, i8* %func_name) #14
  %call.i27 = tail call i8* @halide_string_to_string(i8* %call.i24, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.5.41, i32 0, i32 0)) #14
  %conv.i = sext i32 %min_bound to i64
  %call.i30 = tail call i8* @halide_int64_to_string(i8* %call.i27, i8* %ref.tmp.sroa.34.0, i64 %conv.i, i32 1) #14
  %call.i33 = tail call i8* @halide_string_to_string(i8* %call.i30, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.42, i32 0, i32 0)) #14
  %conv.i36 = sext i32 %max_bound to i64
  %call.i37 = tail call i8* @halide_int64_to_string(i8* %call.i33, i8* %ref.tmp.sroa.34.0, i64 %conv.i36, i32 1) #14
  %call.i40 = tail call i8* @halide_string_to_string(i8* %call.i37, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.7.43, i32 0, i32 0)) #14
  %conv.i43 = sext i32 %min_required to i64
  %call.i44 = tail call i8* @halide_int64_to_string(i8* %call.i40, i8* %ref.tmp.sroa.34.0, i64 %conv.i43, i32 1) #14
  %call.i47 = tail call i8* @halide_string_to_string(i8* %call.i44, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.42, i32 0, i32 0)) #14
  %conv.i50 = sext i32 %max_required to i64
  %call.i51 = tail call i8* @halide_int64_to_string(i8* %call.i47, i8* %ref.tmp.sroa.34.0, i64 %conv.i50, i32 1) #14
  %call.i54 = tail call i8* @halide_string_to_string(i8* %call.i51, i8* %ref.tmp.sroa.34.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.44, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i54 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -2
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_type(i8* %user_context, i8* %func_name, i32 %type_given_bits, i32 %correct_type_bits) local_unnamed_addr #4 {
entry:
  %type_given_bits.addr = alloca i32, align 4
  %correct_type_bits.addr = alloca i32, align 4
  %correct_type = alloca %struct.halide_type_t, align 2
  %type_given = alloca %struct.halide_type_t, align 2
  store i32 %type_given_bits, i32* %type_given_bits.addr, align 4, !tbaa !14
  store i32 %correct_type_bits, i32* %correct_type_bits.addr, align 4, !tbaa !14
  %0 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i32 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %0) #11
  store i8 0, i8* %0, align 2, !tbaa !34
  %bits.i = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i32 0, i32 1
  store i8 0, i8* %bits.i, align 1, !tbaa !38
  %lanes.i = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %correct_type, i32 0, i32 2
  store i16 0, i16* %lanes.i, align 2, !tbaa !39
  %1 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i32 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %1) #11
  store i8 0, i8* %1, align 2, !tbaa !34
  %bits.i8 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i32 0, i32 1
  store i8 0, i8* %bits.i8, align 1, !tbaa !38
  %lanes.i9 = getelementptr inbounds %struct.halide_type_t, %struct.halide_type_t* %type_given, i32 0, i32 2
  store i16 0, i16* %lanes.i9, align 2, !tbaa !39
  %2 = bitcast i32* %correct_type_bits.addr to i8*
  %call = call i8* @memcpy(i8* nonnull %0, i8* nonnull %2, i32 4) #14
  %3 = bitcast i32* %type_given_bits.addr to i8*
  %call1 = call i8* @memcpy(i8* nonnull %1, i8* nonnull %3, i32 4) #14
  %call.i = call i8* @malloc(i32 1024) #14
  %tobool.not.i12 = icmp eq i8* %call.i, null
  br i1 %tobool.not.i12, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i151 = call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i152 = call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i151, %entry.split ], [ %call.i152, %if.then6.i ]
  %ref.tmp.sroa.18.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i18 = call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.9.45, i32 0, i32 0)) #14
  %call.i21 = call i8* @halide_type_to_string(i8* %call.i18, i8* %ref.tmp.sroa.18.0, %struct.halide_type_t* nonnull %correct_type) #14
  %call.i24 = call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.10.46, i32 0, i32 0)) #14
  %call.i27 = call i8* @halide_type_to_string(i8* %call.i24, i8* %ref.tmp.sroa.18.0, %struct.halide_type_t* nonnull %type_given) #14
  br i1 %tobool.not.i12, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i27 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  call void @free(i8* %call.i) #14
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %1) #11
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %0) #11
  ret i32 -3
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_dimensions(i8* %user_context, i8* %func_name, i32 %dimensions_given, i32 %correct_dimensions) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.11.47, i32 0, i32 0)) #14
  %conv.i = sext i32 %correct_dimensions to i64
  %call.i14 = tail call i8* @halide_int64_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i64 %conv.i, i32 1) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.12.48, i32 0, i32 0)) #14
  %conv.i20 = sext i32 %dimensions_given to i64
  %call.i21 = tail call i8* @halide_int64_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i64 %conv.i20, i32 1) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.13.49, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i24 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -43
}

; Function Attrs: nounwind
define weak i32 @halide_error_access_out_of_bounds(i8* %user_context, i8* %func_name, i32 %dimension, i32 %min_touched, i32 %max_touched, i32 %min_valid, i32 %max_valid) local_unnamed_addr #4 {
entry:
  %cmp = icmp slt i32 %min_touched, %min_valid
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.split, label %if.then6.i

if.then.split:                                    ; preds = %if.then
  %call.i271 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i272 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %if.then.split, %if.then6.i
  %phi.call = phi i8* [ %call.i271, %if.then.split ], [ %call.i272, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %if.then.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i30 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.14.50, i32 0, i32 0)) #14
  %conv.i = sext i32 %min_touched to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i30, i8* %ref.tmp.sroa.22.0, i64 %conv.i, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.15.51, i32 0, i32 0)) #14
  %conv.i39 = sext i32 %min_valid to i64
  %call.i40 = tail call i8* @halide_int64_to_string(i8* %call.i36, i8* %ref.tmp.sroa.22.0, i64 %conv.i39, i32 1) #14
  %call.i43 = tail call i8* @halide_string_to_string(i8* %call.i40, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.16.52, i32 0, i32 0)) #14
  %conv.i46 = sext i32 %dimension to i64
  %call.i47 = tail call i8* @halide_int64_to_string(i8* %call.i43, i8* %ref.tmp.sroa.22.0, i64 %conv.i46, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %if.end17.sink.split

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i47 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %if.end17.sink.split

if.else:                                          ; preds = %entry
  %cmp7 = icmp sgt i32 %max_touched, %max_valid
  br i1 %cmp7, label %if.then8, label %if.end17

if.then8:                                         ; preds = %if.else
  %call.i53 = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i56 = icmp eq i8* %call.i53, null
  br i1 %tobool.not.i56, label %if.then8.split, label %if.then6.i59

if.then8.split:                                   ; preds = %if.then8
  %call.i653 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62

if.then6.i59:                                     ; preds = %if.then8
  %add.ptr.i57 = getelementptr inbounds i8, i8* %call.i53, i32 1023
  store i8 0, i8* %add.ptr.i57, align 1, !tbaa !22
  %call.i654 = tail call i8* @halide_string_to_string(i8* nonnull %call.i53, i8* nonnull %add.ptr.i57, i8* %func_name) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62: ; preds = %if.then8.split, %if.then6.i59
  %phi.call5 = phi i8* [ %call.i653, %if.then8.split ], [ %call.i654, %if.then6.i59 ]
  %ref.tmp9.sroa.22.0 = phi i8* [ null, %if.then8.split ], [ %add.ptr.i57, %if.then6.i59 ]
  %call.i68 = tail call i8* @halide_string_to_string(i8* %phi.call5, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.14.50, i32 0, i32 0)) #14
  %conv.i71 = sext i32 %max_touched to i64
  %call.i72 = tail call i8* @halide_int64_to_string(i8* %call.i68, i8* %ref.tmp9.sroa.22.0, i64 %conv.i71, i32 1) #14
  %call.i75 = tail call i8* @halide_string_to_string(i8* %call.i72, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.17.53, i32 0, i32 0)) #14
  %conv.i78 = sext i32 %max_valid to i64
  %call.i79 = tail call i8* @halide_int64_to_string(i8* %call.i75, i8* %ref.tmp9.sroa.22.0, i64 %conv.i78, i32 1) #14
  %call.i82 = tail call i8* @halide_string_to_string(i8* %call.i79, i8* %ref.tmp9.sroa.22.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.16.52, i32 0, i32 0)) #14
  %conv.i85 = sext i32 %dimension to i64
  %call.i86 = tail call i8* @halide_int64_to_string(i8* %call.i82, i8* %ref.tmp9.sroa.22.0, i64 %conv.i85, i32 1) #14
  br i1 %tobool.not.i56, label %if.then.i90, label %if.else.i101

if.then.i90:                                      ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %if.end17.sink.split

if.else.i101:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit62
  %sub.ptr.lhs.cast.i.i95 = ptrtoint i8* %call.i86 to i32
  %sub.ptr.rhs.cast.i.i96 = ptrtoint i8* %call.i53 to i32
  %sub.ptr.sub.i.i97 = sub i32 1, %sub.ptr.rhs.cast.i.i96
  %add.i.i98 = add i32 %sub.ptr.sub.i.i97, %sub.ptr.lhs.cast.i.i95
  %conv.i.i99 = sext i32 %add.i.i98 to i64
  %call.i.i100 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i53, i64 %conv.i.i99) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i53) #14
  br label %if.end17.sink.split

if.end17.sink.split:                              ; preds = %if.else.i101, %if.then.i90, %if.else.i, %if.then.i
  %call.i53.sink = phi i8* [ %call.i, %if.else.i ], [ null, %if.then.i ], [ %call.i53, %if.else.i101 ], [ null, %if.then.i90 ]
  tail call void @free(i8* %call.i53.sink) #14
  br label %if.end17

if.end17:                                         ; preds = %if.end17.sink.split, %if.else
  ret i32 -4
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_allocation_too_large(i8* %user_context, i8* %buffer_name, i64 %allocation_size, i64 %max_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.18.54, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.18.54, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %buffer_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %allocation_size, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.20.56, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_size, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -5
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_extents_negative(i8* %user_context, i8* %buffer_name, i32 %dimension, i32 %extent) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i91 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.21.57, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i92 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.21.57, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i91, %entry.split ], [ %call.i92, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i12 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* %buffer_name) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.22.58, i32 0, i32 0)) #14
  %conv.i = sext i32 %dimension to i64
  %call.i18 = tail call i8* @halide_int64_to_string(i8* %call.i15, i8* %ref.tmp.sroa.22.0, i64 %conv.i, i32 1) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.23.59, i32 0, i32 0)) #14
  %conv.i24 = sext i32 %extent to i64
  %call.i25 = tail call i8* @halide_int64_to_string(i8* %call.i21, i8* %ref.tmp.sroa.22.0, i64 %conv.i24, i32 1) #14
  %call.i28 = tail call i8* @halide_string_to_string(i8* %call.i25, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.44, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i28 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -28
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_extents_too_large(i8* %user_context, i8* %buffer_name, i64 %actual_size, i64 %max_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.24.60, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.24.60, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %buffer_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %actual_size, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.20.56, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_size, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -6
}

; Function Attrs: nounwind
define weak i32 @halide_error_constraints_make_required_region_smaller(i8* %user_context, i8* %buffer_name, i32 %dimension, i32 %constrained_min, i32 %constrained_extent, i32 %required_min, i32 %required_extent) local_unnamed_addr #4 {
entry:
  %add = add i32 %required_min, -1
  %sub = add i32 %add, %required_extent
  %add1 = add i32 %constrained_min, -1
  %sub2 = add i32 %add1, %constrained_extent
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i231 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.25.61, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i232 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.25.61, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i231, %entry.split ], [ %call.i232, %if.then6.i ]
  %ref.tmp.sroa.38.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i26 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.38.0, i8* %buffer_name) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([54 x i8], [54 x i8]* @.str.26.62, i32 0, i32 0)) #14
  %conv.i = sext i32 %dimension to i64
  %call.i32 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.38.0, i64 %conv.i, i32 1) #14
  %call.i35 = tail call i8* @halide_string_to_string(i8* %call.i32, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.27.63, i32 0, i32 0)) #14
  %call.i38 = tail call i8* @halide_string_to_string(i8* %call.i35, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.28.64, i32 0, i32 0)) #14
  %conv.i41 = sext i32 %required_min to i64
  %call.i42 = tail call i8* @halide_int64_to_string(i8* %call.i38, i8* %ref.tmp.sroa.38.0, i64 %conv.i41, i32 1) #14
  %call.i45 = tail call i8* @halide_string_to_string(i8* %call.i42, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.42, i32 0, i32 0)) #14
  %conv.i48 = sext i32 %sub to i64
  %call.i49 = tail call i8* @halide_int64_to_string(i8* %call.i45, i8* %ref.tmp.sroa.38.0, i64 %conv.i48, i32 1) #14
  %call.i52 = tail call i8* @halide_string_to_string(i8* %call.i49, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.27.63, i32 0, i32 0)) #14
  %call.i55 = tail call i8* @halide_string_to_string(i8* %call.i52, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.29.65, i32 0, i32 0)) #14
  %conv.i58 = sext i32 %constrained_min to i64
  %call.i59 = tail call i8* @halide_int64_to_string(i8* %call.i55, i8* %ref.tmp.sroa.38.0, i64 %conv.i58, i32 1) #14
  %call.i62 = tail call i8* @halide_string_to_string(i8* %call.i59, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.6.42, i32 0, i32 0)) #14
  %conv.i65 = sext i32 %sub2 to i64
  %call.i66 = tail call i8* @halide_int64_to_string(i8* %call.i62, i8* %ref.tmp.sroa.38.0, i64 %conv.i65, i32 1) #14
  %call.i69 = tail call i8* @halide_string_to_string(i8* %call.i66, i8* %ref.tmp.sroa.38.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.66, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i69 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -7
}

; Function Attrs: nounwind
define weak i32 @halide_error_constraint_violated(i8* %user_context, i8* %var, i32 %val, i8* %constrained_var, i32 %constrained_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i111 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.31.67, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i112 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.31.67, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i111, %entry.split ], [ %call.i112, %if.then6.i ]
  %ref.tmp.sroa.26.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i14 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.26.0, i8* %var) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.68, i32 0, i32 0)) #14
  %conv.i = sext i32 %val to i64
  %call.i20 = tail call i8* @halide_int64_to_string(i8* %call.i17, i8* %ref.tmp.sroa.26.0, i64 %conv.i, i32 1) #14
  %call.i23 = tail call i8* @halide_string_to_string(i8* %call.i20, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.33.69, i32 0, i32 0)) #14
  %call.i26 = tail call i8* @halide_string_to_string(i8* %call.i23, i8* %ref.tmp.sroa.26.0, i8* %constrained_var) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.68, i32 0, i32 0)) #14
  %conv.i32 = sext i32 %constrained_val to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.26.0, i64 %conv.i32, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8.44, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i36 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -8
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_i64(i8* %user_context, i8* %param_name, i64 %val, i64 %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.71, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_u64(i8* %user_context, i8* %param_name, i64 %val, i64 %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.71, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_small_f64(i8* %user_context, i8* %param_name, double %val, double %min_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_double_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, double %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.35.71, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_double_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, double %min_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -9
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_i64(i8* %user_context, i8* %param_name, i64 %val, i64 %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_int64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36.72, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_u64(i8* %user_context, i8* %param_name, i64 %val, i64 %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_uint64_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i64 %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36.72, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_uint64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind
define weak i32 @halide_error_param_too_large_f64(i8* %user_context, i8* %param_name, double %val, double %max_val) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.34.70, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %param_name) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.19.55, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_double_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, double %val, i32 1) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.36.72, i32 0, i32 0)) #14
  %call.i23 = tail call i8* @halide_double_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, double %max_val, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -10
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_error_out_of_memory(i8* %user_context) local_unnamed_addr #0 {
entry:
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.37, i32 0, i32 0)) #14
  ret i32 -11
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_argument_is_null(i8* %user_context, i8* %buffer_name) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.38, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.38, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %buffer_name) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.39, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -12
}

; Function Attrs: nounwind
define weak i32 @halide_error_debug_to_file_failed(i8* %user_context, i8* %func, i8* %filename, i32 %error_code) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i81 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.40, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i82 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.40, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i81, %entry.split ], [ %call.i82, %if.then6.i ]
  %ref.tmp.sroa.20.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i11 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.20.0, i8* %func) #14
  %call.i14 = tail call i8* @halide_string_to_string(i8* %call.i11, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.41.73, i32 0, i32 0)) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.20.0, i8* %filename) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.20.0, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.42, i32 0, i32 0)) #14
  %conv.i = sext i32 %error_code to i64
  %call.i23 = tail call i8* @halide_int64_to_string(i8* %call.i20, i8* %ref.tmp.sroa.20.0, i64 %conv.i, i32 1) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i23 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -13
}

; Function Attrs: nounwind
define weak i32 @halide_error_unaligned_host_ptr(i8* %user_context, i8* %func, i32 %alignment) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i71 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i72 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i71, %entry.split ], [ %call.i72, %if.then6.i ]
  %ref.tmp.sroa.18.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i10 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.18.0, i8* %func) #14
  %call.i13 = tail call i8* @halide_string_to_string(i8* %call.i10, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.44, i32 0, i32 0)) #14
  %conv.i = sext i32 %alignment to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %call.i13, i8* %ref.tmp.sroa.18.0, i64 %conv.i, i32 1) #14
  %call.i19 = tail call i8* @halide_string_to_string(i8* %call.i16, i8* %ref.tmp.sroa.18.0, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.45, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i19 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -24
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_dirty_with_no_device_support(i8* %user_context, i8* %func) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i61 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.46, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i62 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.46, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i61, %entry.split ], [ %call.i62, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i9 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %func) #14
  %call.i12 = tail call i8* @halide_string_to_string(i8* %call.i9, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.47, i32 0, i32 0)) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.48, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i15 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -44
}

; Function Attrs: nounwind
define weak i32 @halide_error_host_is_null(i8* %user_context, i8* %func) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.43, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %func) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.49, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -34
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_fold(i8* %user_context, i8* %func_name, i8* %var_name, i8* %loop_name) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i91 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.50, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i92 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.50, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i91, %entry.split ], [ %call.i92, %if.then6.i ]
  %ref.tmp.sroa.22.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i12 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.22.0, i8* %var_name) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i32 0, i32 0)) #14
  %call.i18 = tail call i8* @halide_string_to_string(i8* %call.i15, i8* %ref.tmp.sroa.22.0, i8* %func_name) #14
  %call.i21 = tail call i8* @halide_string_to_string(i8* %call.i18, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.52, i32 0, i32 0)) #14
  %call.i24 = tail call i8* @halide_string_to_string(i8* %call.i21, i8* %ref.tmp.sroa.22.0, i8* %loop_name) #14
  %call.i27 = tail call i8* @halide_string_to_string(i8* %call.i24, i8* %ref.tmp.sroa.22.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.66, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i27 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -25
}

; Function Attrs: nounwind
define weak i32 @halide_error_bad_extern_fold(i8* %user_context, i8* %func_name, i32 %dim, i32 %min, i32 %extent, i32 %valid_min, i32 %fold_factor) local_unnamed_addr #4 {
entry:
  %cmp = icmp slt i32 %min, %valid_min
  br i1 %cmp, label %if.then, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %entry
  %add = add nsw i32 %extent, %min
  %add1 = add nsw i32 %fold_factor, %valid_min
  %cmp2 = icmp sgt i32 %add, %add1
  br i1 %cmp2, label %if.then, label %if.else

if.then:                                          ; preds = %lor.lhs.false, %entry
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.split, label %if.then6.i

if.then.split:                                    ; preds = %if.then
  %call.i521 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i522 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %if.then.split, %if.then6.i
  %phi.call = phi i8* [ %call.i521, %if.then.split ], [ %call.i522, %if.then6.i ]
  %ref.tmp.sroa.36.0 = phi i8* [ null, %if.then.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %dim to i64
  %call.i55 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.36.0, i64 %conv.i, i32 1) #14
  %call.i58 = tail call i8* @halide_string_to_string(i8* %call.i55, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i32 0, i32 0)) #14
  %call.i61 = tail call i8* @halide_string_to_string(i8* %call.i58, i8* %ref.tmp.sroa.36.0, i8* %func_name) #14
  %call.i64 = tail call i8* @halide_string_to_string(i8* %call.i61, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.54, i32 0, i32 0)) #14
  %conv.i67 = sext i32 %min to i64
  %call.i68 = tail call i8* @halide_int64_to_string(i8* %call.i64, i8* %ref.tmp.sroa.36.0, i64 %conv.i67, i32 1) #14
  %call.i71 = tail call i8* @halide_string_to_string(i8* %call.i68, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #14
  %add9 = add nsw i32 %extent, %min
  %sub = add nsw i32 %add9, -1
  %conv.i74 = sext i32 %sub to i64
  %call.i75 = tail call i8* @halide_int64_to_string(i8* %call.i71, i8* %ref.tmp.sroa.36.0, i64 %conv.i74, i32 1) #14
  %call.i78 = tail call i8* @halide_string_to_string(i8* %call.i75, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.56, i32 0, i32 0)) #14
  %call.i81 = tail call i8* @halide_string_to_string(i8* %call.i78, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.57, i32 0, i32 0)) #14
  %conv.i84 = sext i32 %valid_min to i64
  %call.i85 = tail call i8* @halide_int64_to_string(i8* %call.i81, i8* %ref.tmp.sroa.36.0, i64 %conv.i84, i32 1) #14
  %call.i88 = tail call i8* @halide_string_to_string(i8* %call.i85, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #14
  %add15 = add nsw i32 %fold_factor, %valid_min
  %sub16 = add nsw i32 %add15, -1
  %conv.i91 = sext i32 %sub16 to i64
  %call.i92 = tail call i8* @halide_int64_to_string(i8* %call.i88, i8* %ref.tmp.sroa.36.0, i64 %conv.i91, i32 1) #14
  %call.i95 = tail call i8* @halide_string_to_string(i8* %call.i92, i8* %ref.tmp.sroa.36.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.58.74, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %if.end

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i95 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %if.end

if.else:                                          ; preds = %lor.lhs.false
  %call.i101 = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i104 = icmp eq i8* %call.i101, null
  br i1 %tobool.not.i104, label %if.else.split, label %if.then6.i107

if.else.split:                                    ; preds = %if.else
  %call.i1133 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110

if.then6.i107:                                    ; preds = %if.else
  %add.ptr.i105 = getelementptr inbounds i8, i8* %call.i101, i32 1023
  store i8 0, i8* %add.ptr.i105, align 1, !tbaa !22
  %call.i1134 = tail call i8* @halide_string_to_string(i8* nonnull %call.i101, i8* nonnull %add.ptr.i105, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.53, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110: ; preds = %if.else.split, %if.then6.i107
  %phi.call5 = phi i8* [ %call.i1133, %if.else.split ], [ %call.i1134, %if.then6.i107 ]
  %ref.tmp19.sroa.34.0 = phi i8* [ null, %if.else.split ], [ %add.ptr.i105, %if.then6.i107 ]
  %conv.i116 = sext i32 %dim to i64
  %call.i117 = tail call i8* @halide_int64_to_string(i8* %phi.call5, i8* %ref.tmp19.sroa.34.0, i64 %conv.i116, i32 1) #14
  %call.i120 = tail call i8* @halide_string_to_string(i8* %call.i117, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i32 0, i32 0)) #14
  %call.i123 = tail call i8* @halide_string_to_string(i8* %call.i120, i8* %ref.tmp19.sroa.34.0, i8* %func_name) #14
  %call.i126 = tail call i8* @halide_string_to_string(i8* %call.i123, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.54, i32 0, i32 0)) #14
  %conv.i129 = sext i32 %min to i64
  %call.i130 = tail call i8* @halide_int64_to_string(i8* %call.i126, i8* %ref.tmp19.sroa.34.0, i64 %conv.i129, i32 1) #14
  %call.i133 = tail call i8* @halide_string_to_string(i8* %call.i130, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.55, i32 0, i32 0)) #14
  %sub28 = add nsw i32 %add, -1
  %conv.i136 = sext i32 %sub28 to i64
  %call.i137 = tail call i8* @halide_int64_to_string(i8* %call.i133, i8* %ref.tmp19.sroa.34.0, i64 %conv.i136, i32 1) #14
  %call.i140 = tail call i8* @halide_string_to_string(i8* %call.i137, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.56, i32 0, i32 0)) #14
  %call.i143 = tail call i8* @halide_string_to_string(i8* %call.i140, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.59.75, i32 0, i32 0)) #14
  %call.i146 = tail call i8* @halide_string_to_string(i8* %call.i143, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.60.76, i32 0, i32 0)) #14
  %conv.i149 = sext i32 %fold_factor to i64
  %call.i150 = tail call i8* @halide_int64_to_string(i8* %call.i146, i8* %ref.tmp19.sroa.34.0, i64 %conv.i149, i32 1) #14
  %call.i153 = tail call i8* @halide_string_to_string(i8* %call.i150, i8* %ref.tmp19.sroa.34.0, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.30.66, i32 0, i32 0)) #14
  br i1 %tobool.not.i104, label %if.then.i157, label %if.else.i168

if.then.i157:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %if.end

if.else.i168:                                     ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit110
  %sub.ptr.lhs.cast.i.i162 = ptrtoint i8* %call.i153 to i32
  %sub.ptr.rhs.cast.i.i163 = ptrtoint i8* %call.i101 to i32
  %sub.ptr.sub.i.i164 = sub i32 1, %sub.ptr.rhs.cast.i.i163
  %add.i.i165 = add i32 %sub.ptr.sub.i.i164, %sub.ptr.lhs.cast.i.i162
  %conv.i.i166 = sext i32 %add.i.i165 to i64
  %call.i.i167 = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i101, i64 %conv.i.i166) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i101) #14
  br label %if.end

if.end:                                           ; preds = %if.else.i168, %if.then.i157, %if.else.i, %if.then.i
  %call.i101.sink = phi i8* [ %call.i, %if.else.i ], [ null, %if.then.i ], [ %call.i101, %if.else.i168 ], [ null, %if.then.i157 ]
  tail call void @free(i8* %call.i101.sink) #14
  ret i32 -35
}

; Function Attrs: nounwind
define weak i32 @halide_error_fold_factor_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %fold_factor, i8* %loop_name, i32 %required_extent) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i131 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.61.77, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i132 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.61.77, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i131, %entry.split ], [ %call.i132, %if.then6.i ]
  %ref.tmp.sroa.30.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %fold_factor to i64
  %call.i16 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.30.0, i64 %conv.i, i32 1) #14
  %call.i19 = tail call i8* @halide_string_to_string(i8* %call.i16, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.62, i32 0, i32 0)) #14
  %call.i22 = tail call i8* @halide_string_to_string(i8* %call.i19, i8* %ref.tmp.sroa.30.0, i8* %var_name) #14
  %call.i25 = tail call i8* @halide_string_to_string(i8* %call.i22, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i32 0, i32 0)) #14
  %call.i28 = tail call i8* @halide_string_to_string(i8* %call.i25, i8* %ref.tmp.sroa.30.0, i8* %func_name) #14
  %call.i31 = tail call i8* @halide_string_to_string(i8* %call.i28, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.63, i32 0, i32 0)) #14
  %call.i34 = tail call i8* @halide_string_to_string(i8* %call.i31, i8* %ref.tmp.sroa.30.0, i8* %loop_name) #14
  %call.i37 = tail call i8* @halide_string_to_string(i8* %call.i34, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.32.68, i32 0, i32 0)) #14
  %conv.i40 = sext i32 %required_extent to i64
  %call.i41 = tail call i8* @halide_int64_to_string(i8* %call.i37, i8* %ref.tmp.sroa.30.0, i64 %conv.i40, i32 1) #14
  %call.i44 = tail call i8* @halide_string_to_string(i8* %call.i41, i8* %ref.tmp.sroa.30.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.64.78, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i44 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -26
}

; Function Attrs: nounwind
define weak i32 @halide_error_requirement_failed(i8* %user_context, i8* %condition, i8* %message) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i61 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.65, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i62 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.65, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i61, %entry.split ], [ %call.i62, %if.then6.i ]
  %ref.tmp.sroa.16.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i9 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.16.0, i8* %condition) #14
  %call.i12 = tail call i8* @halide_string_to_string(i8* %call.i9, i8* %ref.tmp.sroa.16.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.66, i32 0, i32 0)) #14
  %call.i15 = tail call i8* @halide_string_to_string(i8* %call.i12, i8* %ref.tmp.sroa.16.0, i8* %message) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i15 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -27
}

; Function Attrs: nounwind
define weak i32 @halide_error_specialize_fail(i8* %user_context, i8* %message) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i41 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.67, i32 0, i32 0)) #14
  %call.i75 = tail call i8* @halide_string_to_string(i8* %call.i41, i8* null, i8* %message) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i42 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([59 x i8], [59 x i8]* @.str.67, i32 0, i32 0)) #14
  %call.i7 = tail call i8* @halide_string_to_string(i8* %call.i42, i8* nonnull %add.ptr.i, i8* %message) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i7 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -31
}

; Function Attrs: nounwind
define weak i32 @halide_error_no_device_interface(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.68, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.68, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -19
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_interface_no_device(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.69, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.69, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -36
}

; Function Attrs: nounwind
define weak i32 @halide_error_host_and_device_dirty(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.70, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.70, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -37
}

; Function Attrs: nounwind
define weak i32 @halide_error_buffer_is_null(i8* %user_context, i8* %routine) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i51 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.71, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i52 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.71, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i51, %entry.split ], [ %call.i52, %if.then6.i ]
  %ref.tmp.sroa.14.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %call.i8 = tail call i8* @halide_string_to_string(i8* %phi.call, i8* %ref.tmp.sroa.14.0, i8* %routine) #14
  %call.i11 = tail call i8* @halide_string_to_string(i8* %call.i8, i8* %ref.tmp.sroa.14.0, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.72, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i11 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -38
}

; Function Attrs: nounwind
define weak i32 @halide_error_storage_bound_too_small(i8* %user_context, i8* %func_name, i8* %var_name, i32 %provided_size, i32 %required_size) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %entry.split, label %if.then6.i

entry.split:                                      ; preds = %entry
  %call.i111 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.73, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

if.then6.i:                                       ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i112 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.73, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit: ; preds = %entry.split, %if.then6.i
  %phi.call = phi i8* [ %call.i111, %entry.split ], [ %call.i112, %if.then6.i ]
  %ref.tmp.sroa.26.0 = phi i8* [ null, %entry.split ], [ %add.ptr.i, %if.then6.i ]
  %conv.i = sext i32 %provided_size to i64
  %call.i14 = tail call i8* @halide_int64_to_string(i8* %phi.call, i8* %ref.tmp.sroa.26.0, i64 %conv.i, i32 1) #14
  %call.i17 = tail call i8* @halide_string_to_string(i8* %call.i14, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.62, i32 0, i32 0)) #14
  %call.i20 = tail call i8* @halide_string_to_string(i8* %call.i17, i8* %ref.tmp.sroa.26.0, i8* %var_name) #14
  %call.i23 = tail call i8* @halide_string_to_string(i8* %call.i20, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.51, i32 0, i32 0)) #14
  %call.i26 = tail call i8* @halide_string_to_string(i8* %call.i23, i8* %ref.tmp.sroa.26.0, i8* %func_name) #14
  %call.i29 = tail call i8* @halide_string_to_string(i8* %call.i26, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.74, i32 0, i32 0)) #14
  %conv.i32 = sext i32 %required_size to i64
  %call.i33 = tail call i8* @halide_int64_to_string(i8* %call.i29, i8* %ref.tmp.sroa.26.0, i64 %conv.i32, i32 1) #14
  %call.i36 = tail call i8* @halide_string_to_string(i8* %call.i33, i8* %ref.tmp.sroa.26.0, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.64.78, i32 0, i32 0)) #14
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EEC2EPvPc.exit
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i36 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -45
}

; Function Attrs: nounwind
define weak i32 @halide_error_device_crop_failed(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call.i = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i = icmp eq i8* %call.i, null
  br i1 %tobool.not.i, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %entry
  %call.i316 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([77 x i8], [77 x i8]* @.str.75, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %entry
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i3 = tail call i8* @halide_string_to_string(i8* nonnull %call.i, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([77 x i8], [77 x i8]* @.str.75, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i3 to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i) #14
  ret i32 -41
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* %ptr, i64 %len) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_check_memory_is_initialized(i8* %user_context, i8* %ptr, i64 %len, i8* %name) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_check_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* %b, i8* %buf_name) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 @halide_msan_annotate_buffer_is_initialized(i8* %user_context, %struct.halide_buffer_t* %b) local_unnamed_addr #2 {
entry:
  ret i32 0
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_msan_annotate_buffer_is_initialized_as_destructor(i8* %user_context, i8* %b) local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind
define weak i32 @halide_qurt_hvx_lock(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @qurt_hvx_lock(i32 1) #14
  %cmp.not = icmp eq i32 %call, 0
  br i1 %cmp.not, label %cleanup, label %if.then

if.then:                                          ; preds = %entry
  %call.i17 = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i19 = icmp eq i8* %call.i17, null
  br i1 %tobool.not.i19, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %if.then
  %call.i30 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.4.91, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i17, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i = tail call i8* @halide_string_to_string(i8* nonnull %call.i17, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.4.91, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i17 to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i17, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i17) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i17) #14
  br label %cleanup

cleanup:                                          ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit, %entry
  %retval.0 = phi i32 [ -1, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit ], [ 0, %entry ]
  ret i32 %retval.0
}

declare i32 @qurt_hvx_lock(i32) local_unnamed_addr #1

; Function Attrs: nounwind
define weak i32 @halide_qurt_hvx_unlock(i8* %user_context) local_unnamed_addr #4 {
entry:
  %call = tail call i32 @qurt_hvx_unlock() #14
  %cmp.not = icmp eq i32 %call, 0
  br i1 %cmp.not, label %cleanup, label %if.then

if.then:                                          ; preds = %entry
  %call.i13 = tail call i8* @malloc(i32 1024) #14
  %tobool.not.i15 = icmp eq i8* %call.i13, null
  br i1 %tobool.not.i15, label %if.then.i, label %if.else.i

if.then.i:                                        ; preds = %if.then
  %call.i26 = tail call i8* @halide_string_to_string(i8* null, i8* null, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.6.93, i32 0, i32 0)) #14
  tail call void @halide_error(i8* %user_context, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.7.92, i32 0, i32 0)) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

if.else.i:                                        ; preds = %if.then
  %add.ptr.i = getelementptr inbounds i8, i8* %call.i13, i32 1023
  store i8 0, i8* %add.ptr.i, align 1, !tbaa !22
  %call.i = tail call i8* @halide_string_to_string(i8* nonnull %call.i13, i8* nonnull %add.ptr.i, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.6.93, i32 0, i32 0)) #14
  %sub.ptr.lhs.cast.i.i = ptrtoint i8* %call.i to i32
  %sub.ptr.rhs.cast.i.i = ptrtoint i8* %call.i13 to i32
  %sub.ptr.sub.i.i = sub i32 1, %sub.ptr.rhs.cast.i.i
  %add.i.i = add i32 %sub.ptr.sub.i.i, %sub.ptr.lhs.cast.i.i
  %conv.i.i = sext i32 %add.i.i to i64
  %call.i.i = tail call i32 @halide_msan_annotate_memory_is_initialized(i8* %user_context, i8* nonnull %call.i13, i64 %conv.i.i) #14
  tail call void @halide_error(i8* %user_context, i8* nonnull %call.i13) #14
  br label %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit

_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit: ; preds = %if.else.i, %if.then.i
  tail call void @free(i8* %call.i13) #14
  br label %cleanup

cleanup:                                          ; preds = %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit, %entry
  %retval.0 = phi i32 [ -1, %_ZN6Halide7Runtime8Internal12_GLOBAL__N_17PrinterILNS1_11PrinterTypeE1ELy1024EED2Ev.exit ], [ 0, %entry ]
  ret i32 %retval.0
}

declare i32 @qurt_hvx_unlock() local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_qurt_hvx_unlock_as_destructor(i8* %user_context, i8* %0) local_unnamed_addr #0 {
entry:
  %call = tail call i32 @halide_qurt_hvx_unlock(i8* %user_context) #15
  ret void
}

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32>) #9

; Function Attrs: nounwind readnone
declare <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32>, <32 x i32>, i32) #9

; Function Attrs: nounwind mustprogress
define weak i8* @halide_vtcm_malloc(i8* %user_context, i32 %size) local_unnamed_addr #0 {
entry:
  %call = tail call i8* @HAP_request_VTCM(i32 %size, i32 1) #14
  ret i8* %call
}

declare i8* @HAP_request_VTCM(i32, i32) local_unnamed_addr #1

; Function Attrs: nounwind mustprogress
define weak void @halide_vtcm_free(i8* %user_context, i8* %addr) local_unnamed_addr #0 {
entry:
  %call = tail call i32 @HAP_release_VTCM(i8* %addr) #14
  ret void
}

declare i32 @HAP_release_VTCM(i8*) local_unnamed_addr #1

; Function Attrs: nounwind
define weak i32 @halide_default_can_use_target_features(i32 %count, i64* %features) #4 {
entry:
  %tmp = alloca %"struct.Halide::Runtime::Internal::CpuFeatures", align 8
  tail call void @halide_mutex_lock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE) #14
  %0 = load i8, i8* @_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE, align 1, !tbaa !18, !range !21
  %tobool.not = icmp eq i8 %0, 0
  br i1 %tobool.not, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  %1 = bitcast %"struct.Halide::Runtime::Internal::CpuFeatures"* %tmp to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1) #11
  call void @_ZN6Halide7Runtime8Internal23halide_get_cpu_featuresEv(%"struct.Halide::Runtime::Internal::CpuFeatures"* nonnull sret(%"struct.Halide::Runtime::Internal::CpuFeatures") align 8 %tmp) #14
  %call = call i8* @memcpy(i8* bitcast ([4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE to i8*), i8* nonnull %1, i32 32) #14
  store i8 1, i8* @_ZN6Halide7Runtime8Internal31halide_cpu_features_initializedE, align 1, !tbaa !18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1) #11
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  call void @halide_mutex_unlock(%struct.halide_mutex* nonnull @_ZN6Halide7Runtime8Internal36halide_cpu_features_initialized_lockE) #14
  %cmp.not = icmp eq i32 %count, 2
  br i1 %cmp.not, label %if.end2, label %if.then1

if.then1:                                         ; preds = %if.end
  call void @halide_error(i8* null, i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.94, i32 0, i32 0)) #14
  br label %if.end2

if.end2:                                          ; preds = %if.then1, %if.end
  %2 = load i64, i64* %features, align 8, !tbaa !26
  %3 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i32 0, i32 0), align 8, !tbaa !26
  %and = and i64 %3, %2
  %cmp5.not = icmp eq i64 %and, 0
  br i1 %cmp5.not, label %for.inc.critedge, label %if.then6

if.then6:                                         ; preds = %if.end2
  %4 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i32 0, i32 2), align 8, !tbaa !26
  %and8 = and i64 %4, %and
  %cmp9.not = icmp eq i64 %and8, %and
  br i1 %cmp9.not, label %for.inc.critedge, label %cleanup13

for.inc.critedge:                                 ; preds = %if.then6, %if.end2
  %arrayidx.1 = getelementptr inbounds i64, i64* %features, i32 1
  %5 = load i64, i64* %arrayidx.1, align 8, !tbaa !26
  %6 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i32 0, i32 1), align 8, !tbaa !26
  %and.1 = and i64 %6, %5
  %cmp5.not.1 = icmp eq i64 %and.1, 0
  br i1 %cmp5.not.1, label %for.inc.critedge.1, label %if.then6.1

cleanup13:                                        ; preds = %for.inc.critedge.1, %if.then6.1, %if.then6
  %cmp3.lcssa = phi i32 [ 0, %if.then6 ], [ 0, %if.then6.1 ], [ 1, %for.inc.critedge.1 ]
  ret i32 %cmp3.lcssa

if.then6.1:                                       ; preds = %for.inc.critedge
  %7 = load i64, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @_ZN6Halide7Runtime8Internal27halide_cpu_features_storageE, i32 0, i32 3), align 8, !tbaa !26
  %and8.1 = and i64 %7, %and.1
  %cmp9.not.1 = icmp eq i64 %and8.1, %and.1
  br i1 %cmp9.not.1, label %for.inc.critedge.1, label %cleanup13

for.inc.critedge.1:                               ; preds = %if.then6.1, %for.inc.critedge
  br label %cleanup13
}

; Function Attrs: nounwind willreturn mustprogress
define weak i32 (i32, i64*)* @halide_set_custom_can_use_target_features(i32 (i32, i64*)* %fn) local_unnamed_addr #2 {
entry:
  %0 = load i32 (i32, i64*)*, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 4, !tbaa !10
  store i32 (i32, i64*)* %fn, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 4, !tbaa !10
  ret i32 (i32, i64*)* %0
}

; Function Attrs: nounwind mustprogress
define weak i32 @halide_can_use_target_features(i32 %count, i64* %features) local_unnamed_addr #0 {
entry:
  %0 = load i32 (i32, i64*)*, i32 (i32, i64*)** @_ZN6Halide7Runtime8Internal30custom_can_use_target_featuresE, align 4, !tbaa !10
  %call = tail call i32 %0(i32 %count, i64* %features) #14
  ret i32 %call
}

; Function Attrs: nounwind willreturn
define linkonce void @_ZN6Halide7Runtime8Internal23halide_get_cpu_featuresEv(%"struct.Halide::Runtime::Internal::CpuFeatures"* noalias sret(%"struct.Halide::Runtime::Internal::CpuFeatures") align 8 %agg.result) local_unnamed_addr #7 {
entry:
  %arrayidx.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::CpuFeatures", %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result, i32 0, i32 0, i32 0
  store i64 0, i64* %arrayidx.i, align 8, !tbaa !26
  %arrayidx2.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::CpuFeatures", %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result, i32 0, i32 1, i32 0
  store i64 0, i64* %arrayidx2.i, align 8, !tbaa !26
  %arrayidx.1.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::CpuFeatures", %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result, i32 0, i32 0, i32 1
  store i64 0, i64* %arrayidx.1.i, align 8, !tbaa !26
  %arrayidx2.1.i = getelementptr inbounds %"struct.Halide::Runtime::Internal::CpuFeatures", %"struct.Halide::Runtime::Internal::CpuFeatures"* %agg.result, i32 0, i32 1, i32 1
  store i64 0, i64* %arrayidx2.1.i, align 8, !tbaa !26
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_use_jit_module() local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind willreturn mustprogress
define weak void @halide_release_jit_module() local_unnamed_addr #2 {
entry:
  ret void
}

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind readnone
declare <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32>, <32 x i32>) #9

; Function Attrs: nounwind
define i32 @conv_nn_hvx128(%struct.halide_buffer_t* noalias nocapture readonly %input.buffer, i8 %input_zero, %struct.halide_buffer_t* noalias nocapture readonly %filter.buffer, i8 %filter_zero, %struct.halide_buffer_t* noalias nocapture readonly %bias.buffer, i32 %stride_x, i32 %stride_y, i32 %dilation_x, i32 %dilation_y, i32 %output_multiplier, i32 %a497, i8 %output_zero, i8 %output_min, i8 %output_max, %struct.halide_buffer_t* noalias nocapture readonly %output.buffer) local_unnamed_addr #10 {
if.end.i:
  %hvx_lock_result = tail call i32 @halide_qurt_hvx_lock(i8* null) #11
  %host.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %bias.buffer, i32 0, i32 2
  %0 = bitcast i8** %host.i to i32**
  %1 = load i32*, i32** %0, align 4, !tbaa !43
  %2 = bitcast i32* %1 to i8*
  %dim.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %bias.buffer, i32 0, i32 6
  %3 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i, align 8, !tbaa !46
  %extent.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %3, i32 0, i32 1
  %4 = load i32, i32* %extent.i, align 4, !tbaa !49
  %host.i391 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %filter.buffer, i32 0, i32 2
  %5 = load i8*, i8** %host.i391, align 4, !tbaa !43
  %dim.i392 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %filter.buffer, i32 0, i32 6
  %6 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i392, align 8, !tbaa !46
  %extent.i407 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 2, i32 1
  %7 = load i32, i32* %extent.i407, align 4, !tbaa !49
  %stride.i413 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 3, i32 2
  %8 = load i32, i32* %stride.i413, align 4, !tbaa !50
  %extent.i417 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 4, i32 1
  %9 = load i32, i32* %extent.i417, align 4, !tbaa !49
  %stride.i419 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 4, i32 2
  %10 = load i32, i32* %stride.i419, align 4, !tbaa !50
  %extent.i423 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 5, i32 1
  %11 = load i32, i32* %extent.i423, align 4, !tbaa !49
  %stride.i425 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %6, i32 5, i32 2
  %12 = load i32, i32* %stride.i425, align 4, !tbaa !50
  %host.i426 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %input.buffer, i32 0, i32 2
  %13 = load i8*, i8** %host.i426, align 4, !tbaa !43
  %dim.i427 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %input.buffer, i32 0, i32 6
  %14 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i427, align 8, !tbaa !46
  %extent.i430 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 0, i32 1
  %15 = load i32, i32* %extent.i430, align 4, !tbaa !49
  %min.i434 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 1, i32 0
  %16 = load i32, i32* %min.i434, align 4, !tbaa !47
  %stride.i436 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 1, i32 2
  %17 = load i32, i32* %stride.i436, align 4, !tbaa !50
  %min.i438 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 2, i32 0
  %18 = load i32, i32* %min.i438, align 4, !tbaa !47
  %stride.i440 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 2, i32 2
  %19 = load i32, i32* %stride.i440, align 4, !tbaa !50
  %min.i442 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 3, i32 0
  %20 = load i32, i32* %min.i442, align 4, !tbaa !47
  %extent.i444 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 3, i32 1
  %21 = load i32, i32* %extent.i444, align 4, !tbaa !49
  %stride.i446 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %14, i32 3, i32 2
  %22 = load i32, i32* %stride.i446, align 4, !tbaa !50
  %host.i447 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %output.buffer, i32 0, i32 2
  %23 = load i8*, i8** %host.i447, align 4, !tbaa !43
  %dim.i448 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %output.buffer, i32 0, i32 6
  %24 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i448, align 8, !tbaa !46
  %min.i455 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 1, i32 0
  %25 = load i32, i32* %min.i455, align 4, !tbaa !47
  %extent.i457 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 1, i32 1
  %26 = load i32, i32* %extent.i457, align 4, !tbaa !49
  %stride.i459 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 1, i32 2
  %27 = load i32, i32* %stride.i459, align 4, !tbaa !50
  %min.i461 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 2, i32 0
  %28 = load i32, i32* %min.i461, align 4, !tbaa !47
  %extent.i463 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 2, i32 1
  %29 = load i32, i32* %extent.i463, align 4, !tbaa !49
  %stride.i465 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 2, i32 2
  %30 = load i32, i32* %stride.i465, align 4, !tbaa !50
  %stride.i471 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %24, i32 3, i32 2
  %31 = load i32, i32* %stride.i471, align 4, !tbaa !50
  %32 = add nsw i32 %4, -1
  %a0 = ashr i32 %32, 5
  %33 = icmp sgt i32 %a0, -1
  %t1217 = select i1 %33, i32 %a0, i32 -1
  %34 = shl i32 %t1217, 7
  %35 = add i32 %34, 268
  %cmp7.i = icmp ugt i32 %35, 16384
  br i1 %cmp7.i, label %pseudostack_alloc.exit, label %then_bb

pseudostack_alloc.exit:                           ; preds = %if.end.i
  %call.i = tail call i8* @halide_malloc(i8* null, i32 %35) #14
  %.not = icmp eq i8* %call.i, null
  br i1 %.not, label %then_bb, label %"pseudostack_alloc.exit.produce bias_im_global_wrapper$0_crit_edge", !prof !95

"pseudostack_alloc.exit.produce bias_im_global_wrapper$0_crit_edge": ; preds = %pseudostack_alloc.exit
  %36 = bitcast i8* %call.i to i32*
  br label %"produce bias_im_global_wrapper$0"

then_bb:                                          ; preds = %if.end.i, %pseudostack_alloc.exit
  %37 = alloca i32, i32 %35, align 128
  %38 = bitcast i32* %37 to i8*
  br label %"produce bias_im_global_wrapper$0"

"produce bias_im_global_wrapper$0":               ; preds = %"pseudostack_alloc.exit.produce bias_im_global_wrapper$0_crit_edge", %then_bb
  %"bias_im_global_wrapper$0.pseudostack_slot.sroa.0.0" = phi i8* [ %call.i, %"pseudostack_alloc.exit.produce bias_im_global_wrapper$0_crit_edge" ], [ %38, %then_bb ]
  %"bias_im_global_wrapper$0" = phi i32* [ %36, %"pseudostack_alloc.exit.produce bias_im_global_wrapper$0_crit_edge" ], [ %37, %then_bb ]
  %39 = icmp sgt i32 %4, 0
  br i1 %39, label %"for bias_im_global_wrapper$0.s0._0.preheader.old", label %"end for bias_im_global_wrapper$0.s0._0", !prof !96

"for bias_im_global_wrapper$0.s0._0.preheader.old": ; preds = %"produce bias_im_global_wrapper$0"
  %40 = shl nuw i32 %4, 2
  %41 = ptrtoint i32* %1 to i32
  %42 = ptrtoint i8* %"bias_im_global_wrapper$0.pseudostack_slot.sroa.0.0" to i32
  %43 = bitcast i32* %1 to i8*
  %44 = icmp ult i8* %"bias_im_global_wrapper$0.pseudostack_slot.sroa.0.0", %43
  %45 = sub i32 %42, %41
  %46 = icmp sle i32 %40, %45
  %47 = or i1 %44, %46
  br i1 %47, label %"for bias_im_global_wrapper$0.s0._0.rtli", label %"for bias_im_global_wrapper$0.s0._0.preheader"

"for bias_im_global_wrapper$0.s0._0.preheader":   ; preds = %"for bias_im_global_wrapper$0.s0._0.preheader.old"
  %48 = add i32 %4, -1
  %xtraiter = and i32 %4, 7
  %49 = icmp ult i32 %48, 7
  br i1 %49, label %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa", label %"for bias_im_global_wrapper$0.s0._0.preheader.new"

"for bias_im_global_wrapper$0.s0._0.preheader.new": ; preds = %"for bias_im_global_wrapper$0.s0._0.preheader"
  %unroll_iter = and i32 %4, -8
  br label %"for bias_im_global_wrapper$0.s0._0"

"for bias_im_global_wrapper$0.s0._0.rtli":        ; preds = %"for bias_im_global_wrapper$0.s0._0.preheader.old"
  call void @llvm.memmove.p0i8.p0i8.i32(i8* nonnull align 4 %"bias_im_global_wrapper$0.pseudostack_slot.sroa.0.0", i8* align 4 %2, i32 %40, i1 false)
  br label %"end for bias_im_global_wrapper$0.s0._0"

"for bias_im_global_wrapper$0.s0._0":             ; preds = %"for bias_im_global_wrapper$0.s0._0", %"for bias_im_global_wrapper$0.s0._0.preheader.new"
  %"bias_im_global_wrapper$0.s0._0" = phi i32 [ 0, %"for bias_im_global_wrapper$0.s0._0.preheader.new" ], [ %81, %"for bias_im_global_wrapper$0.s0._0" ]
  %niter = phi i32 [ %unroll_iter, %"for bias_im_global_wrapper$0.s0._0.preheader.new" ], [ %niter.nsub.7, %"for bias_im_global_wrapper$0.s0._0" ]
  %50 = getelementptr inbounds i32, i32* %1, i32 %"bias_im_global_wrapper$0.s0._0"
  %51 = load i32, i32* %50, align 4, !tbaa !97
  %52 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %"bias_im_global_wrapper$0.s0._0"
  store i32 %51, i32* %52, align 4, !tbaa !100
  %53 = or i32 %"bias_im_global_wrapper$0.s0._0", 1
  %54 = getelementptr inbounds i32, i32* %1, i32 %53
  %55 = load i32, i32* %54, align 4, !tbaa !97
  %56 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %53
  store i32 %55, i32* %56, align 4, !tbaa !100
  %57 = or i32 %"bias_im_global_wrapper$0.s0._0", 2
  %58 = getelementptr inbounds i32, i32* %1, i32 %57
  %59 = load i32, i32* %58, align 4, !tbaa !97
  %60 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %57
  store i32 %59, i32* %60, align 4, !tbaa !100
  %61 = or i32 %"bias_im_global_wrapper$0.s0._0", 3
  %62 = getelementptr inbounds i32, i32* %1, i32 %61
  %63 = load i32, i32* %62, align 4, !tbaa !97
  %64 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %61
  store i32 %63, i32* %64, align 4, !tbaa !100
  %65 = or i32 %"bias_im_global_wrapper$0.s0._0", 4
  %66 = getelementptr inbounds i32, i32* %1, i32 %65
  %67 = load i32, i32* %66, align 4, !tbaa !97
  %68 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %65
  store i32 %67, i32* %68, align 4, !tbaa !100
  %69 = or i32 %"bias_im_global_wrapper$0.s0._0", 5
  %70 = getelementptr inbounds i32, i32* %1, i32 %69
  %71 = load i32, i32* %70, align 4, !tbaa !97
  %72 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %69
  store i32 %71, i32* %72, align 4, !tbaa !100
  %73 = or i32 %"bias_im_global_wrapper$0.s0._0", 6
  %74 = getelementptr inbounds i32, i32* %1, i32 %73
  %75 = load i32, i32* %74, align 4, !tbaa !97
  %76 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %73
  store i32 %75, i32* %76, align 4, !tbaa !100
  %77 = or i32 %"bias_im_global_wrapper$0.s0._0", 7
  %78 = getelementptr inbounds i32, i32* %1, i32 %77
  %79 = load i32, i32* %78, align 4, !tbaa !97
  %80 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %77
  store i32 %79, i32* %80, align 4, !tbaa !100
  %81 = add nuw nsw i32 %"bias_im_global_wrapper$0.s0._0", 8
  %niter.nsub.7 = add i32 %niter, -8
  %niter.ncmp.7 = icmp eq i32 %niter.nsub.7, 0
  br i1 %niter.ncmp.7, label %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa", label %"for bias_im_global_wrapper$0.s0._0"

"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa": ; preds = %"for bias_im_global_wrapper$0.s0._0", %"for bias_im_global_wrapper$0.s0._0.preheader"
  %"bias_im_global_wrapper$0.s0._0.unr" = phi i32 [ 0, %"for bias_im_global_wrapper$0.s0._0.preheader" ], [ %81, %"for bias_im_global_wrapper$0.s0._0" ]
  %lcmp.mod.not = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod.not, label %"end for bias_im_global_wrapper$0.s0._0", label %"for bias_im_global_wrapper$0.s0._0.epil"

"for bias_im_global_wrapper$0.s0._0.epil":        ; preds = %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa", %"for bias_im_global_wrapper$0.s0._0.epil"
  %"bias_im_global_wrapper$0.s0._0.epil" = phi i32 [ %85, %"for bias_im_global_wrapper$0.s0._0.epil" ], [ %"bias_im_global_wrapper$0.s0._0.unr", %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa" ]
  %epil.iter = phi i32 [ %epil.iter.sub, %"for bias_im_global_wrapper$0.s0._0.epil" ], [ %xtraiter, %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa" ]
  %82 = getelementptr inbounds i32, i32* %1, i32 %"bias_im_global_wrapper$0.s0._0.epil"
  %83 = load i32, i32* %82, align 4, !tbaa !97
  %84 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %"bias_im_global_wrapper$0.s0._0.epil"
  store i32 %83, i32* %84, align 4, !tbaa !100
  %85 = add nuw nsw i32 %"bias_im_global_wrapper$0.s0._0.epil", 1
  %epil.iter.sub = add i32 %epil.iter, -1
  %epil.iter.cmp.not = icmp eq i32 %epil.iter.sub, 0
  br i1 %epil.iter.cmp.not, label %"end for bias_im_global_wrapper$0.s0._0", label %"for bias_im_global_wrapper$0.s0._0.epil", !llvm.loop !102

"end for bias_im_global_wrapper$0.s0._0":         ; preds = %"end for bias_im_global_wrapper$0.s0._0.loopexit.unr-lcssa", %"for bias_im_global_wrapper$0.s0._0.epil", %"for bias_im_global_wrapper$0.s0._0.rtli", %"produce bias_im_global_wrapper$0"
  %86 = icmp sgt i32 %26, 5
  %87 = and i32 %4, 127
  %88 = icmp eq i32 %87, 0
  %89 = and i1 %88, %86
  %90 = or i32 %32, 127
  %91 = icmp sgt i32 %26, 7
  %92 = and i32 %4, 63
  %93 = icmp eq i32 %92, 0
  %94 = and i1 %93, %91
  %95 = or i32 %32, 63
  %96 = and i32 %4, 31
  %97 = icmp eq i32 %96, 0
  %98 = and i1 %97, %91
  %99 = or i32 %32, 31
  %100 = icmp sgt i32 %26, 0
  %101 = and i1 %88, %100
  %102 = icmp slt i32 %4, 32
  %103 = select i1 %102, i32 %4, i32 32
  %104 = add nsw i32 %103, -1
  %a3 = ashr i32 %104, 5
  %105 = icmp slt i32 %a0, 3
  %106 = select i1 %105, i32 %a0, i32 3
  %107 = and i32 %a3, -4
  %b5 = add nsw i32 %107, %106
  %108 = icmp slt i32 %a3, %b5
  %109 = select i1 %108, i32 %a3, i32 %b5
  %110 = add nsw i32 %109, %a0
  %111 = shl nsw i32 %110, 5
  %112 = or i32 %111, 31
  %113 = select i1 %101, i32 %90, i32 %112
  %114 = select i1 %98, i32 %99, i32 %113
  %115 = select i1 %94, i32 %95, i32 %114
  %a2 = select i1 %89, i32 %90, i32 %115
  %116 = icmp sgt i32 %a2, %99
  %a9 = select i1 %116, i32 %a2, i32 %99
  %117 = icmp sgt i32 %a9, -1
  %t1218 = select i1 %117, i32 %a9, i32 -1
  %118 = shl i32 %t1218, 2
  %119 = add i32 %118, 144
  %120 = call i8* @halide_malloc(i8* null, i32 %119)
  %offset_c = bitcast i8* %120 to i32*
  %121 = add nsw i32 %4, 31
  %122 = ashr i32 %121, 5
  br i1 %39, label %"for offset_c.s0.c.c.preheader", label %"consume bias_im_global_wrapper$0.thread", !prof !96

"for offset_c.s0.c.c.preheader":                  ; preds = %"end for bias_im_global_wrapper$0.s0._0"
  %123 = shl nuw i32 %122, 7
  call void @llvm.memset.p0i8.i32(i8* align 128 %120, i8 0, i32 %123, i1 false)
  %.not315 = icmp eq i8 %input_zero, 0
  br i1 %.not315, label %"for offset_c.s2.c.c.preheader", label %"for offset_c.s1.c.co.preheader"

"for offset_c.s1.c.co.preheader":                 ; preds = %"for offset_c.s0.c.c.preheader"
  %124 = icmp sgt i32 %11, 0
  %125 = select i1 %124, i32 %11, i32 0
  %126 = icmp sgt i32 %7, 0
  %127 = insertelement <128 x i8> undef, i8 %input_zero, i32 0
  %128 = shufflevector <128 x i8> %127, <128 x i8> undef, <128 x i32> zeroinitializer
  %129 = icmp sgt i32 %9, 0
  %or.cond = and i1 %124, %129
  %130 = and i1 %or.cond, %126
  br i1 %130, label %"for offset_c.s1.c.co.us.us.us", label %"for offset_c.s2.c.c.preheader", !prof !103

"for offset_c.s1.c.co.us.us.us":                  ; preds = %"for offset_c.s1.c.co.preheader", %"end for offset_c.s1.r19$y.loopexit.split.us.split.us.us.us.us"
  %offset_c.s1.c.co.us.us.us = phi i32 [ %148, %"end for offset_c.s1.r19$y.loopexit.split.us.split.us.us.us.us" ], [ 0, %"for offset_c.s1.c.co.preheader" ]
  %131 = mul nsw i32 %offset_c.s1.c.co.us.us.us, %8
  %132 = shl nsw i32 %offset_c.s1.c.co.us.us.us, 5
  %133 = getelementptr inbounds i32, i32* %offset_c, i32 %132
  %134 = bitcast i32* %133 to <32 x i32>*
  %.pre.pre.pre = load <32 x i32>, <32 x i32>* %134, align 128, !tbaa !104
  br label %"for offset_c.s1.r19$y.us.us.us.us.us"

"for offset_c.s1.r19$y.us.us.us.us.us":           ; preds = %"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us", %"for offset_c.s1.c.co.us.us.us"
  %.pre.pre = phi <32 x i32> [ %144, %"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us" ], [ %.pre.pre.pre, %"for offset_c.s1.c.co.us.us.us" ]
  %"offset_c.s1.r19$y.us.us.us.us.us" = phi i32 [ %147, %"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us" ], [ 0, %"for offset_c.s1.c.co.us.us.us" ]
  %135 = mul nsw i32 %"offset_c.s1.r19$y.us.us.us.us.us", %12
  %t838.us.us.us.us.us = add nsw i32 %135, %131
  br label %"for offset_c.s1.r19$x.us.us.us.us.us.us"

"for offset_c.s1.r19$x.us.us.us.us.us.us":        ; preds = %"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us", %"for offset_c.s1.r19$y.us.us.us.us.us"
  %.pre = phi <32 x i32> [ %144, %"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us" ], [ %.pre.pre, %"for offset_c.s1.r19$y.us.us.us.us.us" ]
  %"offset_c.s1.r19$x.us.us.us.us.us.us" = phi i32 [ %146, %"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us" ], [ 0, %"for offset_c.s1.r19$y.us.us.us.us.us" ]
  %136 = mul nsw i32 %"offset_c.s1.r19$x.us.us.us.us.us.us", %10
  %137 = add nsw i32 %t838.us.us.us.us.us, %136
  br label %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us"

"for offset_c.s1.r19$z.r124.us.us.us.us.us.us":   ; preds = %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us", %"for offset_c.s1.r19$x.us.us.us.us.us.us"
  %138 = phi <32 x i32> [ %144, %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us" ], [ %.pre, %"for offset_c.s1.r19$x.us.us.us.us.us.us" ]
  %"offset_c.s1.r19$z.r124.us.us.us.us.us.us" = phi i32 [ %145, %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us" ], [ 0, %"for offset_c.s1.r19$x.us.us.us.us.us.us" ]
  %139 = shl nsw i32 %"offset_c.s1.r19$z.r124.us.us.us.us.us.us", 7
  %140 = add nsw i32 %137, %139
  %141 = getelementptr inbounds i8, i8* %5, i32 %140
  %142 = bitcast i8* %141 to <128 x i8>*
  %143 = load <128 x i8>, <128 x i8>* %142, align 128, !tbaa !106
  %144 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl(<32 x i32> %138, <128 x i8> %128, <128 x i8> %143, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  store <32 x i32> %144, <32 x i32>* %134, align 128, !tbaa !104
  %145 = add nuw nsw i32 %"offset_c.s1.r19$z.r124.us.us.us.us.us.us", 1
  %.not386.us.us.us.us.us.us = icmp eq i32 %145, %7
  br i1 %.not386.us.us.us.us.us.us, label %"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us", label %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us"

"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us": ; preds = %"for offset_c.s1.r19$z.r124.us.us.us.us.us.us"
  %146 = add nuw nsw i32 %"offset_c.s1.r19$x.us.us.us.us.us.us", 1
  %.not385.us.us.us.us.us.us = icmp eq i32 %146, %9
  br i1 %.not385.us.us.us.us.us.us, label %"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us", label %"for offset_c.s1.r19$x.us.us.us.us.us.us"

"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us": ; preds = %"end for offset_c.s1.r19$z.r124.loopexit.us.us.us.us.us.us"
  %147 = add nuw nsw i32 %"offset_c.s1.r19$y.us.us.us.us.us", 1
  %.not384.us.us.us.us.us = icmp eq i32 %147, %125
  br i1 %.not384.us.us.us.us.us, label %"end for offset_c.s1.r19$y.loopexit.split.us.split.us.us.us.us", label %"for offset_c.s1.r19$y.us.us.us.us.us"

"end for offset_c.s1.r19$y.loopexit.split.us.split.us.us.us.us": ; preds = %"end for offset_c.s1.r19$x.loopexit.split.us.us.us.us.us.us"
  %148 = add nuw nsw i32 %offset_c.s1.c.co.us.us.us, 1
  %.not383.us.us.us = icmp eq i32 %148, %122
  br i1 %.not383.us.us.us, label %"for offset_c.s2.c.c.preheader", label %"for offset_c.s1.c.co.us.us.us"

"consume bias_im_global_wrapper$0.thread":        ; preds = %"end for bias_im_global_wrapper$0.s0._0"
  %149 = zext i8 %filter_zero to i32
  br label %"consume offset_c"

"for offset_c.s2.c.c.preheader":                  ; preds = %"end for offset_c.s1.r19$y.loopexit.split.us.split.us.us.us.us", %"for offset_c.s1.c.co.preheader", %"for offset_c.s0.c.c.preheader"
  %150 = zext i8 %filter_zero to i32
  %151 = zext i8 %input_zero to i32
  %152 = shl nuw nsw i32 %151, 2
  %153 = mul nuw nsw i32 %152, %150
  %154 = mul i32 %153, %7
  %t841.s = mul i32 %154, %9
  %155 = mul i32 %t841.s, %11
  %156 = insertelement <1 x i32> poison, i32 %155, i32 0
  br label %"for offset_c.s2.c.c"

"for offset_c.s2.c.c":                            ; preds = %"for offset_c.s2.c.c.preheader", %"for offset_c.s2.c.c"
  %offset_c.s2.c.c = phi i32 [ %167, %"for offset_c.s2.c.c" ], [ 0, %"for offset_c.s2.c.c.preheader" ]
  %157 = shl nsw i32 %offset_c.s2.c.c, 5
  %158 = getelementptr inbounds i32, i32* %"bias_im_global_wrapper$0", i32 %157
  %159 = bitcast i32* %158 to <32 x i32>*
  %160 = load <32 x i32>, <32 x i32>* %159, align 128, !tbaa !100
  %161 = getelementptr inbounds i32, i32* %offset_c, i32 %157
  %162 = bitcast i32* %161 to <32 x i32>*
  %163 = load <32 x i32>, <32 x i32>* %162, align 128, !tbaa !104
  %164 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %160, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %165 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %166 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %164, <32 x i32> %165, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  store <32 x i32> %166, <32 x i32>* %162, align 128, !tbaa !104
  %167 = add nuw nsw i32 %offset_c.s2.c.c, 1
  %.not382 = icmp eq i32 %167, %122
  br i1 %.not382, label %"consume offset_c", label %"for offset_c.s2.c.c"

"consume offset_c":                               ; preds = %"for offset_c.s2.c.c", %"consume bias_im_global_wrapper$0.thread"
  %168 = phi i32 [ %149, %"consume bias_im_global_wrapper$0.thread" ], [ %150, %"for offset_c.s2.c.c" ]
  %169 = icmp eq i32 %stride_x, 1
  %170 = icmp eq i32 %7, 1
  %171 = and i1 %169, %170
  %172 = icmp eq i32 %15, 4
  %173 = icmp eq i32 %17, 4
  %174 = and i1 %172, %173
  %t844 = and i1 %171, %174
  %t843.not = icmp eq i8 %filter_zero, 0
  br i1 %89, label %then_bb4, label %next_bb5

after_bb3:                                        ; preds = %"end for output.s0.y.rebased182", %"end for output.s0.y.rebased133.loopexit.us", %"end for output.s0.y.rebased80.loopexit.us", %"end for output.s0.y.rebased27.loopexit.us", %"end for output.s0.y.rebased.loopexit.us", %"for output.s0.b.rebased129.preheader", %"for output.s0.b.rebased76.preheader", %"for output.s0.b.rebased23.preheader", %"for output.s0.b.rebased.preheader", %next_bb128, %then_bb127, %then_bb74, %then_bb21, %then_bb4
  %tobool.not.i.not = icmp eq i8* %120, null
  br i1 %tobool.not.i.not, label %land.lhs.true.i487, label %if.then.i472

if.then.i472:                                     ; preds = %after_bb3
  call void @halide_free(i8* null, i8* nonnull %120) #14
  br label %land.lhs.true.i487

land.lhs.true.i487:                               ; preds = %after_bb3, %if.then.i472
  br i1 %cmp7.i, label %if.then.i488, label %call_destructor.exit483

if.then.i488:                                     ; preds = %land.lhs.true.i487
  call void @halide_free(i8* null, i8* nonnull %"bias_im_global_wrapper$0.pseudostack_slot.sroa.0.0") #14
  br label %call_destructor.exit483

call_destructor.exit483:                          ; preds = %if.then.i488, %land.lhs.true.i487
  call void @halide_qurt_hvx_unlock_as_destructor(i8* null, i8* nonnull inttoptr (i32 1 to i8*)) #14
  ret i32 0

then_bb4:                                         ; preds = %"consume offset_c"
  %175 = mul nsw i32 %19, %18
  %176 = mul nsw i32 %22, %20
  %177 = mul nsw i32 %17, %16
  %178 = add i32 %176, %175
  %t852 = add i32 %178, %177
  %179 = icmp sgt i32 %21, 0
  br i1 %179, label %"for output.s0.b.rebased.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased.preheader":              ; preds = %then_bb4
  %180 = mul nsw i32 %17, %stride_x
  %181 = mul nsw i32 %180, 5
  %182 = shl nsw i32 %180, 2
  %183 = mul nsw i32 %180, 3
  %184 = shl nsw i32 %180, 1
  %185 = sub nsw i32 %stride_x, %16
  %186 = mul nsw i32 %185, %17
  %187 = icmp sgt i32 %29, 0
  %.neg796 = mul i32 %30, %28
  %.neg797 = mul i32 %27, %25
  %.neg798 = mul i32 %31, %20
  %reass.add800 = add i32 %.neg796, %.neg797
  %reass.add801 = add i32 %reass.add800, %.neg798
  %188 = add nuw nsw i32 %26, 5
  %189 = ashr i32 %188, 31
  %190 = xor i32 %189, %188
  %191 = zext i32 %190 to i64
  %192 = mul nuw i64 %191, 2863311531
  %193 = lshr i64 %192, 34
  %194 = trunc i64 %193 to i32
  %195 = xor i32 %189, %194
  %196 = icmp sgt i32 %195, 0
  %b14 = add nsw i32 %26, -6
  %197 = icmp sgt i32 %11, 0
  %198 = icmp sgt i32 %9, 0
  %199 = icmp sgt i32 %7, 0
  %200 = ashr i32 %4, 7
  %201 = icmp sgt i32 %4, 127
  %202 = insertelement <32 x i32> undef, i32 %output_multiplier, i32 0
  %203 = shufflevector <32 x i32> %202, <32 x i32> undef, <32 x i32> zeroinitializer
  %204 = sext <32 x i32> %203 to <32 x i64>
  %205 = icmp sgt i32 %a497, 0
  %206 = select i1 %205, i32 %a497, i32 0
  %207 = shl nuw i32 1, %206
  %208 = ashr i32 %207, 1
  %209 = zext i8 %output_zero to i16
  %210 = insertelement <128 x i16> undef, i16 %209, i32 0
  %211 = shufflevector <128 x i16> %210, <128 x i16> undef, <128 x i32> zeroinitializer
  %212 = insertelement <128 x i8> undef, i8 %output_max, i32 0
  %213 = shufflevector <128 x i8> %212, <128 x i8> undef, <128 x i32> zeroinitializer
  %214 = insertelement <128 x i8> undef, i8 %output_min, i32 0
  %215 = shufflevector <128 x i8> %214, <128 x i8> undef, <128 x i32> zeroinitializer
  %216 = insertelement <1 x i32> poison, i32 %208, i32 0
  %217 = insertelement <1 x i32> poison, i32 %a497, i32 0
  br i1 %187, label %"for output.s0.b.rebased.us.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased.us.preheader":           ; preds = %"for output.s0.b.rebased.preheader"
  %218 = add i32 %177, %175
  %219 = add i32 %9, -1
  %brmerge1305.demorgan = and i1 %198, %199
  %xtraiter1510 = and i32 %7, 1
  %220 = icmp eq i32 %7, 1
  %unroll_iter1512 = and i32 %7, -2
  %lcmp.mod1511.not = icmp eq i32 %xtraiter1510, 0
  %xtraiter1514 = and i32 %9, 3
  %221 = icmp ult i32 %219, 3
  %unroll_iter1518 = and i32 %9, -4
  %lcmp.mod1516.not = icmp eq i32 %xtraiter1514, 0
  br label %"for output.s0.b.rebased.us"

"for output.s0.b.rebased.us":                     ; preds = %"for output.s0.b.rebased.us.preheader", %"end for output.s0.y.rebased.loopexit.us"
  %sum_input314.sroa.0.0.us = phi <6 x i32> [ %.us-phi1118.us, %"end for output.s0.y.rebased.loopexit.us" ], [ undef, %"for output.s0.b.rebased.us.preheader" ]
  %output.s0.b.rebased.us = phi i32 [ %228, %"end for output.s0.y.rebased.loopexit.us" ], [ 0, %"for output.s0.b.rebased.us.preheader" ]
  %222 = add nsw i32 %output.s0.b.rebased.us, %20
  %223 = mul nsw i32 %222, %31
  %224 = sub i32 %223, %reass.add801
  %225 = mul nsw i32 %222, %22
  %226 = sub i32 %225, %178
  %227 = sub nsw i32 %225, %t852
  br i1 %196, label %"for output.s0.y.rebased.us.us", label %"end for output.s0.y.rebased.loopexit.us", !prof !96

"end for output.s0.y.rebased.loopexit.us":        ; preds = %"end for output.s0.x.xo.loopexit.us.us", %"for output.s0.b.rebased.us"
  %.us-phi1118.us = phi <6 x i32> [ %sum_input314.sroa.0.0.us, %"for output.s0.b.rebased.us" ], [ %sum_input314.sroa.0.13.us.us, %"end for output.s0.x.xo.loopexit.us.us" ]
  %228 = add nuw nsw i32 %output.s0.b.rebased.us, 1
  %.not370.us = icmp eq i32 %228, %21
  br i1 %.not370.us, label %after_bb3, label %"for output.s0.b.rebased.us"

"for output.s0.y.rebased.us.us":                  ; preds = %"for output.s0.b.rebased.us", %"end for output.s0.x.xo.loopexit.us.us"
  %sum_input314.sroa.0.1.us.us = phi <6 x i32> [ %sum_input314.sroa.0.13.us.us, %"end for output.s0.x.xo.loopexit.us.us" ], [ %sum_input314.sroa.0.0.us, %"for output.s0.b.rebased.us" ]
  %output.s0.y.rebased.us.us = phi i32 [ %849, %"end for output.s0.x.xo.loopexit.us.us" ], [ 0, %"for output.s0.b.rebased.us" ]
  %229 = add nsw i32 %output.s0.y.rebased.us.us, %28
  %230 = mul nsw i32 %229, %30
  %t877.us.us = add i32 %224, %230
  %231 = mul nsw i32 %229, %stride_y
  br label %"for output.s0.x.xo.us.us"

"for output.s0.x.xo.us.us":                       ; preds = %"end for output.s0.c.co.us.us", %"for output.s0.y.rebased.us.us"
  %sum_input314.sroa.0.3.us.us = phi <6 x i32> [ %sum_input314.sroa.0.13.us.us, %"end for output.s0.c.co.us.us" ], [ %sum_input314.sroa.0.1.us.us, %"for output.s0.y.rebased.us.us" ]
  %output.s0.x.xo.us.us = phi i32 [ %794, %"end for output.s0.c.co.us.us" ], [ 0, %"for output.s0.y.rebased.us.us" ]
  %a12.us.us = mul nsw i32 %output.s0.x.xo.us.us, 6
  %232 = icmp slt i32 %a12.us.us, %b14
  %output.s0.x.x.base.s.us.us = select i1 %232, i32 %a12.us.us, i32 %b14
  br i1 %t843.not, label %"consume sum_input.us.us", label %then_bb7.us.us

then_bb7.us.us:                                   ; preds = %"for output.s0.x.xo.us.us"
  br i1 %t844, label %then_bb10.us.us, label %next_bb11.us.us

next_bb11.us.us:                                  ; preds = %then_bb7.us.us
  br i1 %197, label %"for sum_input.s1.r19$y12.preheader.us.us", label %"consume sum_input.us.us", !prof !96

then_bb10.us.us:                                  ; preds = %then_bb7.us.us
  br i1 %197, label %"for sum_input.s1.r19$y.preheader.us.us", label %"consume sum_input.us.us", !prof !96

"for sum_input.s1.r19$y.us.us":                   ; preds = %"for sum_input.s1.r19$y.preheader.us.us", %"end for sum_input.s1.r19$x.us.us"
  %sum_input314.sroa.0.5.us.us = phi <6 x i32> [ %sum_input314.sroa.0.7.us.us, %"end for sum_input.s1.r19$x.us.us" ], [ zeroinitializer, %"for sum_input.s1.r19$y.preheader.us.us" ]
  %"sum_input.s1.r19$y.us.us" = phi i32 [ %343, %"end for sum_input.s1.r19$x.us.us" ], [ 0, %"for sum_input.s1.r19$y.preheader.us.us" ]
  br i1 %198, label %"for sum_input.s1.r19$x.preheader.us.us", label %"end for sum_input.s1.r19$x.us.us", !prof !96

"for sum_input.s1.r19$x.us.us":                   ; preds = %"for sum_input.s1.r19$x.preheader.us.us", %"for sum_input.s1.r19$x.us.us"
  %sum_input314.sroa.0.6.us.us = phi <6 x i32> [ %319, %"for sum_input.s1.r19$x.us.us" ], [ %sum_input314.sroa.0.5.us.us, %"for sum_input.s1.r19$x.preheader.us.us" ]
  %"sum_input.s1.r19$x.us.us" = phi i32 [ %320, %"for sum_input.s1.r19$x.us.us" ], [ 0, %"for sum_input.s1.r19$x.preheader.us.us" ]
  %niter1519 = phi i32 [ %niter1519.nsub.3, %"for sum_input.s1.r19$x.us.us" ], [ %unroll_iter1518, %"for sum_input.s1.r19$x.preheader.us.us" ]
  %233 = mul nsw i32 %"sum_input.s1.r19$x.us.us", %dilation_x
  %reass.add806.us.us = add i32 %846, %233
  %reass.mul807.us.us = shl i32 %reass.add806.us.us, 2
  %234 = add i32 %t880.us.us, %reass.mul807.us.us
  %235 = getelementptr inbounds i8, i8* %13, i32 %234
  %236 = bitcast i8* %235 to <24 x i8>*
  %237 = load <24 x i8>, <24 x i8>* %236, align 4, !tbaa !108
  %t1220.us.us = zext <24 x i8> %237 to <24 x i16>
  %238 = shufflevector <24 x i16> %t1220.us.us, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %239 = bitcast <64 x i16> %238 to <32 x i32>
  %240 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %239)
  %241 = bitcast <32 x i32> %240 to <64 x i16>
  %242 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %239)
  %243 = bitcast <32 x i32> %242 to <64 x i16>
  %244 = add <64 x i16> %243, %241
  %245 = shufflevector <64 x i16> %244, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1219.us.us = zext <12 x i16> %245 to <12 x i32>
  %246 = shufflevector <12 x i32> %t1219.us.us, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %247 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %246, i32 -4)
  %248 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %247)
  %249 = shufflevector <32 x i32> %248, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %250 = add nsw <6 x i32> %249, %sum_input314.sroa.0.6.us.us
  %251 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %247)
  %252 = shufflevector <32 x i32> %251, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %253 = add nsw <6 x i32> %250, %252
  %254 = or i32 %"sum_input.s1.r19$x.us.us", 1
  %255 = mul nsw i32 %254, %dilation_x
  %reass.add806.us.us.1 = add i32 %846, %255
  %reass.mul807.us.us.1 = shl i32 %reass.add806.us.us.1, 2
  %256 = add i32 %t880.us.us, %reass.mul807.us.us.1
  %257 = getelementptr inbounds i8, i8* %13, i32 %256
  %258 = bitcast i8* %257 to <24 x i8>*
  %259 = load <24 x i8>, <24 x i8>* %258, align 4, !tbaa !108
  %t1220.us.us.1 = zext <24 x i8> %259 to <24 x i16>
  %260 = shufflevector <24 x i16> %t1220.us.us.1, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %261 = bitcast <64 x i16> %260 to <32 x i32>
  %262 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %261)
  %263 = bitcast <32 x i32> %262 to <64 x i16>
  %264 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %261)
  %265 = bitcast <32 x i32> %264 to <64 x i16>
  %266 = add <64 x i16> %265, %263
  %267 = shufflevector <64 x i16> %266, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1219.us.us.1 = zext <12 x i16> %267 to <12 x i32>
  %268 = shufflevector <12 x i32> %t1219.us.us.1, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %269 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %268, i32 -4)
  %270 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %269)
  %271 = shufflevector <32 x i32> %270, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %272 = add nsw <6 x i32> %271, %253
  %273 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %269)
  %274 = shufflevector <32 x i32> %273, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %275 = add nsw <6 x i32> %272, %274
  %276 = or i32 %"sum_input.s1.r19$x.us.us", 2
  %277 = mul nsw i32 %276, %dilation_x
  %reass.add806.us.us.2 = add i32 %846, %277
  %reass.mul807.us.us.2 = shl i32 %reass.add806.us.us.2, 2
  %278 = add i32 %t880.us.us, %reass.mul807.us.us.2
  %279 = getelementptr inbounds i8, i8* %13, i32 %278
  %280 = bitcast i8* %279 to <24 x i8>*
  %281 = load <24 x i8>, <24 x i8>* %280, align 4, !tbaa !108
  %t1220.us.us.2 = zext <24 x i8> %281 to <24 x i16>
  %282 = shufflevector <24 x i16> %t1220.us.us.2, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %283 = bitcast <64 x i16> %282 to <32 x i32>
  %284 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %283)
  %285 = bitcast <32 x i32> %284 to <64 x i16>
  %286 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %283)
  %287 = bitcast <32 x i32> %286 to <64 x i16>
  %288 = add <64 x i16> %287, %285
  %289 = shufflevector <64 x i16> %288, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1219.us.us.2 = zext <12 x i16> %289 to <12 x i32>
  %290 = shufflevector <12 x i32> %t1219.us.us.2, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %291 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %290, i32 -4)
  %292 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %291)
  %293 = shufflevector <32 x i32> %292, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %294 = add nsw <6 x i32> %293, %275
  %295 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %291)
  %296 = shufflevector <32 x i32> %295, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %297 = add nsw <6 x i32> %294, %296
  %298 = or i32 %"sum_input.s1.r19$x.us.us", 3
  %299 = mul nsw i32 %298, %dilation_x
  %reass.add806.us.us.3 = add i32 %846, %299
  %reass.mul807.us.us.3 = shl i32 %reass.add806.us.us.3, 2
  %300 = add i32 %t880.us.us, %reass.mul807.us.us.3
  %301 = getelementptr inbounds i8, i8* %13, i32 %300
  %302 = bitcast i8* %301 to <24 x i8>*
  %303 = load <24 x i8>, <24 x i8>* %302, align 4, !tbaa !108
  %t1220.us.us.3 = zext <24 x i8> %303 to <24 x i16>
  %304 = shufflevector <24 x i16> %t1220.us.us.3, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %305 = bitcast <64 x i16> %304 to <32 x i32>
  %306 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %305)
  %307 = bitcast <32 x i32> %306 to <64 x i16>
  %308 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %305)
  %309 = bitcast <32 x i32> %308 to <64 x i16>
  %310 = add <64 x i16> %309, %307
  %311 = shufflevector <64 x i16> %310, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1219.us.us.3 = zext <12 x i16> %311 to <12 x i32>
  %312 = shufflevector <12 x i32> %t1219.us.us.3, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %313 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %312, i32 -4)
  %314 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %313)
  %315 = shufflevector <32 x i32> %314, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %316 = add nsw <6 x i32> %315, %297
  %317 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %313)
  %318 = shufflevector <32 x i32> %317, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %319 = add nsw <6 x i32> %316, %318
  %320 = add nuw nsw i32 %"sum_input.s1.r19$x.us.us", 4
  %niter1519.nsub.3 = add i32 %niter1519, -4
  %niter1519.ncmp.3 = icmp eq i32 %niter1519.nsub.3, 0
  br i1 %niter1519.ncmp.3, label %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x.us.us"

"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa": ; preds = %"for sum_input.s1.r19$x.us.us", %"for sum_input.s1.r19$x.preheader.us.us"
  %.lcssa1395.ph = phi <6 x i32> [ undef, %"for sum_input.s1.r19$x.preheader.us.us" ], [ %319, %"for sum_input.s1.r19$x.us.us" ]
  %sum_input314.sroa.0.6.us.us.unr = phi <6 x i32> [ %sum_input314.sroa.0.5.us.us, %"for sum_input.s1.r19$x.preheader.us.us" ], [ %319, %"for sum_input.s1.r19$x.us.us" ]
  %"sum_input.s1.r19$x.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x.preheader.us.us" ], [ %320, %"for sum_input.s1.r19$x.us.us" ]
  br i1 %lcmp.mod1516.not, label %"end for sum_input.s1.r19$x.us.us", label %"for sum_input.s1.r19$x.us.us.epil"

"for sum_input.s1.r19$x.us.us.epil":              ; preds = %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x.us.us.epil"
  %sum_input314.sroa.0.6.us.us.epil = phi <6 x i32> [ %341, %"for sum_input.s1.r19$x.us.us.epil" ], [ %sum_input314.sroa.0.6.us.us.unr, %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa" ]
  %"sum_input.s1.r19$x.us.us.epil" = phi i32 [ %342, %"for sum_input.s1.r19$x.us.us.epil" ], [ %"sum_input.s1.r19$x.us.us.unr", %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa" ]
  %epil.iter1515 = phi i32 [ %epil.iter1515.sub, %"for sum_input.s1.r19$x.us.us.epil" ], [ %xtraiter1514, %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa" ]
  %321 = mul nsw i32 %"sum_input.s1.r19$x.us.us.epil", %dilation_x
  %reass.add806.us.us.epil = add i32 %846, %321
  %reass.mul807.us.us.epil = shl i32 %reass.add806.us.us.epil, 2
  %322 = add i32 %t880.us.us, %reass.mul807.us.us.epil
  %323 = getelementptr inbounds i8, i8* %13, i32 %322
  %324 = bitcast i8* %323 to <24 x i8>*
  %325 = load <24 x i8>, <24 x i8>* %324, align 4, !tbaa !108
  %t1220.us.us.epil = zext <24 x i8> %325 to <24 x i16>
  %326 = shufflevector <24 x i16> %t1220.us.us.epil, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %327 = bitcast <64 x i16> %326 to <32 x i32>
  %328 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %327)
  %329 = bitcast <32 x i32> %328 to <64 x i16>
  %330 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %327)
  %331 = bitcast <32 x i32> %330 to <64 x i16>
  %332 = add <64 x i16> %331, %329
  %333 = shufflevector <64 x i16> %332, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1219.us.us.epil = zext <12 x i16> %333 to <12 x i32>
  %334 = shufflevector <12 x i32> %t1219.us.us.epil, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %335 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %334, i32 -4)
  %336 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %335)
  %337 = shufflevector <32 x i32> %336, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %338 = add nsw <6 x i32> %337, %sum_input314.sroa.0.6.us.us.epil
  %339 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %335)
  %340 = shufflevector <32 x i32> %339, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %341 = add nsw <6 x i32> %338, %340
  %342 = add nuw nsw i32 %"sum_input.s1.r19$x.us.us.epil", 1
  %epil.iter1515.sub = add i32 %epil.iter1515, -1
  %epil.iter1515.cmp.not = icmp eq i32 %epil.iter1515.sub, 0
  br i1 %epil.iter1515.cmp.not, label %"end for sum_input.s1.r19$x.us.us", label %"for sum_input.s1.r19$x.us.us.epil", !llvm.loop !110

"end for sum_input.s1.r19$x.us.us":               ; preds = %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x.us.us.epil", %"for sum_input.s1.r19$y.us.us"
  %sum_input314.sroa.0.7.us.us = phi <6 x i32> [ %sum_input314.sroa.0.5.us.us, %"for sum_input.s1.r19$y.us.us" ], [ %.lcssa1395.ph, %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa" ], [ %341, %"for sum_input.s1.r19$x.us.us.epil" ]
  %343 = add nuw nsw i32 %"sum_input.s1.r19$y.us.us", 1
  %.not380.us.us = icmp eq i32 %343, %11
  br i1 %.not380.us.us, label %"consume sum_input.us.us", label %"for sum_input.s1.r19$y.us.us"

"consume sum_input.us.us":                        ; preds = %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us", %"end for sum_input.s1.r19$x.us.us", %"for sum_input.s1.r19$y12.preheader.us.us", %then_bb10.us.us, %next_bb11.us.us, %"for output.s0.x.xo.us.us"
  %sum_input314.sroa.0.13.us.us = phi <6 x i32> [ %sum_input314.sroa.0.3.us.us, %"for output.s0.x.xo.us.us" ], [ zeroinitializer, %then_bb10.us.us ], [ zeroinitializer, %next_bb11.us.us ], [ zeroinitializer, %"for sum_input.s1.r19$y12.preheader.us.us" ], [ %sum_input314.sroa.0.7.us.us, %"end for sum_input.s1.r19$x.us.us" ], [ %.lcssa, %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us" ]
  br i1 %201, label %"for output.s0.c.co.preheader.us.us", label %"end for output.s0.c.co.us.us", !prof !96

"for output.s0.c.co.us.us":                       ; preds = %"for output.s0.c.co.preheader.us.us", %"consume convolved.us.us"
  %output.s0.c.co.us.us = phi i32 [ %793, %"consume convolved.us.us" ], [ 0, %"for output.s0.c.co.preheader.us.us" ]
  %344 = shl nsw i32 %output.s0.c.co.us.us, 7
  %345 = getelementptr inbounds i32, i32* %offset_c, i32 %344
  %346 = bitcast i32* %345 to <32 x i32>*
  %347 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  br i1 %t843.not, label %then_bb19.us.us, label %next_bb20.us.us

next_bb20.us.us:                                  ; preds = %"for output.s0.c.co.us.us"
  %348 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %816, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %349 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %347, <32 x i32> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %350 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  %351 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %818, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %352 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %350, <32 x i32> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %353 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  %354 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %820, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %355 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %353, <32 x i32> %354, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %356 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  %357 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %822, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %358 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %356, <32 x i32> %357, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %359 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  %360 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %824, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %361 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %359, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %362 = load <32 x i32>, <32 x i32>* %346, align 128, !tbaa !104
  %363 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %826, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %364 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %362, <32 x i32> %363, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %365 = getelementptr inbounds i32, i32* %345, i32 32
  %366 = bitcast i32* %365 to <32 x i32>*
  %367 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %368 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %816, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %369 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %367, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %370 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %371 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %818, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %372 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %370, <32 x i32> %371, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %373 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %374 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %820, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %375 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %373, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %376 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %377 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %822, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %378 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %376, <32 x i32> %377, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %379 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %380 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %824, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %381 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %379, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %382 = load <32 x i32>, <32 x i32>* %366, align 128, !tbaa !104
  %383 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %826, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %384 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %382, <32 x i32> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %385 = getelementptr inbounds i32, i32* %345, i32 64
  %386 = bitcast i32* %385 to <32 x i32>*
  %387 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %388 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %816, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %389 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %387, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %390 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %391 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %818, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %392 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %390, <32 x i32> %391, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %393 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %394 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %820, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %395 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %393, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %396 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %397 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %822, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %398 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %396, <32 x i32> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %399 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %400 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %824, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %401 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %399, <32 x i32> %400, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %402 = load <32 x i32>, <32 x i32>* %386, align 128, !tbaa !104
  %403 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %826, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %404 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %402, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %405 = getelementptr inbounds i32, i32* %345, i32 96
  %406 = bitcast i32* %405 to <32 x i32>*
  %407 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %408 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %816, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %409 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %407, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %410 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %411 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %818, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %412 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %410, <32 x i32> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %413 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %414 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %820, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %415 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %413, <32 x i32> %414, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %416 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %417 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %822, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %418 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %416, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %419 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %420 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %824, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %421 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %419, <32 x i32> %420, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %422 = load <32 x i32>, <32 x i32>* %406, align 128, !tbaa !104
  %423 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %826, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %424 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %422, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb18.us.us

then_bb19.us.us:                                  ; preds = %"for output.s0.c.co.us.us"
  %425 = getelementptr inbounds i32, i32* %345, i32 32
  %426 = bitcast i32* %425 to <32 x i32>*
  %427 = load <32 x i32>, <32 x i32>* %426, align 128, !tbaa !104
  %428 = getelementptr inbounds i32, i32* %345, i32 64
  %429 = bitcast i32* %428 to <32 x i32>*
  %430 = load <32 x i32>, <32 x i32>* %429, align 128, !tbaa !104
  %431 = getelementptr inbounds i32, i32* %345, i32 96
  %432 = bitcast i32* %431 to <32 x i32>*
  %433 = load <32 x i32>, <32 x i32>* %432, align 128, !tbaa !104
  br label %after_bb18.us.us

after_bb18.us.us:                                 ; preds = %then_bb19.us.us, %next_bb20.us.us
  %convolved313.sroa.207.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %424, %next_bb20.us.us ]
  %convolved313.sroa.202.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %404, %next_bb20.us.us ]
  %convolved313.sroa.197.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %384, %next_bb20.us.us ]
  %convolved313.sroa.192.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %364, %next_bb20.us.us ]
  %convolved313.sroa.187.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %421, %next_bb20.us.us ]
  %convolved313.sroa.182.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %401, %next_bb20.us.us ]
  %convolved313.sroa.177.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %381, %next_bb20.us.us ]
  %convolved313.sroa.172.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %361, %next_bb20.us.us ]
  %convolved313.sroa.167.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %418, %next_bb20.us.us ]
  %convolved313.sroa.162.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %398, %next_bb20.us.us ]
  %convolved313.sroa.157.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %378, %next_bb20.us.us ]
  %convolved313.sroa.152.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %358, %next_bb20.us.us ]
  %convolved313.sroa.147.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %415, %next_bb20.us.us ]
  %convolved313.sroa.142.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %395, %next_bb20.us.us ]
  %convolved313.sroa.137.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %375, %next_bb20.us.us ]
  %convolved313.sroa.132.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %355, %next_bb20.us.us ]
  %convolved313.sroa.122.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %412, %next_bb20.us.us ]
  %convolved313.sroa.112.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %392, %next_bb20.us.us ]
  %convolved313.sroa.102.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %372, %next_bb20.us.us ]
  %convolved313.sroa.92.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %352, %next_bb20.us.us ]
  %convolved313.sroa.77.0.us.us = phi <32 x i32> [ %433, %then_bb19.us.us ], [ %409, %next_bb20.us.us ]
  %convolved313.sroa.62.0.us.us = phi <32 x i32> [ %430, %then_bb19.us.us ], [ %389, %next_bb20.us.us ]
  %convolved313.sroa.47.0.us.us = phi <32 x i32> [ %427, %then_bb19.us.us ], [ %369, %next_bb20.us.us ]
  %convolved313.sroa.0.0.us.us = phi <32 x i32> [ %347, %then_bb19.us.us ], [ %349, %next_bb20.us.us ]
  br i1 %197, label %"for convolved.s1.r19$y.preheader.us.us", label %"consume convolved.us.us", !prof !96

"for convolved.s1.r19$y.us.us":                   ; preds = %"for convolved.s1.r19$y.preheader.us.us", %"end for convolved.s1.r19$x.us.us"
  %convolved313.sroa.207.1.us.us = phi <32 x i32> [ %convolved313.sroa.207.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.207.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.202.1.us.us = phi <32 x i32> [ %convolved313.sroa.202.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.202.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.197.1.us.us = phi <32 x i32> [ %convolved313.sroa.197.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.197.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.192.1.us.us = phi <32 x i32> [ %convolved313.sroa.192.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.192.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.187.1.us.us = phi <32 x i32> [ %convolved313.sroa.187.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.187.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.182.1.us.us = phi <32 x i32> [ %convolved313.sroa.182.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.182.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.177.1.us.us = phi <32 x i32> [ %convolved313.sroa.177.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.177.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.172.1.us.us = phi <32 x i32> [ %convolved313.sroa.172.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.172.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.167.1.us.us = phi <32 x i32> [ %convolved313.sroa.167.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.167.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.162.1.us.us = phi <32 x i32> [ %convolved313.sroa.162.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.162.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.157.1.us.us = phi <32 x i32> [ %convolved313.sroa.157.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.157.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.152.1.us.us = phi <32 x i32> [ %convolved313.sroa.152.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.152.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.147.1.us.us = phi <32 x i32> [ %convolved313.sroa.147.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.147.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.142.1.us.us = phi <32 x i32> [ %convolved313.sroa.142.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.142.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.137.1.us.us = phi <32 x i32> [ %convolved313.sroa.137.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.137.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.132.1.us.us = phi <32 x i32> [ %convolved313.sroa.132.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.132.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.122.1.us.us = phi <32 x i32> [ %convolved313.sroa.122.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.122.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.112.1.us.us = phi <32 x i32> [ %convolved313.sroa.112.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.112.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.102.1.us.us = phi <32 x i32> [ %convolved313.sroa.102.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.102.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.92.1.us.us = phi <32 x i32> [ %convolved313.sroa.92.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.92.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.77.1.us.us = phi <32 x i32> [ %convolved313.sroa.77.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.77.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.62.1.us.us = phi <32 x i32> [ %convolved313.sroa.62.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.62.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.47.1.us.us = phi <32 x i32> [ %convolved313.sroa.47.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.47.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %convolved313.sroa.0.1.us.us = phi <32 x i32> [ %convolved313.sroa.0.3.us.us, %"end for convolved.s1.r19$x.us.us" ], [ %convolved313.sroa.0.0.us.us, %"for convolved.s1.r19$y.preheader.us.us" ]
  %"convolved.s1.r19$y.us.us" = phi i32 [ %574, %"end for convolved.s1.r19$x.us.us" ], [ 0, %"for convolved.s1.r19$y.preheader.us.us" ]
  %434 = mul nsw i32 %"convolved.s1.r19$y.us.us", %dilation_y
  %435 = add nsw i32 %434, %231
  %436 = mul nsw i32 %435, %19
  %t913.us.us = add nsw i32 %436, %227
  %437 = mul nsw i32 %"convolved.s1.r19$y.us.us", %12
  br i1 %198, label %"for convolved.s1.r19$x.us.us", label %"end for convolved.s1.r19$x.us.us", !prof !96

"for convolved.s1.r19$x.us.us":                   ; preds = %"for convolved.s1.r19$y.us.us", %"end for convolved.s1.r19$z.r124.us.us"
  %convolved313.sroa.207.2.us.us = phi <32 x i32> [ %convolved313.sroa.207.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.207.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.202.2.us.us = phi <32 x i32> [ %convolved313.sroa.202.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.202.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.197.2.us.us = phi <32 x i32> [ %convolved313.sroa.197.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.197.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.192.2.us.us = phi <32 x i32> [ %convolved313.sroa.192.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.192.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.187.2.us.us = phi <32 x i32> [ %convolved313.sroa.187.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.187.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.182.2.us.us = phi <32 x i32> [ %convolved313.sroa.182.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.182.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.177.2.us.us = phi <32 x i32> [ %convolved313.sroa.177.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.177.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.172.2.us.us = phi <32 x i32> [ %convolved313.sroa.172.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.172.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.167.2.us.us = phi <32 x i32> [ %convolved313.sroa.167.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.167.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.162.2.us.us = phi <32 x i32> [ %convolved313.sroa.162.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.162.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.157.2.us.us = phi <32 x i32> [ %convolved313.sroa.157.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.157.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.152.2.us.us = phi <32 x i32> [ %convolved313.sroa.152.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.152.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.147.2.us.us = phi <32 x i32> [ %convolved313.sroa.147.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.147.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.142.2.us.us = phi <32 x i32> [ %convolved313.sroa.142.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.142.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.137.2.us.us = phi <32 x i32> [ %convolved313.sroa.137.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.137.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.132.2.us.us = phi <32 x i32> [ %convolved313.sroa.132.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.132.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.122.2.us.us = phi <32 x i32> [ %convolved313.sroa.122.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.122.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.112.2.us.us = phi <32 x i32> [ %convolved313.sroa.112.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.112.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.102.2.us.us = phi <32 x i32> [ %convolved313.sroa.102.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.102.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.92.2.us.us = phi <32 x i32> [ %convolved313.sroa.92.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.92.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.77.2.us.us = phi <32 x i32> [ %convolved313.sroa.77.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.77.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.62.2.us.us = phi <32 x i32> [ %convolved313.sroa.62.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.62.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.47.2.us.us = phi <32 x i32> [ %convolved313.sroa.47.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.47.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %convolved313.sroa.0.2.us.us = phi <32 x i32> [ %convolved313.sroa.0.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.0.1.us.us, %"for convolved.s1.r19$y.us.us" ]
  %"convolved.s1.r19$x.us.us" = phi i32 [ %573, %"end for convolved.s1.r19$z.r124.us.us" ], [ 0, %"for convolved.s1.r19$y.us.us" ]
  %438 = mul nsw i32 %"convolved.s1.r19$x.us.us", %dilation_x
  %439 = mul nsw i32 %"convolved.s1.r19$x.us.us", %10
  %t920.us.us = add i32 %439, %437
  br i1 %199, label %"for convolved.s1.r19$z.r124.preheader.us.us", label %"end for convolved.s1.r19$z.r124.us.us", !prof !96

"for convolved.s1.r19$z.r124.us.us":              ; preds = %"for convolved.s1.r19$z.r124.preheader.us.us", %"for convolved.s1.r19$z.r124.us.us"
  %convolved313.sroa.207.4.us.us = phi <32 x i32> [ %571, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.207.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.202.4.us.us = phi <32 x i32> [ %567, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.202.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.197.4.us.us = phi <32 x i32> [ %563, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.197.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.192.4.us.us = phi <32 x i32> [ %559, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.192.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.187.4.us.us = phi <32 x i32> [ %552, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.187.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.182.4.us.us = phi <32 x i32> [ %548, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.182.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.177.4.us.us = phi <32 x i32> [ %544, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.177.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.172.4.us.us = phi <32 x i32> [ %540, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.172.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.167.4.us.us = phi <32 x i32> [ %533, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.167.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.162.4.us.us = phi <32 x i32> [ %529, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.162.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.157.4.us.us = phi <32 x i32> [ %525, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.157.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.152.4.us.us = phi <32 x i32> [ %521, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.152.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.147.4.us.us = phi <32 x i32> [ %514, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.147.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.142.4.us.us = phi <32 x i32> [ %510, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.142.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.137.4.us.us = phi <32 x i32> [ %506, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.137.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.132.4.us.us = phi <32 x i32> [ %502, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.132.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.122.4.us.us = phi <32 x i32> [ %495, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.122.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.112.4.us.us = phi <32 x i32> [ %491, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.112.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.102.4.us.us = phi <32 x i32> [ %487, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.102.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.92.4.us.us = phi <32 x i32> [ %483, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.92.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.77.4.us.us = phi <32 x i32> [ %476, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.77.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.62.4.us.us = phi <32 x i32> [ %469, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.62.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.47.4.us.us = phi <32 x i32> [ %462, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.47.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %convolved313.sroa.0.4.us.us = phi <32 x i32> [ %454, %"for convolved.s1.r19$z.r124.us.us" ], [ %convolved313.sroa.0.2.us.us, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %"convolved.s1.r19$z.r124.us.us" = phi i32 [ %572, %"for convolved.s1.r19$z.r124.us.us" ], [ 0, %"for convolved.s1.r19$z.r124.preheader.us.us" ]
  %440 = shl nsw i32 %"convolved.s1.r19$z.r124.us.us", 2
  %441 = add i32 %440, %t913.us.us
  %442 = add i32 %441, %795
  %443 = getelementptr inbounds i8, i8* %13, i32 %442
  %444 = bitcast i8* %443 to <4 x i8>*
  %445 = load <4 x i8>, <4 x i8>* %444, align 4, !tbaa !108
  %446 = shl nsw i32 %"convolved.s1.r19$z.r124.us.us", 5
  %447 = add nsw i32 %446, %811
  %448 = shl nsw i32 %447, 2
  %449 = add nsw i32 %t920.us.us, %448
  %450 = getelementptr inbounds i8, i8* %5, i32 %449
  %451 = bitcast i8* %450 to <128 x i8>*
  %452 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %453 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %454 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.0.4.us.us, <128 x i8> %452, <32 x i32> %453, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %455 = load <4 x i8>, <4 x i8>* %444, align 4, !tbaa !108
  %456 = shl nsw i32 %"convolved.s1.r19$z.r124.us.us", 7
  %457 = add i32 %796, %456
  %458 = getelementptr inbounds i8, i8* %5, i32 %457
  %459 = bitcast i8* %458 to <128 x i8>*
  %460 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %461 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %455, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %462 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.47.4.us.us, <128 x i8> %460, <32 x i32> %461, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %463 = load <4 x i8>, <4 x i8>* %444, align 4, !tbaa !108
  %464 = add i32 %797, %456
  %465 = getelementptr inbounds i8, i8* %5, i32 %464
  %466 = bitcast i8* %465 to <128 x i8>*
  %467 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %468 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %469 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.62.4.us.us, <128 x i8> %467, <32 x i32> %468, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %470 = load <4 x i8>, <4 x i8>* %444, align 4, !tbaa !108
  %471 = add i32 %798, %456
  %472 = getelementptr inbounds i8, i8* %5, i32 %471
  %473 = bitcast i8* %472 to <128 x i8>*
  %474 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %475 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %476 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.77.4.us.us, <128 x i8> %474, <32 x i32> %475, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %477 = add i32 %441, %799
  %478 = getelementptr inbounds i8, i8* %13, i32 %477
  %479 = bitcast i8* %478 to <4 x i8>*
  %480 = load <4 x i8>, <4 x i8>* %479, align 4, !tbaa !108
  %481 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %482 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %480, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %483 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.92.4.us.us, <128 x i8> %481, <32 x i32> %482, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %484 = load <4 x i8>, <4 x i8>* %479, align 4, !tbaa !108
  %485 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %486 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %484, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %487 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.102.4.us.us, <128 x i8> %485, <32 x i32> %486, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %488 = load <4 x i8>, <4 x i8>* %479, align 4, !tbaa !108
  %489 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %490 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %488, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %491 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.112.4.us.us, <128 x i8> %489, <32 x i32> %490, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %492 = load <4 x i8>, <4 x i8>* %479, align 4, !tbaa !108
  %493 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %494 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %492, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %495 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.122.4.us.us, <128 x i8> %493, <32 x i32> %494, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %496 = add i32 %441, %800
  %497 = getelementptr inbounds i8, i8* %13, i32 %496
  %498 = bitcast i8* %497 to <4 x i8>*
  %499 = load <4 x i8>, <4 x i8>* %498, align 4, !tbaa !108
  %500 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %501 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %499, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %502 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.132.4.us.us, <128 x i8> %500, <32 x i32> %501, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %503 = load <4 x i8>, <4 x i8>* %498, align 4, !tbaa !108
  %504 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %505 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %503, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %506 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.137.4.us.us, <128 x i8> %504, <32 x i32> %505, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %507 = load <4 x i8>, <4 x i8>* %498, align 4, !tbaa !108
  %508 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %509 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %507, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %510 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.142.4.us.us, <128 x i8> %508, <32 x i32> %509, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %511 = load <4 x i8>, <4 x i8>* %498, align 4, !tbaa !108
  %512 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %513 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %511, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %514 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.147.4.us.us, <128 x i8> %512, <32 x i32> %513, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %515 = add i32 %441, %801
  %516 = getelementptr inbounds i8, i8* %13, i32 %515
  %517 = bitcast i8* %516 to <4 x i8>*
  %518 = load <4 x i8>, <4 x i8>* %517, align 4, !tbaa !108
  %519 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %520 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %518, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %521 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.152.4.us.us, <128 x i8> %519, <32 x i32> %520, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %522 = load <4 x i8>, <4 x i8>* %517, align 4, !tbaa !108
  %523 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %524 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %522, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %525 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.157.4.us.us, <128 x i8> %523, <32 x i32> %524, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %526 = load <4 x i8>, <4 x i8>* %517, align 4, !tbaa !108
  %527 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %528 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %526, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %529 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.162.4.us.us, <128 x i8> %527, <32 x i32> %528, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %530 = load <4 x i8>, <4 x i8>* %517, align 4, !tbaa !108
  %531 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %532 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %530, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %533 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.167.4.us.us, <128 x i8> %531, <32 x i32> %532, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %534 = add i32 %441, %802
  %535 = getelementptr inbounds i8, i8* %13, i32 %534
  %536 = bitcast i8* %535 to <4 x i8>*
  %537 = load <4 x i8>, <4 x i8>* %536, align 4, !tbaa !108
  %538 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %539 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %537, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %540 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.172.4.us.us, <128 x i8> %538, <32 x i32> %539, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %541 = load <4 x i8>, <4 x i8>* %536, align 4, !tbaa !108
  %542 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %543 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %541, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %544 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.177.4.us.us, <128 x i8> %542, <32 x i32> %543, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %545 = load <4 x i8>, <4 x i8>* %536, align 4, !tbaa !108
  %546 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %547 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %545, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %548 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.182.4.us.us, <128 x i8> %546, <32 x i32> %547, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %549 = load <4 x i8>, <4 x i8>* %536, align 4, !tbaa !108
  %550 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %551 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %549, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %552 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.187.4.us.us, <128 x i8> %550, <32 x i32> %551, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %553 = add i32 %441, %803
  %554 = getelementptr inbounds i8, i8* %13, i32 %553
  %555 = bitcast i8* %554 to <4 x i8>*
  %556 = load <4 x i8>, <4 x i8>* %555, align 4, !tbaa !108
  %557 = load <128 x i8>, <128 x i8>* %451, align 128, !tbaa !106
  %558 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %556, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %559 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.192.4.us.us, <128 x i8> %557, <32 x i32> %558, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %560 = load <4 x i8>, <4 x i8>* %555, align 4, !tbaa !108
  %561 = load <128 x i8>, <128 x i8>* %459, align 128, !tbaa !106
  %562 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %560, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %563 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.197.4.us.us, <128 x i8> %561, <32 x i32> %562, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %564 = load <4 x i8>, <4 x i8>* %555, align 4, !tbaa !108
  %565 = load <128 x i8>, <128 x i8>* %466, align 128, !tbaa !106
  %566 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %564, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %567 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.202.4.us.us, <128 x i8> %565, <32 x i32> %566, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %568 = load <4 x i8>, <4 x i8>* %555, align 4, !tbaa !108
  %569 = load <128 x i8>, <128 x i8>* %473, align 128, !tbaa !106
  %570 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %568, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %571 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.207.4.us.us, <128 x i8> %569, <32 x i32> %570, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %572 = add nuw nsw i32 %"convolved.s1.r19$z.r124.us.us", 1
  %.not376.us.us = icmp eq i32 %572, %7
  br i1 %.not376.us.us, label %"end for convolved.s1.r19$z.r124.us.us", label %"for convolved.s1.r19$z.r124.us.us"

"end for convolved.s1.r19$z.r124.us.us":          ; preds = %"for convolved.s1.r19$z.r124.us.us", %"for convolved.s1.r19$x.us.us"
  %convolved313.sroa.207.5.us.us = phi <32 x i32> [ %convolved313.sroa.207.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %571, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.202.5.us.us = phi <32 x i32> [ %convolved313.sroa.202.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %567, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.197.5.us.us = phi <32 x i32> [ %convolved313.sroa.197.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %563, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.192.5.us.us = phi <32 x i32> [ %convolved313.sroa.192.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %559, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.187.5.us.us = phi <32 x i32> [ %convolved313.sroa.187.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %552, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.182.5.us.us = phi <32 x i32> [ %convolved313.sroa.182.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %548, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.177.5.us.us = phi <32 x i32> [ %convolved313.sroa.177.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %544, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.172.5.us.us = phi <32 x i32> [ %convolved313.sroa.172.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %540, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.167.5.us.us = phi <32 x i32> [ %convolved313.sroa.167.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %533, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.162.5.us.us = phi <32 x i32> [ %convolved313.sroa.162.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %529, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.157.5.us.us = phi <32 x i32> [ %convolved313.sroa.157.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %525, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.152.5.us.us = phi <32 x i32> [ %convolved313.sroa.152.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %521, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.147.5.us.us = phi <32 x i32> [ %convolved313.sroa.147.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %514, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.142.5.us.us = phi <32 x i32> [ %convolved313.sroa.142.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %510, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.137.5.us.us = phi <32 x i32> [ %convolved313.sroa.137.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %506, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.132.5.us.us = phi <32 x i32> [ %convolved313.sroa.132.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %502, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.122.5.us.us = phi <32 x i32> [ %convolved313.sroa.122.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %495, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.112.5.us.us = phi <32 x i32> [ %convolved313.sroa.112.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %491, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.102.5.us.us = phi <32 x i32> [ %convolved313.sroa.102.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %487, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.92.5.us.us = phi <32 x i32> [ %convolved313.sroa.92.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %483, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.77.5.us.us = phi <32 x i32> [ %convolved313.sroa.77.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %476, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.62.5.us.us = phi <32 x i32> [ %convolved313.sroa.62.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %469, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.47.5.us.us = phi <32 x i32> [ %convolved313.sroa.47.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %462, %"for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.0.5.us.us = phi <32 x i32> [ %convolved313.sroa.0.2.us.us, %"for convolved.s1.r19$x.us.us" ], [ %454, %"for convolved.s1.r19$z.r124.us.us" ]
  %573 = add nuw nsw i32 %"convolved.s1.r19$x.us.us", 1
  %.not375.us.us = icmp eq i32 %573, %9
  br i1 %.not375.us.us, label %"end for convolved.s1.r19$x.us.us", label %"for convolved.s1.r19$x.us.us"

"end for convolved.s1.r19$x.us.us":               ; preds = %"end for convolved.s1.r19$z.r124.us.us", %"for convolved.s1.r19$y.us.us"
  %convolved313.sroa.207.3.us.us = phi <32 x i32> [ %convolved313.sroa.207.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.207.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.202.3.us.us = phi <32 x i32> [ %convolved313.sroa.202.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.202.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.197.3.us.us = phi <32 x i32> [ %convolved313.sroa.197.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.197.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.192.3.us.us = phi <32 x i32> [ %convolved313.sroa.192.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.192.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.187.3.us.us = phi <32 x i32> [ %convolved313.sroa.187.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.187.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.182.3.us.us = phi <32 x i32> [ %convolved313.sroa.182.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.182.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.177.3.us.us = phi <32 x i32> [ %convolved313.sroa.177.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.177.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.172.3.us.us = phi <32 x i32> [ %convolved313.sroa.172.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.172.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.167.3.us.us = phi <32 x i32> [ %convolved313.sroa.167.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.167.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.162.3.us.us = phi <32 x i32> [ %convolved313.sroa.162.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.162.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.157.3.us.us = phi <32 x i32> [ %convolved313.sroa.157.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.157.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.152.3.us.us = phi <32 x i32> [ %convolved313.sroa.152.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.152.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.147.3.us.us = phi <32 x i32> [ %convolved313.sroa.147.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.147.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.142.3.us.us = phi <32 x i32> [ %convolved313.sroa.142.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.142.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.137.3.us.us = phi <32 x i32> [ %convolved313.sroa.137.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.137.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.132.3.us.us = phi <32 x i32> [ %convolved313.sroa.132.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.132.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.122.3.us.us = phi <32 x i32> [ %convolved313.sroa.122.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.122.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.112.3.us.us = phi <32 x i32> [ %convolved313.sroa.112.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.112.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.102.3.us.us = phi <32 x i32> [ %convolved313.sroa.102.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.102.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.92.3.us.us = phi <32 x i32> [ %convolved313.sroa.92.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.92.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.77.3.us.us = phi <32 x i32> [ %convolved313.sroa.77.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.77.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.62.3.us.us = phi <32 x i32> [ %convolved313.sroa.62.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.62.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.47.3.us.us = phi <32 x i32> [ %convolved313.sroa.47.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.47.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %convolved313.sroa.0.3.us.us = phi <32 x i32> [ %convolved313.sroa.0.1.us.us, %"for convolved.s1.r19$y.us.us" ], [ %convolved313.sroa.0.5.us.us, %"end for convolved.s1.r19$z.r124.us.us" ]
  %574 = add nuw nsw i32 %"convolved.s1.r19$y.us.us", 1
  %.not374.us.us = icmp eq i32 %574, %11
  br i1 %.not374.us.us, label %"consume convolved.us.us", label %"for convolved.s1.r19$y.us.us"

"consume convolved.us.us":                        ; preds = %"end for convolved.s1.r19$x.us.us", %after_bb18.us.us
  %convolved313.sroa.207.6.us.us = phi <32 x i32> [ %convolved313.sroa.207.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.207.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.202.6.us.us = phi <32 x i32> [ %convolved313.sroa.202.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.202.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.197.6.us.us = phi <32 x i32> [ %convolved313.sroa.197.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.197.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.192.6.us.us = phi <32 x i32> [ %convolved313.sroa.192.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.192.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.187.6.us.us = phi <32 x i32> [ %convolved313.sroa.187.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.187.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.182.6.us.us = phi <32 x i32> [ %convolved313.sroa.182.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.182.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.177.6.us.us = phi <32 x i32> [ %convolved313.sroa.177.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.177.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.172.6.us.us = phi <32 x i32> [ %convolved313.sroa.172.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.172.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.167.6.us.us = phi <32 x i32> [ %convolved313.sroa.167.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.167.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.162.6.us.us = phi <32 x i32> [ %convolved313.sroa.162.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.162.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.157.6.us.us = phi <32 x i32> [ %convolved313.sroa.157.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.157.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.152.6.us.us = phi <32 x i32> [ %convolved313.sroa.152.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.152.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.147.6.us.us = phi <32 x i32> [ %convolved313.sroa.147.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.147.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.142.6.us.us = phi <32 x i32> [ %convolved313.sroa.142.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.142.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.137.6.us.us = phi <32 x i32> [ %convolved313.sroa.137.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.137.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.132.6.us.us = phi <32 x i32> [ %convolved313.sroa.132.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.132.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.122.6.us.us = phi <32 x i32> [ %convolved313.sroa.122.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.122.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.112.6.us.us = phi <32 x i32> [ %convolved313.sroa.112.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.112.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.102.6.us.us = phi <32 x i32> [ %convolved313.sroa.102.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.102.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.92.6.us.us = phi <32 x i32> [ %convolved313.sroa.92.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.92.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.77.6.us.us = phi <32 x i32> [ %convolved313.sroa.77.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.77.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.62.6.us.us = phi <32 x i32> [ %convolved313.sroa.62.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.62.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.47.6.us.us = phi <32 x i32> [ %convolved313.sroa.47.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.47.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %convolved313.sroa.0.6.us.us = phi <32 x i32> [ %convolved313.sroa.0.0.us.us, %after_bb18.us.us ], [ %convolved313.sroa.0.3.us.us, %"end for convolved.s1.r19$x.us.us" ]
  %575 = sext <32 x i32> %convolved313.sroa.0.6.us.us to <32 x i64>
  %a15.us.us = mul nsw <32 x i64> %575, %204
  %576 = icmp slt <32 x i64> %a15.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %577 = select <32 x i1> %576, <32 x i64> %a15.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %578 = add nsw <32 x i64> %577, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a14.us.us = ashr <32 x i64> %578, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %579 = icmp slt <32 x i64> %a14.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a13.us.us = select <32 x i1> %579, <32 x i64> %a14.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %580 = icmp sgt <32 x i64> %a13.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %581 = select <32 x i1> %580, <32 x i64> %a13.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %582 = trunc <32 x i64> %581 to <32 x i32>
  %583 = sext <32 x i32> %convolved313.sroa.47.6.us.us to <32 x i64>
  %a19.us.us = mul nsw <32 x i64> %583, %204
  %584 = icmp slt <32 x i64> %a19.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %585 = select <32 x i1> %584, <32 x i64> %a19.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %586 = add nsw <32 x i64> %585, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a18.us.us = ashr <32 x i64> %586, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %587 = icmp slt <32 x i64> %a18.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a17.us.us = select <32 x i1> %587, <32 x i64> %a18.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %588 = icmp sgt <32 x i64> %a17.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %589 = select <32 x i1> %588, <32 x i64> %a17.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %590 = trunc <32 x i64> %589 to <32 x i32>
  %591 = sext <32 x i32> %convolved313.sroa.62.6.us.us to <32 x i64>
  %a23.us.us = mul nsw <32 x i64> %591, %204
  %592 = icmp slt <32 x i64> %a23.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %593 = select <32 x i1> %592, <32 x i64> %a23.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %594 = add nsw <32 x i64> %593, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a22.us.us = ashr <32 x i64> %594, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %595 = icmp slt <32 x i64> %a22.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a21.us.us = select <32 x i1> %595, <32 x i64> %a22.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %596 = icmp sgt <32 x i64> %a21.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %597 = select <32 x i1> %596, <32 x i64> %a21.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %598 = trunc <32 x i64> %597 to <32 x i32>
  %599 = sext <32 x i32> %convolved313.sroa.77.6.us.us to <32 x i64>
  %a27.us.us = mul nsw <32 x i64> %599, %204
  %600 = icmp slt <32 x i64> %a27.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %601 = select <32 x i1> %600, <32 x i64> %a27.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %602 = add nsw <32 x i64> %601, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a26.us.us = ashr <32 x i64> %602, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %603 = icmp slt <32 x i64> %a26.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a25.us.us = select <32 x i1> %603, <32 x i64> %a26.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %604 = icmp sgt <32 x i64> %a25.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %605 = select <32 x i1> %604, <32 x i64> %a25.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %606 = trunc <32 x i64> %605 to <32 x i32>
  %607 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.50(<32 x i32> %582, <1 x i32> %216, <1 x i32> %217, <32 x i32> %590, <1 x i32> %216, <32 x i32> %598, <1 x i32> %216, <32 x i32> %606, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %608 = shl nsw i32 %output.s0.c.co.us.us, 7
  %609 = add i32 %608, %t877.us.us
  %610 = add i32 %609, %839
  %611 = getelementptr inbounds i8, i8* %23, i32 %610
  %612 = bitcast i8* %611 to <128 x i8>*
  store <128 x i8> %607, <128 x i8>* %612, align 1, !tbaa !111
  %613 = sext <32 x i32> %convolved313.sroa.92.6.us.us to <32 x i64>
  %a31.us.us = mul nsw <32 x i64> %613, %204
  %614 = icmp slt <32 x i64> %a31.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %615 = select <32 x i1> %614, <32 x i64> %a31.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %616 = add nsw <32 x i64> %615, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a30.us.us = ashr <32 x i64> %616, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %617 = icmp slt <32 x i64> %a30.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a29.us.us = select <32 x i1> %617, <32 x i64> %a30.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %618 = icmp sgt <32 x i64> %a29.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %619 = select <32 x i1> %618, <32 x i64> %a29.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %620 = trunc <32 x i64> %619 to <32 x i32>
  %621 = sext <32 x i32> %convolved313.sroa.102.6.us.us to <32 x i64>
  %a35.us.us = mul nsw <32 x i64> %621, %204
  %622 = icmp slt <32 x i64> %a35.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %623 = select <32 x i1> %622, <32 x i64> %a35.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %624 = add nsw <32 x i64> %623, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a34.us.us = ashr <32 x i64> %624, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %625 = icmp slt <32 x i64> %a34.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a33.us.us = select <32 x i1> %625, <32 x i64> %a34.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %626 = icmp sgt <32 x i64> %a33.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %627 = select <32 x i1> %626, <32 x i64> %a33.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %628 = trunc <32 x i64> %627 to <32 x i32>
  %629 = sext <32 x i32> %convolved313.sroa.112.6.us.us to <32 x i64>
  %a39.us.us = mul nsw <32 x i64> %629, %204
  %630 = icmp slt <32 x i64> %a39.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %631 = select <32 x i1> %630, <32 x i64> %a39.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %632 = add nsw <32 x i64> %631, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a38.us.us = ashr <32 x i64> %632, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %633 = icmp slt <32 x i64> %a38.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a37.us.us = select <32 x i1> %633, <32 x i64> %a38.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %634 = icmp sgt <32 x i64> %a37.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %635 = select <32 x i1> %634, <32 x i64> %a37.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %636 = trunc <32 x i64> %635 to <32 x i32>
  %637 = sext <32 x i32> %convolved313.sroa.122.6.us.us to <32 x i64>
  %a43.us.us = mul nsw <32 x i64> %637, %204
  %638 = icmp slt <32 x i64> %a43.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %639 = select <32 x i1> %638, <32 x i64> %a43.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %640 = add nsw <32 x i64> %639, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a42.us.us = ashr <32 x i64> %640, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %641 = icmp slt <32 x i64> %a42.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a41.us.us = select <32 x i1> %641, <32 x i64> %a42.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %642 = icmp sgt <32 x i64> %a41.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %643 = select <32 x i1> %642, <32 x i64> %a41.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %644 = trunc <32 x i64> %643 to <32 x i32>
  %645 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.51(<32 x i32> %620, <1 x i32> %216, <1 x i32> %217, <32 x i32> %628, <1 x i32> %216, <32 x i32> %636, <1 x i32> %216, <32 x i32> %644, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %646 = add i32 %609, %840
  %647 = getelementptr inbounds i8, i8* %23, i32 %646
  %648 = bitcast i8* %647 to <128 x i8>*
  store <128 x i8> %645, <128 x i8>* %648, align 1, !tbaa !111
  %649 = sext <32 x i32> %convolved313.sroa.132.6.us.us to <32 x i64>
  %a47.us.us = mul nsw <32 x i64> %649, %204
  %650 = icmp slt <32 x i64> %a47.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %651 = select <32 x i1> %650, <32 x i64> %a47.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %652 = add nsw <32 x i64> %651, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a46.us.us = ashr <32 x i64> %652, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %653 = icmp slt <32 x i64> %a46.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a45.us.us = select <32 x i1> %653, <32 x i64> %a46.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %654 = icmp sgt <32 x i64> %a45.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %655 = select <32 x i1> %654, <32 x i64> %a45.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %656 = trunc <32 x i64> %655 to <32 x i32>
  %657 = sext <32 x i32> %convolved313.sroa.137.6.us.us to <32 x i64>
  %a51.us.us = mul nsw <32 x i64> %657, %204
  %658 = icmp slt <32 x i64> %a51.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %659 = select <32 x i1> %658, <32 x i64> %a51.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %660 = add nsw <32 x i64> %659, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a50.us.us = ashr <32 x i64> %660, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %661 = icmp slt <32 x i64> %a50.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a49.us.us = select <32 x i1> %661, <32 x i64> %a50.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %662 = icmp sgt <32 x i64> %a49.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %663 = select <32 x i1> %662, <32 x i64> %a49.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %664 = trunc <32 x i64> %663 to <32 x i32>
  %665 = sext <32 x i32> %convolved313.sroa.142.6.us.us to <32 x i64>
  %a55.us.us = mul nsw <32 x i64> %665, %204
  %666 = icmp slt <32 x i64> %a55.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %667 = select <32 x i1> %666, <32 x i64> %a55.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %668 = add nsw <32 x i64> %667, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a54.us.us = ashr <32 x i64> %668, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %669 = icmp slt <32 x i64> %a54.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a53.us.us = select <32 x i1> %669, <32 x i64> %a54.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %670 = icmp sgt <32 x i64> %a53.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %671 = select <32 x i1> %670, <32 x i64> %a53.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %672 = trunc <32 x i64> %671 to <32 x i32>
  %673 = sext <32 x i32> %convolved313.sroa.147.6.us.us to <32 x i64>
  %a59.us.us = mul nsw <32 x i64> %673, %204
  %674 = icmp slt <32 x i64> %a59.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %675 = select <32 x i1> %674, <32 x i64> %a59.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %676 = add nsw <32 x i64> %675, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a58.us.us = ashr <32 x i64> %676, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %677 = icmp slt <32 x i64> %a58.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a57.us.us = select <32 x i1> %677, <32 x i64> %a58.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %678 = icmp sgt <32 x i64> %a57.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %679 = select <32 x i1> %678, <32 x i64> %a57.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %680 = trunc <32 x i64> %679 to <32 x i32>
  %681 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.52(<32 x i32> %656, <1 x i32> %216, <1 x i32> %217, <32 x i32> %664, <1 x i32> %216, <32 x i32> %672, <1 x i32> %216, <32 x i32> %680, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %682 = add i32 %609, %841
  %683 = getelementptr inbounds i8, i8* %23, i32 %682
  %684 = bitcast i8* %683 to <128 x i8>*
  store <128 x i8> %681, <128 x i8>* %684, align 1, !tbaa !111
  %685 = sext <32 x i32> %convolved313.sroa.152.6.us.us to <32 x i64>
  %a63.us.us = mul nsw <32 x i64> %685, %204
  %686 = icmp slt <32 x i64> %a63.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %687 = select <32 x i1> %686, <32 x i64> %a63.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %688 = add nsw <32 x i64> %687, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a62.us.us = ashr <32 x i64> %688, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %689 = icmp slt <32 x i64> %a62.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a61.us.us = select <32 x i1> %689, <32 x i64> %a62.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %690 = icmp sgt <32 x i64> %a61.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %691 = select <32 x i1> %690, <32 x i64> %a61.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %692 = trunc <32 x i64> %691 to <32 x i32>
  %693 = sext <32 x i32> %convolved313.sroa.157.6.us.us to <32 x i64>
  %a67.us.us = mul nsw <32 x i64> %693, %204
  %694 = icmp slt <32 x i64> %a67.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %695 = select <32 x i1> %694, <32 x i64> %a67.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %696 = add nsw <32 x i64> %695, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a66.us.us = ashr <32 x i64> %696, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %697 = icmp slt <32 x i64> %a66.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a65.us.us = select <32 x i1> %697, <32 x i64> %a66.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %698 = icmp sgt <32 x i64> %a65.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %699 = select <32 x i1> %698, <32 x i64> %a65.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %700 = trunc <32 x i64> %699 to <32 x i32>
  %701 = sext <32 x i32> %convolved313.sroa.162.6.us.us to <32 x i64>
  %a71.us.us = mul nsw <32 x i64> %701, %204
  %702 = icmp slt <32 x i64> %a71.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %703 = select <32 x i1> %702, <32 x i64> %a71.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %704 = add nsw <32 x i64> %703, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a70.us.us = ashr <32 x i64> %704, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %705 = icmp slt <32 x i64> %a70.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a69.us.us = select <32 x i1> %705, <32 x i64> %a70.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %706 = icmp sgt <32 x i64> %a69.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %707 = select <32 x i1> %706, <32 x i64> %a69.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %708 = trunc <32 x i64> %707 to <32 x i32>
  %709 = sext <32 x i32> %convolved313.sroa.167.6.us.us to <32 x i64>
  %a75.us.us = mul nsw <32 x i64> %709, %204
  %710 = icmp slt <32 x i64> %a75.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %711 = select <32 x i1> %710, <32 x i64> %a75.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %712 = add nsw <32 x i64> %711, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a74.us.us = ashr <32 x i64> %712, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %713 = icmp slt <32 x i64> %a74.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a73.us.us = select <32 x i1> %713, <32 x i64> %a74.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %714 = icmp sgt <32 x i64> %a73.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %715 = select <32 x i1> %714, <32 x i64> %a73.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %716 = trunc <32 x i64> %715 to <32 x i32>
  %717 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.53(<32 x i32> %692, <1 x i32> %216, <1 x i32> %217, <32 x i32> %700, <1 x i32> %216, <32 x i32> %708, <1 x i32> %216, <32 x i32> %716, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %718 = add i32 %609, %842
  %719 = getelementptr inbounds i8, i8* %23, i32 %718
  %720 = bitcast i8* %719 to <128 x i8>*
  store <128 x i8> %717, <128 x i8>* %720, align 1, !tbaa !111
  %721 = sext <32 x i32> %convolved313.sroa.172.6.us.us to <32 x i64>
  %a79.us.us = mul nsw <32 x i64> %721, %204
  %722 = icmp slt <32 x i64> %a79.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %723 = select <32 x i1> %722, <32 x i64> %a79.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %724 = add nsw <32 x i64> %723, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a78.us.us = ashr <32 x i64> %724, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %725 = icmp slt <32 x i64> %a78.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a77.us.us = select <32 x i1> %725, <32 x i64> %a78.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %726 = icmp sgt <32 x i64> %a77.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %727 = select <32 x i1> %726, <32 x i64> %a77.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %728 = trunc <32 x i64> %727 to <32 x i32>
  %729 = sext <32 x i32> %convolved313.sroa.177.6.us.us to <32 x i64>
  %a83.us.us = mul nsw <32 x i64> %729, %204
  %730 = icmp slt <32 x i64> %a83.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %731 = select <32 x i1> %730, <32 x i64> %a83.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %732 = add nsw <32 x i64> %731, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a82.us.us = ashr <32 x i64> %732, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %733 = icmp slt <32 x i64> %a82.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a81.us.us = select <32 x i1> %733, <32 x i64> %a82.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %734 = icmp sgt <32 x i64> %a81.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %735 = select <32 x i1> %734, <32 x i64> %a81.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %736 = trunc <32 x i64> %735 to <32 x i32>
  %737 = sext <32 x i32> %convolved313.sroa.182.6.us.us to <32 x i64>
  %a87.us.us = mul nsw <32 x i64> %737, %204
  %738 = icmp slt <32 x i64> %a87.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %739 = select <32 x i1> %738, <32 x i64> %a87.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %740 = add nsw <32 x i64> %739, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a86.us.us = ashr <32 x i64> %740, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %741 = icmp slt <32 x i64> %a86.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a85.us.us = select <32 x i1> %741, <32 x i64> %a86.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %742 = icmp sgt <32 x i64> %a85.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %743 = select <32 x i1> %742, <32 x i64> %a85.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %744 = trunc <32 x i64> %743 to <32 x i32>
  %745 = sext <32 x i32> %convolved313.sroa.187.6.us.us to <32 x i64>
  %a91.us.us = mul nsw <32 x i64> %745, %204
  %746 = icmp slt <32 x i64> %a91.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %747 = select <32 x i1> %746, <32 x i64> %a91.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %748 = add nsw <32 x i64> %747, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a90.us.us = ashr <32 x i64> %748, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %749 = icmp slt <32 x i64> %a90.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a89.us.us = select <32 x i1> %749, <32 x i64> %a90.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %750 = icmp sgt <32 x i64> %a89.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %751 = select <32 x i1> %750, <32 x i64> %a89.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %752 = trunc <32 x i64> %751 to <32 x i32>
  %753 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.54(<32 x i32> %728, <1 x i32> %216, <1 x i32> %217, <32 x i32> %736, <1 x i32> %216, <32 x i32> %744, <1 x i32> %216, <32 x i32> %752, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %754 = add i32 %609, %843
  %755 = getelementptr inbounds i8, i8* %23, i32 %754
  %756 = bitcast i8* %755 to <128 x i8>*
  store <128 x i8> %753, <128 x i8>* %756, align 1, !tbaa !111
  %757 = sext <32 x i32> %convolved313.sroa.192.6.us.us to <32 x i64>
  %a95.us.us = mul nsw <32 x i64> %757, %204
  %758 = icmp slt <32 x i64> %a95.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %759 = select <32 x i1> %758, <32 x i64> %a95.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %760 = add nsw <32 x i64> %759, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a94.us.us = ashr <32 x i64> %760, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %761 = icmp slt <32 x i64> %a94.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a93.us.us = select <32 x i1> %761, <32 x i64> %a94.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %762 = icmp sgt <32 x i64> %a93.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %763 = select <32 x i1> %762, <32 x i64> %a93.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %764 = trunc <32 x i64> %763 to <32 x i32>
  %765 = sext <32 x i32> %convolved313.sroa.197.6.us.us to <32 x i64>
  %a99.us.us = mul nsw <32 x i64> %765, %204
  %766 = icmp slt <32 x i64> %a99.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %767 = select <32 x i1> %766, <32 x i64> %a99.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %768 = add nsw <32 x i64> %767, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a98.us.us = ashr <32 x i64> %768, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %769 = icmp slt <32 x i64> %a98.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a97.us.us = select <32 x i1> %769, <32 x i64> %a98.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %770 = icmp sgt <32 x i64> %a97.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %771 = select <32 x i1> %770, <32 x i64> %a97.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %772 = trunc <32 x i64> %771 to <32 x i32>
  %773 = sext <32 x i32> %convolved313.sroa.202.6.us.us to <32 x i64>
  %a103.us.us = mul nsw <32 x i64> %773, %204
  %774 = icmp slt <32 x i64> %a103.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %775 = select <32 x i1> %774, <32 x i64> %a103.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %776 = add nsw <32 x i64> %775, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a102.us.us = ashr <32 x i64> %776, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %777 = icmp slt <32 x i64> %a102.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a101.us.us = select <32 x i1> %777, <32 x i64> %a102.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %778 = icmp sgt <32 x i64> %a101.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %779 = select <32 x i1> %778, <32 x i64> %a101.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %780 = trunc <32 x i64> %779 to <32 x i32>
  %781 = sext <32 x i32> %convolved313.sroa.207.6.us.us to <32 x i64>
  %a107.us.us = mul nsw <32 x i64> %781, %204
  %782 = icmp slt <32 x i64> %a107.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %783 = select <32 x i1> %782, <32 x i64> %a107.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %784 = add nsw <32 x i64> %783, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a106.us.us = ashr <32 x i64> %784, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %785 = icmp slt <32 x i64> %a106.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a105.us.us = select <32 x i1> %785, <32 x i64> %a106.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %786 = icmp sgt <32 x i64> %a105.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %787 = select <32 x i1> %786, <32 x i64> %a105.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %788 = trunc <32 x i64> %787 to <32 x i32>
  %789 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.55(<32 x i32> %764, <1 x i32> %216, <1 x i32> %217, <32 x i32> %772, <1 x i32> %216, <32 x i32> %780, <1 x i32> %216, <32 x i32> %788, <1 x i32> %216, <128 x i16> %211, <128 x i8> %213, <128 x i8> %215) #11
  %790 = add i32 %609, %844
  %791 = getelementptr inbounds i8, i8* %23, i32 %790
  %792 = bitcast i8* %791 to <128 x i8>*
  store <128 x i8> %789, <128 x i8>* %792, align 1, !tbaa !111
  %793 = add nuw nsw i32 %output.s0.c.co.us.us, 1
  %.not373.us.us = icmp eq i32 %793, %200
  br i1 %.not373.us.us, label %"end for output.s0.c.co.us.us", label %"for output.s0.c.co.us.us"

"end for output.s0.c.co.us.us":                   ; preds = %"consume convolved.us.us", %"consume sum_input.us.us"
  %794 = add nuw nsw i32 %output.s0.x.xo.us.us, 1
  %.not372.us.us = icmp eq i32 %794, %195
  br i1 %.not372.us.us, label %"end for output.s0.x.xo.loopexit.us.us", label %"for output.s0.x.xo.us.us"

"for convolved.s1.r19$z.r124.preheader.us.us":    ; preds = %"for convolved.s1.r19$x.us.us"
  %t919.s.us.us = add nsw i32 %438, %838
  %t924.s.us.us = add nsw i32 %438, %837
  %t925.s.us.us = add nsw i32 %438, %835
  %t926.s.us.us = add nsw i32 %438, %833
  %t927.s.us.us = add nsw i32 %438, %831
  %t928.s.us.us = add nsw i32 %438, %829
  %795 = mul nsw i32 %t919.s.us.us, %17
  %796 = add i32 %t920.us.us, %810
  %797 = add i32 %t920.us.us, %808
  %798 = add i32 %t920.us.us, %806
  %799 = mul nsw i32 %t924.s.us.us, %17
  %800 = mul nsw i32 %t925.s.us.us, %17
  %801 = mul nsw i32 %t926.s.us.us, %17
  %802 = mul nsw i32 %t927.s.us.us, %17
  %803 = mul nsw i32 %t928.s.us.us, %17
  br label %"for convolved.s1.r19$z.r124.us.us"

"for convolved.s1.r19$y.preheader.us.us":         ; preds = %after_bb18.us.us
  %804 = shl nsw i32 %output.s0.c.co.us.us, 2
  %805 = or i32 %804, 3
  %806 = mul nsw i32 %805, %8
  %807 = or i32 %804, 2
  %808 = mul nsw i32 %807, %8
  %809 = or i32 %804, 1
  %810 = mul nsw i32 %809, %8
  %811 = mul nsw i32 %output.s0.c.co.us.us, %8
  br label %"for convolved.s1.r19$y.us.us"

"for sum_input.s1.r19$x.preheader.us.us":         ; preds = %"for sum_input.s1.r19$y.us.us"
  %812 = mul nsw i32 %"sum_input.s1.r19$y.us.us", %dilation_y
  %813 = add nsw i32 %812, %231
  %814 = mul nsw i32 %813, %19
  %t880.us.us = add i32 %226, %814
  br i1 %221, label %"end for sum_input.s1.r19$x.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x.us.us"

"for output.s0.c.co.preheader.us.us":             ; preds = %"consume sum_input.us.us"
  %sum_input314.sroa.0.0.vec.extract518.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 0
  %815 = mul nsw i32 %sum_input314.sroa.0.0.vec.extract518.us.us, %168
  %816 = insertelement <1 x i32> poison, i32 %815, i32 0
  %sum_input314.sroa.0.4.vec.extract524.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 1
  %817 = mul nsw i32 %sum_input314.sroa.0.4.vec.extract524.us.us, %168
  %818 = insertelement <1 x i32> poison, i32 %817, i32 0
  %sum_input314.sroa.0.8.vec.extract530.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 2
  %819 = mul nsw i32 %sum_input314.sroa.0.8.vec.extract530.us.us, %168
  %820 = insertelement <1 x i32> poison, i32 %819, i32 0
  %sum_input314.sroa.0.12.vec.extract536.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 3
  %821 = mul nsw i32 %sum_input314.sroa.0.12.vec.extract536.us.us, %168
  %822 = insertelement <1 x i32> poison, i32 %821, i32 0
  %sum_input314.sroa.0.16.vec.extract542.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 4
  %823 = mul nsw i32 %sum_input314.sroa.0.16.vec.extract542.us.us, %168
  %824 = insertelement <1 x i32> poison, i32 %823, i32 0
  %sum_input314.sroa.0.20.vec.extract548.us.us = extractelement <6 x i32> %sum_input314.sroa.0.13.us.us, i32 5
  %825 = mul nsw i32 %sum_input314.sroa.0.20.vec.extract548.us.us, %168
  %826 = insertelement <1 x i32> poison, i32 %825, i32 0
  %827 = add nsw i32 %output.s0.x.x.base.s.us.us, %25
  %828 = add nsw i32 %827, 5
  %829 = mul nsw i32 %828, %stride_x
  %830 = add nsw i32 %827, 4
  %831 = mul nsw i32 %830, %stride_x
  %832 = add nsw i32 %827, 3
  %833 = mul nsw i32 %832, %stride_x
  %834 = add nsw i32 %827, 2
  %835 = mul nsw i32 %834, %stride_x
  %836 = add nsw i32 %827, 1
  %837 = mul nsw i32 %836, %stride_x
  %838 = mul nsw i32 %827, %stride_x
  %839 = mul nsw i32 %827, %27
  %840 = mul nsw i32 %836, %27
  %841 = mul nsw i32 %834, %27
  %842 = mul nsw i32 %832, %27
  %843 = mul nsw i32 %830, %27
  %844 = mul nsw i32 %828, %27
  br label %"for output.s0.c.co.us.us"

"for sum_input.s1.r19$y.preheader.us.us":         ; preds = %then_bb10.us.us
  %845 = add nsw i32 %output.s0.x.x.base.s.us.us, %25
  %846 = sub i32 %845, %16
  br label %"for sum_input.s1.r19$y.us.us"

"for sum_input.s1.r19$y12.preheader.us.us":       ; preds = %next_bb11.us.us
  %847 = add nsw i32 %output.s0.x.x.base.s.us.us, %25
  %848 = mul nsw i32 %847, %stride_x
  br i1 %brmerge1305.demorgan, label %"for sum_input.s1.r19$y12.us.us.us.us", label %"consume sum_input.us.us", !prof !103

"end for output.s0.x.xo.loopexit.us.us":          ; preds = %"end for output.s0.c.co.us.us"
  %849 = add nuw nsw i32 %output.s0.y.rebased.us.us, 1
  %.not371.us.us = icmp eq i32 %849, %29
  br i1 %.not371.us.us, label %"end for output.s0.y.rebased.loopexit.us", label %"for output.s0.y.rebased.us.us"

"for sum_input.s1.r19$y12.us.us.us.us":           ; preds = %"for sum_input.s1.r19$y12.preheader.us.us", %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us"
  %sum_input314.sroa.0.8.us.us.us.us = phi <6 x i32> [ %.lcssa, %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us" ], [ zeroinitializer, %"for sum_input.s1.r19$y12.preheader.us.us" ]
  %"sum_input.s1.r19$y14.us.us.us.us" = phi i32 [ %1010, %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y12.preheader.us.us" ]
  %850 = mul nsw i32 %"sum_input.s1.r19$y14.us.us.us.us", %dilation_y
  %t882.s.us.us.us.us = add nsw i32 %850, %231
  %851 = mul nsw i32 %t882.s.us.us.us.us, %19
  br label %"for sum_input.s1.r19$x15.us.us.us.us.us"

"for sum_input.s1.r19$x15.us.us.us.us.us":        ; preds = %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us", %"for sum_input.s1.r19$y12.us.us.us.us"
  %sum_input314.sroa.0.9.us.us.us.us.us = phi <6 x i32> [ %.lcssa, %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us" ], [ %sum_input314.sroa.0.8.us.us.us.us, %"for sum_input.s1.r19$y12.us.us.us.us" ]
  %"sum_input.s1.r19$x17.us.us.us.us.us" = phi i32 [ %1009, %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y12.us.us.us.us" ]
  %852 = mul nsw i32 %"sum_input.s1.r19$x17.us.us.us.us.us", %dilation_x
  %t883.s.us.us.us.us.us = add nsw i32 %852, %848
  %t1221.us.us.us.us.us = mul nsw i32 %t883.s.us.us.us.us.us, %17
  %853 = add i32 %t1221.us.us.us.us.us, %851
  %t884.us.us.us.us.us = sub i32 %853, %t852
  %854 = add i32 %t884.us.us.us.us.us, %225
  %t860.us.us.us.us.us = add i32 %853, %186
  %855 = sub i32 %t860.us.us.us.us.us, %175
  %t885.us.us.us.us.us = sub i32 %855, %176
  %856 = add i32 %t885.us.us.us.us.us, %225
  %857 = add i32 %853, %184
  %858 = sub i32 %857, %218
  %t886.us.us.us.us.us = sub i32 %858, %176
  %859 = add i32 %t886.us.us.us.us.us, %225
  %860 = add i32 %853, %183
  %861 = sub i32 %860, %218
  %t887.us.us.us.us.us = sub i32 %861, %176
  %862 = add i32 %t887.us.us.us.us.us, %225
  %863 = add i32 %853, %182
  %864 = sub i32 %863, %218
  %t888.us.us.us.us.us = sub i32 %864, %176
  %865 = add i32 %t888.us.us.us.us.us, %225
  %866 = add i32 %853, %181
  %867 = sub i32 %866, %218
  %t889.us.us.us.us.us = sub i32 %867, %176
  %868 = add i32 %t889.us.us.us.us.us, %225
  br i1 %220, label %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124.us.us.us.us.us"

"for sum_input.s1.r19$z.r124.us.us.us.us.us":     ; preds = %"for sum_input.s1.r19$x15.us.us.us.us.us", %"for sum_input.s1.r19$z.r124.us.us.us.us.us"
  %sum_input314.sroa.0.11.us.us.us.us.us = phi <6 x i32> [ %961, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ], [ %sum_input314.sroa.0.9.us.us.us.us.us, %"for sum_input.s1.r19$x15.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r124.us.us.us.us.us" = phi i32 [ %962, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$x15.us.us.us.us.us" ]
  %niter1513 = phi i32 [ %niter1513.nsub.1, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ], [ %unroll_iter1512, %"for sum_input.s1.r19$x15.us.us.us.us.us" ]
  %869 = shl nsw i32 %"sum_input.s1.r19$z.r124.us.us.us.us.us", 2
  %870 = add i32 %854, %869
  %871 = getelementptr inbounds i8, i8* %13, i32 %870
  %872 = bitcast i8* %871 to <4 x i8>*
  %873 = load <4 x i8>, <4 x i8>* %872, align 4, !tbaa !108
  %874 = add i32 %856, %869
  %875 = getelementptr inbounds i8, i8* %13, i32 %874
  %876 = bitcast i8* %875 to <4 x i8>*
  %877 = load <4 x i8>, <4 x i8>* %876, align 4, !tbaa !108
  %878 = add i32 %859, %869
  %879 = getelementptr inbounds i8, i8* %13, i32 %878
  %880 = bitcast i8* %879 to <4 x i8>*
  %881 = load <4 x i8>, <4 x i8>* %880, align 4, !tbaa !108
  %882 = add i32 %862, %869
  %883 = getelementptr inbounds i8, i8* %13, i32 %882
  %884 = bitcast i8* %883 to <4 x i8>*
  %885 = load <4 x i8>, <4 x i8>* %884, align 4, !tbaa !108
  %886 = add i32 %865, %869
  %887 = getelementptr inbounds i8, i8* %13, i32 %886
  %888 = bitcast i8* %887 to <4 x i8>*
  %889 = load <4 x i8>, <4 x i8>* %888, align 4, !tbaa !108
  %890 = add i32 %868, %869
  %891 = getelementptr inbounds i8, i8* %13, i32 %890
  %892 = bitcast i8* %891 to <4 x i8>*
  %893 = load <4 x i8>, <4 x i8>* %892, align 4, !tbaa !108
  %894 = shufflevector <4 x i8> %873, <4 x i8> %877, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %895 = shufflevector <4 x i8> %881, <4 x i8> %885, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %896 = shufflevector <8 x i8> %894, <8 x i8> %895, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %897 = shufflevector <4 x i8> %889, <4 x i8> %893, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %898 = shufflevector <16 x i8> %896, <16 x i8> %897, <24 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %t1223.us.us.us.us.us = zext <24 x i8> %898 to <24 x i16>
  %899 = shufflevector <24 x i16> %t1223.us.us.us.us.us, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %900 = bitcast <64 x i16> %899 to <32 x i32>
  %901 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %900)
  %902 = bitcast <32 x i32> %901 to <64 x i16>
  %903 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %900)
  %904 = bitcast <32 x i32> %903 to <64 x i16>
  %905 = add <64 x i16> %904, %902
  %906 = shufflevector <64 x i16> %905, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1222.us.us.us.us.us = zext <12 x i16> %906 to <12 x i32>
  %907 = shufflevector <12 x i32> %t1222.us.us.us.us.us, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %908 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %907, i32 -4)
  %909 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %908)
  %910 = shufflevector <32 x i32> %909, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %911 = add nsw <6 x i32> %910, %sum_input314.sroa.0.11.us.us.us.us.us
  %912 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %908)
  %913 = shufflevector <32 x i32> %912, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %914 = add nsw <6 x i32> %911, %913
  %915 = shl i32 %"sum_input.s1.r19$z.r124.us.us.us.us.us", 2
  %916 = or i32 %915, 4
  %917 = add i32 %854, %916
  %918 = getelementptr inbounds i8, i8* %13, i32 %917
  %919 = bitcast i8* %918 to <4 x i8>*
  %920 = load <4 x i8>, <4 x i8>* %919, align 4, !tbaa !108
  %921 = add i32 %856, %916
  %922 = getelementptr inbounds i8, i8* %13, i32 %921
  %923 = bitcast i8* %922 to <4 x i8>*
  %924 = load <4 x i8>, <4 x i8>* %923, align 4, !tbaa !108
  %925 = add i32 %859, %916
  %926 = getelementptr inbounds i8, i8* %13, i32 %925
  %927 = bitcast i8* %926 to <4 x i8>*
  %928 = load <4 x i8>, <4 x i8>* %927, align 4, !tbaa !108
  %929 = add i32 %862, %916
  %930 = getelementptr inbounds i8, i8* %13, i32 %929
  %931 = bitcast i8* %930 to <4 x i8>*
  %932 = load <4 x i8>, <4 x i8>* %931, align 4, !tbaa !108
  %933 = add i32 %865, %916
  %934 = getelementptr inbounds i8, i8* %13, i32 %933
  %935 = bitcast i8* %934 to <4 x i8>*
  %936 = load <4 x i8>, <4 x i8>* %935, align 4, !tbaa !108
  %937 = add i32 %868, %916
  %938 = getelementptr inbounds i8, i8* %13, i32 %937
  %939 = bitcast i8* %938 to <4 x i8>*
  %940 = load <4 x i8>, <4 x i8>* %939, align 4, !tbaa !108
  %941 = shufflevector <4 x i8> %920, <4 x i8> %924, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %942 = shufflevector <4 x i8> %928, <4 x i8> %932, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %943 = shufflevector <8 x i8> %941, <8 x i8> %942, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %944 = shufflevector <4 x i8> %936, <4 x i8> %940, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %945 = shufflevector <16 x i8> %943, <16 x i8> %944, <24 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %t1223.us.us.us.us.us.1 = zext <24 x i8> %945 to <24 x i16>
  %946 = shufflevector <24 x i16> %t1223.us.us.us.us.us.1, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %947 = bitcast <64 x i16> %946 to <32 x i32>
  %948 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %947)
  %949 = bitcast <32 x i32> %948 to <64 x i16>
  %950 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %947)
  %951 = bitcast <32 x i32> %950 to <64 x i16>
  %952 = add <64 x i16> %951, %949
  %953 = shufflevector <64 x i16> %952, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1222.us.us.us.us.us.1 = zext <12 x i16> %953 to <12 x i32>
  %954 = shufflevector <12 x i32> %t1222.us.us.us.us.us.1, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %955 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %954, i32 -4)
  %956 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %955)
  %957 = shufflevector <32 x i32> %956, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %958 = add nsw <6 x i32> %957, %914
  %959 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %955)
  %960 = shufflevector <32 x i32> %959, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %961 = add nsw <6 x i32> %958, %960
  %962 = add nuw nsw i32 %"sum_input.s1.r19$z.r124.us.us.us.us.us", 2
  %niter1513.nsub.1 = add i32 %niter1513, -2
  %niter1513.ncmp.1 = icmp eq i32 %niter1513.nsub.1, 0
  br i1 %niter1513.ncmp.1, label %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124.us.us.us.us.us"

"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa": ; preds = %"for sum_input.s1.r19$z.r124.us.us.us.us.us", %"for sum_input.s1.r19$x15.us.us.us.us.us"
  %.lcssa.ph = phi <6 x i32> [ undef, %"for sum_input.s1.r19$x15.us.us.us.us.us" ], [ %961, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ]
  %sum_input314.sroa.0.11.us.us.us.us.us.unr = phi <6 x i32> [ %sum_input314.sroa.0.9.us.us.us.us.us, %"for sum_input.s1.r19$x15.us.us.us.us.us" ], [ %961, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r124.us.us.us.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x15.us.us.us.us.us" ], [ %962, %"for sum_input.s1.r19$z.r124.us.us.us.us.us" ]
  br i1 %lcmp.mod1511.not, label %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us", label %"for sum_input.s1.r19$z.r124.us.us.us.us.us.epil"

"for sum_input.s1.r19$z.r124.us.us.us.us.us.epil": ; preds = %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa"
  %963 = shl nsw i32 %"sum_input.s1.r19$z.r124.us.us.us.us.us.unr", 2
  %964 = add i32 %854, %963
  %965 = getelementptr inbounds i8, i8* %13, i32 %964
  %966 = bitcast i8* %965 to <4 x i8>*
  %967 = load <4 x i8>, <4 x i8>* %966, align 4, !tbaa !108
  %968 = add i32 %856, %963
  %969 = getelementptr inbounds i8, i8* %13, i32 %968
  %970 = bitcast i8* %969 to <4 x i8>*
  %971 = load <4 x i8>, <4 x i8>* %970, align 4, !tbaa !108
  %972 = add i32 %859, %963
  %973 = getelementptr inbounds i8, i8* %13, i32 %972
  %974 = bitcast i8* %973 to <4 x i8>*
  %975 = load <4 x i8>, <4 x i8>* %974, align 4, !tbaa !108
  %976 = add i32 %862, %963
  %977 = getelementptr inbounds i8, i8* %13, i32 %976
  %978 = bitcast i8* %977 to <4 x i8>*
  %979 = load <4 x i8>, <4 x i8>* %978, align 4, !tbaa !108
  %980 = add i32 %865, %963
  %981 = getelementptr inbounds i8, i8* %13, i32 %980
  %982 = bitcast i8* %981 to <4 x i8>*
  %983 = load <4 x i8>, <4 x i8>* %982, align 4, !tbaa !108
  %984 = add i32 %868, %963
  %985 = getelementptr inbounds i8, i8* %13, i32 %984
  %986 = bitcast i8* %985 to <4 x i8>*
  %987 = load <4 x i8>, <4 x i8>* %986, align 4, !tbaa !108
  %988 = shufflevector <4 x i8> %967, <4 x i8> %971, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %989 = shufflevector <4 x i8> %975, <4 x i8> %979, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %990 = shufflevector <8 x i8> %988, <8 x i8> %989, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %991 = shufflevector <4 x i8> %983, <4 x i8> %987, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %992 = shufflevector <16 x i8> %990, <16 x i8> %991, <24 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %t1223.us.us.us.us.us.epil = zext <24 x i8> %992 to <24 x i16>
  %993 = shufflevector <24 x i16> %t1223.us.us.us.us.us.epil, <24 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %994 = bitcast <64 x i16> %993 to <32 x i32>
  %995 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %994)
  %996 = bitcast <32 x i32> %995 to <64 x i16>
  %997 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %994)
  %998 = bitcast <32 x i32> %997 to <64 x i16>
  %999 = add <64 x i16> %998, %996
  %1000 = shufflevector <64 x i16> %999, <64 x i16> undef, <12 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %t1222.us.us.us.us.us.epil = zext <12 x i16> %1000 to <12 x i32>
  %1001 = shufflevector <12 x i32> %t1222.us.us.us.us.us.epil, <12 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1002 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1001, i32 -4)
  %1003 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1002)
  %1004 = shufflevector <32 x i32> %1003, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %1005 = add nsw <6 x i32> %1004, %sum_input314.sroa.0.11.us.us.us.us.us.unr
  %1006 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1002)
  %1007 = shufflevector <32 x i32> %1006, <32 x i32> undef, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5>
  %1008 = add nsw <6 x i32> %1005, %1007
  br label %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us"

"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa", %"for sum_input.s1.r19$z.r124.us.us.us.us.us.epil"
  %.lcssa = phi <6 x i32> [ %.lcssa.ph, %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us.unr-lcssa" ], [ %1008, %"for sum_input.s1.r19$z.r124.us.us.us.us.us.epil" ]
  %1009 = add nuw nsw i32 %"sum_input.s1.r19$x17.us.us.us.us.us", 1
  %.not378.us.us.us.us.us = icmp eq i32 %1009, %9
  br i1 %.not378.us.us.us.us.us, label %"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us", label %"for sum_input.s1.r19$x15.us.us.us.us.us"

"end for sum_input.s1.r19$x16.loopexit.split.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r124.loopexit.us.us.us.us.us"
  %1010 = add nuw nsw i32 %"sum_input.s1.r19$y14.us.us.us.us", 1
  %.not377.us.us.us.us = icmp eq i32 %1010, %11
  br i1 %.not377.us.us.us.us, label %"consume sum_input.us.us", label %"for sum_input.s1.r19$y12.us.us.us.us"

next_bb5:                                         ; preds = %"consume offset_c"
  br i1 %94, label %then_bb21, label %next_bb22

then_bb21:                                        ; preds = %next_bb5
  %1011 = mul nsw i32 %19, %18
  %1012 = mul nsw i32 %22, %20
  %1013 = mul nsw i32 %17, %16
  %1014 = add i32 %1012, %1011
  %t941 = add i32 %1014, %1013
  %1015 = icmp sgt i32 %21, 0
  br i1 %1015, label %"for output.s0.b.rebased23.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased23.preheader":            ; preds = %then_bb21
  %1016 = mul nsw i32 %17, %stride_x
  %1017 = mul nsw i32 %1016, 7
  %1018 = mul nsw i32 %1016, 6
  %1019 = mul nsw i32 %1016, 5
  %1020 = shl nsw i32 %1016, 2
  %1021 = mul nsw i32 %1016, 3
  %1022 = shl nsw i32 %1016, 1
  %1023 = sub nsw i32 %stride_x, %16
  %1024 = mul nsw i32 %1023, %17
  %1025 = icmp sgt i32 %29, 0
  %.neg781 = mul i32 %30, %28
  %.neg782 = mul i32 %27, %25
  %.neg783 = mul i32 %31, %20
  %reass.add785 = add i32 %.neg781, %.neg782
  %reass.add786 = add i32 %reass.add785, %.neg783
  %1026 = add nuw nsw i32 %26, 7
  %1027 = ashr i32 %1026, 3
  %b111 = add nsw i32 %26, -8
  %1028 = icmp sgt i32 %11, 0
  %1029 = icmp sgt i32 %9, 0
  %1030 = icmp sgt i32 %7, 0
  %1031 = ashr i32 %4, 6
  %1032 = icmp sgt i32 %4, 63
  %1033 = insertelement <32 x i32> undef, i32 %output_multiplier, i32 0
  %1034 = shufflevector <32 x i32> %1033, <32 x i32> undef, <32 x i32> zeroinitializer
  %1035 = sext <32 x i32> %1034 to <32 x i64>
  %1036 = icmp sgt i32 %a497, 0
  %1037 = select i1 %1036, i32 %a497, i32 0
  %1038 = shl nuw i32 1, %1037
  %1039 = ashr i32 %1038, 1
  %1040 = zext i8 %output_zero to i16
  %1041 = insertelement <64 x i16> undef, i16 %1040, i32 0
  %1042 = shufflevector <64 x i16> %1041, <64 x i16> undef, <64 x i32> zeroinitializer
  %1043 = insertelement <1 x i32> poison, i32 %1039, i32 0
  %1044 = insertelement <1 x i32> poison, i32 %a497, i32 0
  %1045 = insertelement <32 x i8> undef, i8 %output_max, i32 0
  %1046 = shufflevector <32 x i8> %1045, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1047 = bitcast <128 x i8> %1046 to <32 x i32>
  %1048 = insertelement <32 x i8> undef, i8 %output_min, i32 0
  %1049 = shufflevector <32 x i8> %1048, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1050 = bitcast <128 x i8> %1049 to <32 x i32>
  br i1 %1025, label %"for output.s0.b.rebased23.us.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased23.us.preheader":         ; preds = %"for output.s0.b.rebased23.preheader"
  %1051 = add i32 %1013, %1011
  %1052 = add i32 %9, -1
  %brmerge1308.demorgan = and i1 %1029, %1030
  %xtraiter1500 = and i32 %7, 1
  %1053 = icmp eq i32 %7, 1
  %unroll_iter1502 = and i32 %7, -2
  %lcmp.mod1501.not = icmp eq i32 %xtraiter1500, 0
  %xtraiter1504 = and i32 %9, 3
  %1054 = icmp ult i32 %1052, 3
  %unroll_iter1508 = and i32 %9, -4
  %lcmp.mod1506.not = icmp eq i32 %xtraiter1504, 0
  br label %"for output.s0.b.rebased23.us"

"for output.s0.b.rebased23.us":                   ; preds = %"for output.s0.b.rebased23.us.preheader", %"end for output.s0.y.rebased27.loopexit.us"
  %convolved313.sroa.0.7.us = phi <32 x i32> [ %.us-phi1094.us, %"end for output.s0.y.rebased27.loopexit.us" ], [ undef, %"for output.s0.b.rebased23.us.preheader" ]
  %output.s0.b.rebased25.us = phi i32 [ %1061, %"end for output.s0.y.rebased27.loopexit.us" ], [ 0, %"for output.s0.b.rebased23.us.preheader" ]
  %1055 = add nsw i32 %output.s0.b.rebased25.us, %20
  %1056 = mul nsw i32 %1055, %31
  %1057 = sub i32 %1056, %reass.add786
  %1058 = mul nsw i32 %1055, %22
  %1059 = sub i32 %1058, %1014
  %1060 = sub nsw i32 %1058, %t941
  br i1 %100, label %"for output.s0.y.rebased26.us.us", label %"end for output.s0.y.rebased27.loopexit.us", !prof !96

"end for output.s0.y.rebased27.loopexit.us":      ; preds = %"end for output.s0.x.xo30.loopexit.us.us", %"for output.s0.b.rebased23.us"
  %.us-phi1094.us = phi <32 x i32> [ %convolved313.sroa.0.7.us, %"for output.s0.b.rebased23.us" ], [ %convolved313.sroa.0.20.us.us, %"end for output.s0.x.xo30.loopexit.us.us" ]
  %1061 = add nuw nsw i32 %output.s0.b.rebased25.us, 1
  %.not358.us = icmp eq i32 %1061, %21
  br i1 %.not358.us, label %after_bb3, label %"for output.s0.b.rebased23.us"

"for output.s0.y.rebased26.us.us":                ; preds = %"for output.s0.b.rebased23.us", %"end for output.s0.x.xo30.loopexit.us.us"
  %convolved313.sroa.0.8.us.us = phi <32 x i32> [ %convolved313.sroa.0.20.us.us, %"end for output.s0.x.xo30.loopexit.us.us" ], [ %convolved313.sroa.0.7.us, %"for output.s0.b.rebased23.us" ]
  %output.s0.y.rebased28.us.us = phi i32 [ %2726, %"end for output.s0.x.xo30.loopexit.us.us" ], [ 0, %"for output.s0.b.rebased23.us" ]
  %1062 = add nsw i32 %output.s0.y.rebased28.us.us, %28
  %1063 = mul nsw i32 %1062, %30
  %t970.us.us = add i32 %1057, %1063
  %1064 = mul nsw i32 %1062, %stride_y
  br label %"for output.s0.x.xo29.us.us"

"for output.s0.x.xo29.us.us":                     ; preds = %"end for output.s0.c.co58.us.us", %"for output.s0.y.rebased26.us.us"
  %convolved313.sroa.0.10.us.us = phi <32 x i32> [ %convolved313.sroa.0.20.us.us, %"end for output.s0.c.co58.us.us" ], [ %convolved313.sroa.0.8.us.us, %"for output.s0.y.rebased26.us.us" ]
  %output.s0.x.xo31.us.us = phi i32 [ %2674, %"end for output.s0.c.co58.us.us" ], [ 0, %"for output.s0.y.rebased26.us.us" ]
  %a109.us.us = shl nsw i32 %output.s0.x.xo31.us.us, 3
  %1065 = icmp slt i32 %a109.us.us, %b111
  %output.s0.x.x.base.s32.us.us = select i1 %1065, i32 %a109.us.us, i32 %b111
  br i1 %t843.not, label %"consume sum_input56.us.us", label %then_bb36.us.us

then_bb36.us.us:                                  ; preds = %"for output.s0.x.xo29.us.us"
  %convolved313.sroa.0.0.vecblend.us.us = shufflevector <32 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>, <32 x i32> %convolved313.sroa.0.10.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  br i1 %t844, label %then_bb39.us.us, label %next_bb40.us.us

next_bb40.us.us:                                  ; preds = %then_bb36.us.us
  br i1 %1028, label %"for sum_input.s1.r19$y47.preheader.us.us", label %"consume sum_input56.us.us", !prof !96

then_bb39.us.us:                                  ; preds = %then_bb36.us.us
  br i1 %1028, label %"for sum_input.s1.r19$y41.preheader.us.us", label %"consume sum_input56.us.us", !prof !96

"for sum_input.s1.r19$y41.us.us":                 ; preds = %"for sum_input.s1.r19$y41.preheader.us.us", %"end for sum_input.s1.r19$x45.us.us"
  %convolved313.sroa.0.12.us.us = phi <32 x i32> [ %convolved313.sroa.0.14.us.us, %"end for sum_input.s1.r19$x45.us.us" ], [ %convolved313.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y41.preheader.us.us" ]
  %"sum_input.s1.r19$y43.us.us" = phi i32 [ %1166, %"end for sum_input.s1.r19$x45.us.us" ], [ 0, %"for sum_input.s1.r19$y41.preheader.us.us" ]
  br i1 %1029, label %"for sum_input.s1.r19$x44.preheader.us.us", label %"end for sum_input.s1.r19$x45.us.us", !prof !96

"for sum_input.s1.r19$x44.us.us":                 ; preds = %"for sum_input.s1.r19$x44.preheader.us.us", %"for sum_input.s1.r19$x44.us.us"
  %convolved313.sroa.0.13.us.us = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend562.us.us.3, %"for sum_input.s1.r19$x44.us.us" ], [ %convolved313.sroa.0.12.us.us, %"for sum_input.s1.r19$x44.preheader.us.us" ]
  %"sum_input.s1.r19$x46.us.us" = phi i32 [ %1145, %"for sum_input.s1.r19$x44.us.us" ], [ 0, %"for sum_input.s1.r19$x44.preheader.us.us" ]
  %niter1509 = phi i32 [ %niter1509.nsub.3, %"for sum_input.s1.r19$x44.us.us" ], [ %unroll_iter1508, %"for sum_input.s1.r19$x44.preheader.us.us" ]
  %1066 = mul nsw i32 %"sum_input.s1.r19$x46.us.us", %dilation_x
  %reass.add791.us.us = add i32 %2723, %1066
  %reass.mul792.us.us = shl i32 %reass.add791.us.us, 2
  %1067 = add i32 %t973.us.us, %reass.mul792.us.us
  %1068 = getelementptr inbounds i8, i8* %13, i32 %1067
  %1069 = bitcast i8* %1068 to <32 x i8>*
  %1070 = load <32 x i8>, <32 x i8>* %1069, align 4, !tbaa !108
  %t1225.us.us = zext <32 x i8> %1070 to <32 x i16>
  %1071 = shufflevector <32 x i16> %t1225.us.us, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1072 = bitcast <64 x i16> %1071 to <32 x i32>
  %1073 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %1072)
  %1074 = bitcast <32 x i32> %1073 to <64 x i16>
  %1075 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %1072)
  %1076 = bitcast <32 x i32> %1075 to <64 x i16>
  %1077 = add <64 x i16> %1076, %1074
  %1078 = shufflevector <64 x i16> %1077, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1224.us.us = zext <16 x i16> %1078 to <16 x i32>
  %1079 = shufflevector <16 x i32> %t1224.us.us, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1080 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1079, i32 -4)
  %1081 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1080)
  %1082 = add nsw <32 x i32> %1081, %convolved313.sroa.0.13.us.us
  %1083 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1080)
  %1084 = add nsw <32 x i32> %1082, %1083
  %convolved313.sroa.0.0.vecblend562.us.us = shufflevector <32 x i32> %1084, <32 x i32> %convolved313.sroa.0.13.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1085 = or i32 %"sum_input.s1.r19$x46.us.us", 1
  %1086 = mul nsw i32 %1085, %dilation_x
  %reass.add791.us.us.1 = add i32 %2723, %1086
  %reass.mul792.us.us.1 = shl i32 %reass.add791.us.us.1, 2
  %1087 = add i32 %t973.us.us, %reass.mul792.us.us.1
  %1088 = getelementptr inbounds i8, i8* %13, i32 %1087
  %1089 = bitcast i8* %1088 to <32 x i8>*
  %1090 = load <32 x i8>, <32 x i8>* %1089, align 4, !tbaa !108
  %t1225.us.us.1 = zext <32 x i8> %1090 to <32 x i16>
  %1091 = shufflevector <32 x i16> %t1225.us.us.1, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1092 = bitcast <64 x i16> %1091 to <32 x i32>
  %1093 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %1092)
  %1094 = bitcast <32 x i32> %1093 to <64 x i16>
  %1095 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %1092)
  %1096 = bitcast <32 x i32> %1095 to <64 x i16>
  %1097 = add <64 x i16> %1096, %1094
  %1098 = shufflevector <64 x i16> %1097, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1224.us.us.1 = zext <16 x i16> %1098 to <16 x i32>
  %1099 = shufflevector <16 x i32> %t1224.us.us.1, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1100 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1099, i32 -4)
  %1101 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1100)
  %1102 = add nsw <32 x i32> %1101, %convolved313.sroa.0.0.vecblend562.us.us
  %1103 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1100)
  %1104 = add nsw <32 x i32> %1102, %1103
  %convolved313.sroa.0.0.vecblend562.us.us.1 = shufflevector <32 x i32> %1104, <32 x i32> %convolved313.sroa.0.0.vecblend562.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1105 = or i32 %"sum_input.s1.r19$x46.us.us", 2
  %1106 = mul nsw i32 %1105, %dilation_x
  %reass.add791.us.us.2 = add i32 %2723, %1106
  %reass.mul792.us.us.2 = shl i32 %reass.add791.us.us.2, 2
  %1107 = add i32 %t973.us.us, %reass.mul792.us.us.2
  %1108 = getelementptr inbounds i8, i8* %13, i32 %1107
  %1109 = bitcast i8* %1108 to <32 x i8>*
  %1110 = load <32 x i8>, <32 x i8>* %1109, align 4, !tbaa !108
  %t1225.us.us.2 = zext <32 x i8> %1110 to <32 x i16>
  %1111 = shufflevector <32 x i16> %t1225.us.us.2, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1112 = bitcast <64 x i16> %1111 to <32 x i32>
  %1113 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %1112)
  %1114 = bitcast <32 x i32> %1113 to <64 x i16>
  %1115 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %1112)
  %1116 = bitcast <32 x i32> %1115 to <64 x i16>
  %1117 = add <64 x i16> %1116, %1114
  %1118 = shufflevector <64 x i16> %1117, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1224.us.us.2 = zext <16 x i16> %1118 to <16 x i32>
  %1119 = shufflevector <16 x i32> %t1224.us.us.2, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1120 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1119, i32 -4)
  %1121 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1120)
  %1122 = add nsw <32 x i32> %1121, %convolved313.sroa.0.0.vecblend562.us.us.1
  %1123 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1120)
  %1124 = add nsw <32 x i32> %1122, %1123
  %convolved313.sroa.0.0.vecblend562.us.us.2 = shufflevector <32 x i32> %1124, <32 x i32> %convolved313.sroa.0.0.vecblend562.us.us.1, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1125 = or i32 %"sum_input.s1.r19$x46.us.us", 3
  %1126 = mul nsw i32 %1125, %dilation_x
  %reass.add791.us.us.3 = add i32 %2723, %1126
  %reass.mul792.us.us.3 = shl i32 %reass.add791.us.us.3, 2
  %1127 = add i32 %t973.us.us, %reass.mul792.us.us.3
  %1128 = getelementptr inbounds i8, i8* %13, i32 %1127
  %1129 = bitcast i8* %1128 to <32 x i8>*
  %1130 = load <32 x i8>, <32 x i8>* %1129, align 4, !tbaa !108
  %t1225.us.us.3 = zext <32 x i8> %1130 to <32 x i16>
  %1131 = shufflevector <32 x i16> %t1225.us.us.3, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1132 = bitcast <64 x i16> %1131 to <32 x i32>
  %1133 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %1132)
  %1134 = bitcast <32 x i32> %1133 to <64 x i16>
  %1135 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %1132)
  %1136 = bitcast <32 x i32> %1135 to <64 x i16>
  %1137 = add <64 x i16> %1136, %1134
  %1138 = shufflevector <64 x i16> %1137, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1224.us.us.3 = zext <16 x i16> %1138 to <16 x i32>
  %1139 = shufflevector <16 x i32> %t1224.us.us.3, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1140 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1139, i32 -4)
  %1141 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1140)
  %1142 = add nsw <32 x i32> %1141, %convolved313.sroa.0.0.vecblend562.us.us.2
  %1143 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1140)
  %1144 = add nsw <32 x i32> %1142, %1143
  %convolved313.sroa.0.0.vecblend562.us.us.3 = shufflevector <32 x i32> %1144, <32 x i32> %convolved313.sroa.0.0.vecblend562.us.us.2, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1145 = add nuw nsw i32 %"sum_input.s1.r19$x46.us.us", 4
  %niter1509.nsub.3 = add i32 %niter1509, -4
  %niter1509.ncmp.3 = icmp eq i32 %niter1509.nsub.3, 0
  br i1 %niter1509.ncmp.3, label %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x44.us.us"

"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa": ; preds = %"for sum_input.s1.r19$x44.us.us", %"for sum_input.s1.r19$x44.preheader.us.us"
  %convolved313.sroa.0.0.vecblend562.us.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x44.preheader.us.us" ], [ %convolved313.sroa.0.0.vecblend562.us.us.3, %"for sum_input.s1.r19$x44.us.us" ]
  %convolved313.sroa.0.13.us.us.unr = phi <32 x i32> [ %convolved313.sroa.0.12.us.us, %"for sum_input.s1.r19$x44.preheader.us.us" ], [ %convolved313.sroa.0.0.vecblend562.us.us.3, %"for sum_input.s1.r19$x44.us.us" ]
  %"sum_input.s1.r19$x46.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x44.preheader.us.us" ], [ %1145, %"for sum_input.s1.r19$x44.us.us" ]
  br i1 %lcmp.mod1506.not, label %"end for sum_input.s1.r19$x45.us.us", label %"for sum_input.s1.r19$x44.us.us.epil"

"for sum_input.s1.r19$x44.us.us.epil":            ; preds = %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x44.us.us.epil"
  %convolved313.sroa.0.13.us.us.epil = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend562.us.us.epil, %"for sum_input.s1.r19$x44.us.us.epil" ], [ %convolved313.sroa.0.13.us.us.unr, %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa" ]
  %"sum_input.s1.r19$x46.us.us.epil" = phi i32 [ %1165, %"for sum_input.s1.r19$x44.us.us.epil" ], [ %"sum_input.s1.r19$x46.us.us.unr", %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa" ]
  %epil.iter1505 = phi i32 [ %epil.iter1505.sub, %"for sum_input.s1.r19$x44.us.us.epil" ], [ %xtraiter1504, %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa" ]
  %1146 = mul nsw i32 %"sum_input.s1.r19$x46.us.us.epil", %dilation_x
  %reass.add791.us.us.epil = add i32 %2723, %1146
  %reass.mul792.us.us.epil = shl i32 %reass.add791.us.us.epil, 2
  %1147 = add i32 %t973.us.us, %reass.mul792.us.us.epil
  %1148 = getelementptr inbounds i8, i8* %13, i32 %1147
  %1149 = bitcast i8* %1148 to <32 x i8>*
  %1150 = load <32 x i8>, <32 x i8>* %1149, align 4, !tbaa !108
  %t1225.us.us.epil = zext <32 x i8> %1150 to <32 x i16>
  %1151 = shufflevector <32 x i16> %t1225.us.us.epil, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1152 = bitcast <64 x i16> %1151 to <32 x i32>
  %1153 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %1152)
  %1154 = bitcast <32 x i32> %1153 to <64 x i16>
  %1155 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %1152)
  %1156 = bitcast <32 x i32> %1155 to <64 x i16>
  %1157 = add <64 x i16> %1156, %1154
  %1158 = shufflevector <64 x i16> %1157, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1224.us.us.epil = zext <16 x i16> %1158 to <16 x i32>
  %1159 = shufflevector <16 x i32> %t1224.us.us.epil, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1160 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %1159, i32 -4)
  %1161 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %1160)
  %1162 = add nsw <32 x i32> %1161, %convolved313.sroa.0.13.us.us.epil
  %1163 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %1160)
  %1164 = add nsw <32 x i32> %1162, %1163
  %convolved313.sroa.0.0.vecblend562.us.us.epil = shufflevector <32 x i32> %1164, <32 x i32> %convolved313.sroa.0.13.us.us.epil, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %1165 = add nuw nsw i32 %"sum_input.s1.r19$x46.us.us.epil", 1
  %epil.iter1505.sub = add i32 %epil.iter1505, -1
  %epil.iter1505.cmp.not = icmp eq i32 %epil.iter1505.sub, 0
  br i1 %epil.iter1505.cmp.not, label %"end for sum_input.s1.r19$x45.us.us", label %"for sum_input.s1.r19$x44.us.us.epil", !llvm.loop !113

"end for sum_input.s1.r19$x45.us.us":             ; preds = %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x44.us.us.epil", %"for sum_input.s1.r19$y41.us.us"
  %convolved313.sroa.0.14.us.us = phi <32 x i32> [ %convolved313.sroa.0.12.us.us, %"for sum_input.s1.r19$y41.us.us" ], [ %convolved313.sroa.0.0.vecblend562.us.us.lcssa.ph, %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa" ], [ %convolved313.sroa.0.0.vecblend562.us.us.epil, %"for sum_input.s1.r19$x44.us.us.epil" ]
  %1166 = add nuw nsw i32 %"sum_input.s1.r19$y43.us.us", 1
  %.not368.us.us = icmp eq i32 %1166, %11
  br i1 %.not368.us.us, label %"consume sum_input56.us.us", label %"for sum_input.s1.r19$y41.us.us"

"consume sum_input56.us.us":                      ; preds = %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us", %"end for sum_input.s1.r19$x45.us.us", %"for sum_input.s1.r19$y47.preheader.us.us", %then_bb39.us.us, %next_bb40.us.us, %"for output.s0.x.xo29.us.us"
  %convolved313.sroa.0.20.us.us = phi <32 x i32> [ %convolved313.sroa.0.10.us.us, %"for output.s0.x.xo29.us.us" ], [ %convolved313.sroa.0.0.vecblend.us.us, %then_bb39.us.us ], [ %convolved313.sroa.0.0.vecblend.us.us, %next_bb40.us.us ], [ %convolved313.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y47.preheader.us.us" ], [ %convolved313.sroa.0.14.us.us, %"end for sum_input.s1.r19$x45.us.us" ], [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us" ]
  br i1 %1032, label %"for output.s0.c.co57.preheader.us.us", label %"end for output.s0.c.co58.us.us", !prof !96

"for output.s0.c.co57.us.us":                     ; preds = %"for output.s0.c.co57.preheader.us.us", %"consume convolved73.us.us"
  %output.s0.c.co59.us.us = phi i32 [ %2673, %"consume convolved73.us.us" ], [ 0, %"for output.s0.c.co57.preheader.us.us" ]
  %1167 = shl nsw i32 %output.s0.c.co59.us.us, 6
  %1168 = getelementptr inbounds i32, i32* %offset_c, i32 %1167
  %1169 = bitcast i32* %1168 to <32 x i32>*
  %1170 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  br i1 %t843.not, label %then_bb62.us.us, label %next_bb63.us.us

next_bb63.us.us:                                  ; preds = %"for output.s0.c.co57.us.us"
  %1171 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2683, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1172 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1170, <32 x i32> %1171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1173 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1174 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2685, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1175 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1173, <32 x i32> %1174, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1176 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1177 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2687, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1178 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1176, <32 x i32> %1177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1179 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1180 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2689, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1181 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1179, <32 x i32> %1180, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1182 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1183 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2691, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1184 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1182, <32 x i32> %1183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1185 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1186 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2693, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1187 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1185, <32 x i32> %1186, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1188 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1189 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2695, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1190 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1188, <32 x i32> %1189, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1191 = load <32 x i32>, <32 x i32>* %1169, align 128, !tbaa !104
  %1192 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2697, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1193 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1191, <32 x i32> %1192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1194 = getelementptr inbounds i32, i32* %1168, i32 32
  %1195 = bitcast i32* %1194 to <32 x i32>*
  %1196 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1197 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2683, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1198 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1196, <32 x i32> %1197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1199 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1200 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2685, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1201 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1199, <32 x i32> %1200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1202 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1203 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2687, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1204 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1202, <32 x i32> %1203, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1205 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1206 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2689, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1207 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1205, <32 x i32> %1206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1208 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1209 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2691, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1210 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1208, <32 x i32> %1209, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1211 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1212 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2693, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1213 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1211, <32 x i32> %1212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1214 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1215 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2695, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1216 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1214, <32 x i32> %1215, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %1217 = load <32 x i32>, <32 x i32>* %1195, align 128, !tbaa !104
  %1218 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %2697, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1219 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %1217, <32 x i32> %1218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb61.us.us

then_bb62.us.us:                                  ; preds = %"for output.s0.c.co57.us.us"
  %1220 = getelementptr inbounds i32, i32* %1168, i32 32
  %1221 = bitcast i32* %1220 to <32 x i32>*
  %1222 = load <32 x i32>, <32 x i32>* %1221, align 128, !tbaa !104
  br label %after_bb61.us.us

after_bb61.us.us:                                 ; preds = %then_bb62.us.us, %next_bb63.us.us
  %sum_input187312.sroa.155.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1219, %next_bb63.us.us ]
  %sum_input187312.sroa.146.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1193, %next_bb63.us.us ]
  %sum_input187312.sroa.137.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1216, %next_bb63.us.us ]
  %sum_input187312.sroa.128.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1190, %next_bb63.us.us ]
  %sum_input187312.sroa.119.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1213, %next_bb63.us.us ]
  %sum_input187312.sroa.110.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1187, %next_bb63.us.us ]
  %sum_input187312.sroa.101.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1210, %next_bb63.us.us ]
  %sum_input187312.sroa.92.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1184, %next_bb63.us.us ]
  %sum_input187312.sroa.83.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1207, %next_bb63.us.us ]
  %sum_input187312.sroa.74.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1181, %next_bb63.us.us ]
  %sum_input187312.sroa.65.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1204, %next_bb63.us.us ]
  %sum_input187312.sroa.56.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1178, %next_bb63.us.us ]
  %sum_input187312.sroa.47.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1201, %next_bb63.us.us ]
  %sum_input187312.sroa.38.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1175, %next_bb63.us.us ]
  %sum_input187312.sroa.29.0.us.us = phi <32 x i32> [ %1222, %then_bb62.us.us ], [ %1198, %next_bb63.us.us ]
  %sum_input187312.sroa.0.0.us.us = phi <32 x i32> [ %1170, %then_bb62.us.us ], [ %1172, %next_bb63.us.us ]
  br i1 %1028, label %"for convolved.s1.r19$y64.preheader.us.us", label %"consume convolved73.us.us", !prof !96

"consume convolved73.us.us":                      ; preds = %"end for convolved.s1.r19$x68.loopexit.us.us.us", %"for convolved.s1.r19$y64.preheader.us.us", %after_bb61.us.us
  %sum_input187312.sroa.155.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.155.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.155.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1041.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.146.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.146.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.146.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1042.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.137.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.137.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.137.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1043.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.128.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.128.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.128.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1044.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.119.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.119.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.119.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1045.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.110.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.110.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.110.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1046.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.101.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.101.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.101.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1047.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.92.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.92.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.92.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1048.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.83.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.83.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.83.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1049.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.74.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.74.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.74.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1050.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.65.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.65.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.65.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1051.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.56.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.56.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.56.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1052.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.47.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.47.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.47.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1053.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.38.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.38.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.38.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1054.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.29.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.29.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.29.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1055.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %sum_input187312.sroa.0.6.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.us.us, %after_bb61.us.us ], [ %sum_input187312.sroa.0.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ], [ %.us-phi1056.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ]
  %1223 = sext <32 x i32> %sum_input187312.sroa.0.6.us.us to <32 x i64>
  %a112.us.us = mul nsw <32 x i64> %1223, %1035
  %1224 = icmp slt <32 x i64> %a112.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1225 = select <32 x i1> %1224, <32 x i64> %a112.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1226 = add nsw <32 x i64> %1225, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a111.us.us = ashr <32 x i64> %1226, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1227 = icmp slt <32 x i64> %a111.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a110.us.us = select <32 x i1> %1227, <32 x i64> %a111.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1228 = icmp sgt <32 x i64> %a110.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1229 = select <32 x i1> %1228, <32 x i64> %a110.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1230 = trunc <32 x i64> %1229 to <32 x i32>
  %1231 = sext <32 x i32> %sum_input187312.sroa.29.6.us.us to <32 x i64>
  %a116.us.us = mul nsw <32 x i64> %1231, %1035
  %1232 = icmp slt <32 x i64> %a116.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1233 = select <32 x i1> %1232, <32 x i64> %a116.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1234 = add nsw <32 x i64> %1233, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a115.us.us = ashr <32 x i64> %1234, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1235 = icmp slt <32 x i64> %a115.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a114.us.us = select <32 x i1> %1235, <32 x i64> %a115.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1236 = icmp sgt <32 x i64> %a114.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1237 = select <32 x i1> %1236, <32 x i64> %a114.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1238 = trunc <32 x i64> %1237 to <32 x i32>
  %1239 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1240 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1241 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1240, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1242 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1239, <1 x i32> zeroinitializer, <32 x i32> %1241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1243 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1244 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1245 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1244, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1246 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1243, <1 x i32> zeroinitializer, <32 x i32> %1245, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1247 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1242, <32 x i32> %1246, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1248 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1247, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1249 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1248, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1250 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1249, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1251 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1252 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1253 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1252, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1254 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1251, <1 x i32> zeroinitializer, <32 x i32> %1253, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1255 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1256 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1257 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1258 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1255, <1 x i32> zeroinitializer, <32 x i32> %1257, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1259 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1254, <32 x i32> %1258, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1260 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1259, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1261 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1262 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1263 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1250, <32 x i32> %1262, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1264 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1263, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1265 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1264, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1266 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1265, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1267 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1268 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1269 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1268, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1270 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1267, <1 x i32> zeroinitializer, <32 x i32> %1269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1271 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1272 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1273 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1272, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1274 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1271, <1 x i32> zeroinitializer, <32 x i32> %1273, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1275 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1270, <32 x i32> %1274, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1276 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1275, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1277 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1276, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1278 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1277, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1279 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1280 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1281 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1280, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1282 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1279, <1 x i32> zeroinitializer, <32 x i32> %1281, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1283 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1284 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1285 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1286 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1283, <1 x i32> zeroinitializer, <32 x i32> %1285, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1287 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1282, <32 x i32> %1286, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1288 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1287, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1289 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1290 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1291 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1278, <32 x i32> %1290, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1292 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1291, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1293 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1292, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1294 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1293, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1295 = trunc <64 x i16> %1294 to <64 x i8>
  %1296 = bitcast <64 x i8> %1295 to <8 x i64>
  %1297 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1298 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1299 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1300 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1297, <1 x i32> zeroinitializer, <32 x i32> %1299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1301 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1302 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1303 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1302, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1304 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1301, <1 x i32> zeroinitializer, <32 x i32> %1303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1305 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1300, <32 x i32> %1304, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1306 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1305, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1307 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1306, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1308 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1307, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1309 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1310 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1311 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1310, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1312 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1309, <1 x i32> zeroinitializer, <32 x i32> %1311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1313 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1314 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1315 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1314, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1316 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1313, <1 x i32> zeroinitializer, <32 x i32> %1315, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1317 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1312, <32 x i32> %1316, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1318 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1317, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1319 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1320 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1319, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1321 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1308, <32 x i32> %1320, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1322 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1321, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1323 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1322, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1324 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1323, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1325 = shufflevector <8 x i64> %1296, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1326 = bitcast <4 x i64> %1325 to <32 x i8>
  %1327 = shufflevector <32 x i8> %1326, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1328 = bitcast <128 x i8> %1327 to <32 x i32>
  %1329 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1328, <32 x i32> %1047) #11
  %1330 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1329, <32 x i32> %1050) #11
  %1331 = bitcast <32 x i32> %1330 to <128 x i8>
  %1332 = shufflevector <128 x i8> %1331, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1333 = shl nsw i32 %output.s0.c.co59.us.us, 6
  %1334 = add i32 %1333, %t970.us.us
  %1335 = add i32 %1334, %2714
  %1336 = getelementptr inbounds i8, i8* %23, i32 %1335
  %1337 = bitcast i8* %1336 to <32 x i8>*
  store <32 x i8> %1332, <32 x i8>* %1337, align 1, !tbaa !111
  %1338 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1339 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1340 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1341 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1338, <1 x i32> zeroinitializer, <32 x i32> %1340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1342 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1343 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1344 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1343, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1345 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1342, <1 x i32> zeroinitializer, <32 x i32> %1344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1346 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1341, <32 x i32> %1345, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1347 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1346, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1348 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1347, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1349 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1348, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1350 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1351 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1352 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1351, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1353 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1350, <1 x i32> zeroinitializer, <32 x i32> %1352, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1354 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1355 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1356 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1355, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1357 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1354, <1 x i32> zeroinitializer, <32 x i32> %1356, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1358 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1353, <32 x i32> %1357, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1359 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1358, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1360 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1359, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1361 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1362 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1349, <32 x i32> %1361, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1363 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1362, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1364 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1363, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1365 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1364, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1366 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1367 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1368 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1369 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1366, <1 x i32> zeroinitializer, <32 x i32> %1368, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1370 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1371 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1372 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1371, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1373 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1370, <1 x i32> zeroinitializer, <32 x i32> %1372, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1374 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1369, <32 x i32> %1373, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1375 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1374, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1376 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1375, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1377 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1376, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1378 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1379 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1380 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1230, <32 x i32> %1379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1381 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1378, <1 x i32> zeroinitializer, <32 x i32> %1380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1382 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1383 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1384 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1238, <32 x i32> %1383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1385 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1382, <1 x i32> zeroinitializer, <32 x i32> %1384, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1386 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1381, <32 x i32> %1385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1387 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1386, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1388 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1387, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1389 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1390 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1377, <32 x i32> %1389, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1391 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1390, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1392 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1391, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1393 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1392, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1394 = trunc <64 x i16> %1393 to <64 x i8>
  %1395 = bitcast <64 x i8> %1394 to <8 x i64>
  %1396 = shufflevector <8 x i64> %1395, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %1397 = bitcast <4 x i64> %1396 to <32 x i8>
  %1398 = shufflevector <32 x i8> %1397, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1399 = bitcast <128 x i8> %1398 to <32 x i32>
  %1400 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1399, <32 x i32> %1047) #11
  %1401 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1400, <32 x i32> %1050) #11
  %1402 = bitcast <32 x i32> %1401 to <128 x i8>
  %1403 = shufflevector <128 x i8> %1402, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1404 = getelementptr inbounds i8, i8* %1336, i32 32
  %1405 = bitcast i8* %1404 to <32 x i8>*
  store <32 x i8> %1403, <32 x i8>* %1405, align 1, !tbaa !111
  %1406 = sext <32 x i32> %sum_input187312.sroa.38.6.us.us to <32 x i64>
  %a152.us.us = mul nsw <32 x i64> %1406, %1035
  %1407 = icmp slt <32 x i64> %a152.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1408 = select <32 x i1> %1407, <32 x i64> %a152.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1409 = add nsw <32 x i64> %1408, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a151.us.us = ashr <32 x i64> %1409, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1410 = icmp slt <32 x i64> %a151.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a150.us.us = select <32 x i1> %1410, <32 x i64> %a151.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1411 = icmp sgt <32 x i64> %a150.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1412 = select <32 x i1> %1411, <32 x i64> %a150.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1413 = trunc <32 x i64> %1412 to <32 x i32>
  %1414 = sext <32 x i32> %sum_input187312.sroa.47.6.us.us to <32 x i64>
  %a156.us.us = mul nsw <32 x i64> %1414, %1035
  %1415 = icmp slt <32 x i64> %a156.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1416 = select <32 x i1> %1415, <32 x i64> %a156.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1417 = add nsw <32 x i64> %1416, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a155.us.us = ashr <32 x i64> %1417, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1418 = icmp slt <32 x i64> %a155.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a154.us.us = select <32 x i1> %1418, <32 x i64> %a155.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1419 = icmp sgt <32 x i64> %a154.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1420 = select <32 x i1> %1419, <32 x i64> %a154.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1421 = trunc <32 x i64> %1420 to <32 x i32>
  %1422 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1423 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1424 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1425 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1422, <1 x i32> zeroinitializer, <32 x i32> %1424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1426 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1427 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1428 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1427, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1429 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1426, <1 x i32> zeroinitializer, <32 x i32> %1428, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1430 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1425, <32 x i32> %1429, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1431 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1430, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1432 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1431, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1433 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1434 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1435 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1436 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1437 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1434, <1 x i32> zeroinitializer, <32 x i32> %1436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1438 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1439 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1440 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1439, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1441 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1438, <1 x i32> zeroinitializer, <32 x i32> %1440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1442 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1437, <32 x i32> %1441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1443 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1444 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1443, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1445 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1444, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1446 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1433, <32 x i32> %1445, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1447 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1446, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1448 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1447, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1449 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1448, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1450 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1451 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1452 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1453 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1450, <1 x i32> zeroinitializer, <32 x i32> %1452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1454 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1455 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1456 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1455, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1457 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1454, <1 x i32> zeroinitializer, <32 x i32> %1456, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1458 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1453, <32 x i32> %1457, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1459 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1458, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1460 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1459, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1461 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1462 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1463 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1464 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1465 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1462, <1 x i32> zeroinitializer, <32 x i32> %1464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1466 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1467 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1468 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1467, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1469 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1466, <1 x i32> zeroinitializer, <32 x i32> %1468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1470 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1465, <32 x i32> %1469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1471 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1472 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1471, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1473 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1472, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1474 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1461, <32 x i32> %1473, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1475 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1474, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1476 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1477 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1476, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1478 = trunc <64 x i16> %1477 to <64 x i8>
  %1479 = bitcast <64 x i8> %1478 to <8 x i64>
  %1480 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1481 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1482 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1481, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1483 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1480, <1 x i32> zeroinitializer, <32 x i32> %1482, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1484 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1485 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1486 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1485, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1487 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1484, <1 x i32> zeroinitializer, <32 x i32> %1486, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1488 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1483, <32 x i32> %1487, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1489 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1488, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1490 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1489, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1491 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1490, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1492 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1493 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1494 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1493, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1495 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1492, <1 x i32> zeroinitializer, <32 x i32> %1494, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1496 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1497 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1498 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1497, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1499 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1496, <1 x i32> zeroinitializer, <32 x i32> %1498, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1500 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1495, <32 x i32> %1499, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1501 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1500, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1502 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1501, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1503 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1502, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1504 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1491, <32 x i32> %1503, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1505 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1504, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1506 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1505, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1507 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1506, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1508 = shufflevector <8 x i64> %1479, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1509 = bitcast <4 x i64> %1508 to <32 x i8>
  %1510 = shufflevector <32 x i8> %1509, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1511 = bitcast <128 x i8> %1510 to <32 x i32>
  %1512 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1511, <32 x i32> %1047) #11
  %1513 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1512, <32 x i32> %1050) #11
  %1514 = bitcast <32 x i32> %1513 to <128 x i8>
  %1515 = shufflevector <128 x i8> %1514, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1516 = add i32 %1334, %2715
  %1517 = getelementptr inbounds i8, i8* %23, i32 %1516
  %1518 = bitcast i8* %1517 to <32 x i8>*
  store <32 x i8> %1515, <32 x i8>* %1518, align 1, !tbaa !111
  %1519 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1520 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1521 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1520, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1522 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1519, <1 x i32> zeroinitializer, <32 x i32> %1521, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1523 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1524 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1525 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1524, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1526 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1523, <1 x i32> zeroinitializer, <32 x i32> %1525, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1527 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1522, <32 x i32> %1526, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1528 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1527, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1529 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1528, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1530 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1529, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1531 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1532 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1533 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1532, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1534 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1531, <1 x i32> zeroinitializer, <32 x i32> %1533, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1535 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1536 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1537 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1536, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1538 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1535, <1 x i32> zeroinitializer, <32 x i32> %1537, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1539 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1534, <32 x i32> %1538, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1540 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1539, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1541 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1540, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1542 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1541, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1543 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1530, <32 x i32> %1542, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1544 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1543, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1545 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1544, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1546 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1545, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1547 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1548 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1549 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1548, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1550 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1547, <1 x i32> zeroinitializer, <32 x i32> %1549, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1551 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1552 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1553 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1552, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1554 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1551, <1 x i32> zeroinitializer, <32 x i32> %1553, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1555 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1550, <32 x i32> %1554, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1556 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1555, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1557 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1556, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1558 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1557, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1559 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1560 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1561 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1413, <32 x i32> %1560, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1562 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1559, <1 x i32> zeroinitializer, <32 x i32> %1561, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1563 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1564 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1565 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1421, <32 x i32> %1564, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1566 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1563, <1 x i32> zeroinitializer, <32 x i32> %1565, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1567 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1562, <32 x i32> %1566, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1568 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1567, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1569 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1568, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1570 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1569, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1571 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1558, <32 x i32> %1570, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1572 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1571, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1573 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1572, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1574 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1573, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1575 = trunc <64 x i16> %1574 to <64 x i8>
  %1576 = bitcast <64 x i8> %1575 to <8 x i64>
  %1577 = shufflevector <8 x i64> %1576, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %1578 = bitcast <4 x i64> %1577 to <32 x i8>
  %1579 = shufflevector <32 x i8> %1578, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1580 = bitcast <128 x i8> %1579 to <32 x i32>
  %1581 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1580, <32 x i32> %1047) #11
  %1582 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1581, <32 x i32> %1050) #11
  %1583 = bitcast <32 x i32> %1582 to <128 x i8>
  %1584 = shufflevector <128 x i8> %1583, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1585 = getelementptr inbounds i8, i8* %1517, i32 32
  %1586 = bitcast i8* %1585 to <32 x i8>*
  store <32 x i8> %1584, <32 x i8>* %1586, align 1, !tbaa !111
  %1587 = sext <32 x i32> %sum_input187312.sroa.56.6.us.us to <32 x i64>
  %a192.us.us = mul nsw <32 x i64> %1587, %1035
  %1588 = icmp slt <32 x i64> %a192.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1589 = select <32 x i1> %1588, <32 x i64> %a192.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1590 = add nsw <32 x i64> %1589, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a191.us.us = ashr <32 x i64> %1590, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1591 = icmp slt <32 x i64> %a191.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a190.us.us = select <32 x i1> %1591, <32 x i64> %a191.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1592 = icmp sgt <32 x i64> %a190.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1593 = select <32 x i1> %1592, <32 x i64> %a190.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1594 = trunc <32 x i64> %1593 to <32 x i32>
  %1595 = sext <32 x i32> %sum_input187312.sroa.65.6.us.us to <32 x i64>
  %a196.us.us = mul nsw <32 x i64> %1595, %1035
  %1596 = icmp slt <32 x i64> %a196.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1597 = select <32 x i1> %1596, <32 x i64> %a196.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1598 = add nsw <32 x i64> %1597, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a195.us.us = ashr <32 x i64> %1598, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1599 = icmp slt <32 x i64> %a195.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a194.us.us = select <32 x i1> %1599, <32 x i64> %a195.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1600 = icmp sgt <32 x i64> %a194.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1601 = select <32 x i1> %1600, <32 x i64> %a194.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1602 = trunc <32 x i64> %1601 to <32 x i32>
  %1603 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1604 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1605 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1604, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1606 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1603, <1 x i32> zeroinitializer, <32 x i32> %1605, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1607 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1608 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1609 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1608, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1610 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1607, <1 x i32> zeroinitializer, <32 x i32> %1609, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1611 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1606, <32 x i32> %1610, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1612 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1611, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1613 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1612, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1614 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1613, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1615 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1616 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1617 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1616, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1618 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1615, <1 x i32> zeroinitializer, <32 x i32> %1617, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1619 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1620 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1621 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1620, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1622 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1619, <1 x i32> zeroinitializer, <32 x i32> %1621, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1623 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1618, <32 x i32> %1622, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1624 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1623, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1625 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1624, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1626 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1625, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1627 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1614, <32 x i32> %1626, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1628 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1627, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1629 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1628, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1630 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1629, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1631 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1632 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1633 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1632, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1634 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1631, <1 x i32> zeroinitializer, <32 x i32> %1633, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1635 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1636 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1637 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1636, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1638 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1635, <1 x i32> zeroinitializer, <32 x i32> %1637, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1639 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1634, <32 x i32> %1638, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1640 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1639, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1641 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1640, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1642 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1641, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1643 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1644 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1645 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1644, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1646 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1643, <1 x i32> zeroinitializer, <32 x i32> %1645, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1647 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1648 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1649 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1648, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1650 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1647, <1 x i32> zeroinitializer, <32 x i32> %1649, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1651 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1646, <32 x i32> %1650, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1652 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1651, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1653 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1652, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1654 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1653, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1655 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1642, <32 x i32> %1654, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1656 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1655, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1657 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1656, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1658 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1657, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1659 = trunc <64 x i16> %1658 to <64 x i8>
  %1660 = bitcast <64 x i8> %1659 to <8 x i64>
  %1661 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1662 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1663 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1662, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1664 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1661, <1 x i32> zeroinitializer, <32 x i32> %1663, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1665 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1666 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1667 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1666, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1668 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1665, <1 x i32> zeroinitializer, <32 x i32> %1667, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1669 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1664, <32 x i32> %1668, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1670 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1669, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1671 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1670, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1672 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1671, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1673 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1674 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1675 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1674, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1676 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1673, <1 x i32> zeroinitializer, <32 x i32> %1675, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1677 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1678 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1679 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1678, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1680 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1677, <1 x i32> zeroinitializer, <32 x i32> %1679, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1681 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1676, <32 x i32> %1680, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1682 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1681, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1683 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1682, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1684 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1683, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1685 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1672, <32 x i32> %1684, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1686 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1685, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1687 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1686, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1688 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1687, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1689 = shufflevector <8 x i64> %1660, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1690 = bitcast <4 x i64> %1689 to <32 x i8>
  %1691 = shufflevector <32 x i8> %1690, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1692 = bitcast <128 x i8> %1691 to <32 x i32>
  %1693 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1692, <32 x i32> %1047) #11
  %1694 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1693, <32 x i32> %1050) #11
  %1695 = bitcast <32 x i32> %1694 to <128 x i8>
  %1696 = shufflevector <128 x i8> %1695, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1697 = add i32 %1334, %2716
  %1698 = getelementptr inbounds i8, i8* %23, i32 %1697
  %1699 = bitcast i8* %1698 to <32 x i8>*
  store <32 x i8> %1696, <32 x i8>* %1699, align 1, !tbaa !111
  %1700 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1701 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1702 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1701, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1703 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1700, <1 x i32> zeroinitializer, <32 x i32> %1702, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1704 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1705 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1706 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1705, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1707 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1704, <1 x i32> zeroinitializer, <32 x i32> %1706, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1708 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1703, <32 x i32> %1707, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1709 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1708, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1710 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1709, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1711 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1710, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1712 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1713 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1714 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1713, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1715 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1712, <1 x i32> zeroinitializer, <32 x i32> %1714, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1716 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1717 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1718 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1717, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1719 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1716, <1 x i32> zeroinitializer, <32 x i32> %1718, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1720 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1715, <32 x i32> %1719, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1721 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1720, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1722 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1721, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1723 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1722, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1724 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1711, <32 x i32> %1723, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1725 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1724, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1726 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1725, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1727 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1726, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1728 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1729 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1730 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1729, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1731 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1728, <1 x i32> zeroinitializer, <32 x i32> %1730, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1732 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1733 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1734 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1733, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1735 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1732, <1 x i32> zeroinitializer, <32 x i32> %1734, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1736 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1731, <32 x i32> %1735, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1737 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1736, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1738 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1737, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1739 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1738, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1740 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1741 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1742 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1594, <32 x i32> %1741, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1743 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1740, <1 x i32> zeroinitializer, <32 x i32> %1742, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1744 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1745 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1746 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1602, <32 x i32> %1745, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1747 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1744, <1 x i32> zeroinitializer, <32 x i32> %1746, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1748 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1743, <32 x i32> %1747, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1749 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1748, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1750 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1749, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1751 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1750, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1752 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1739, <32 x i32> %1751, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1753 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1752, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1754 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1753, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1755 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1754, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1756 = trunc <64 x i16> %1755 to <64 x i8>
  %1757 = bitcast <64 x i8> %1756 to <8 x i64>
  %1758 = shufflevector <8 x i64> %1757, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %1759 = bitcast <4 x i64> %1758 to <32 x i8>
  %1760 = shufflevector <32 x i8> %1759, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1761 = bitcast <128 x i8> %1760 to <32 x i32>
  %1762 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1761, <32 x i32> %1047) #11
  %1763 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1762, <32 x i32> %1050) #11
  %1764 = bitcast <32 x i32> %1763 to <128 x i8>
  %1765 = shufflevector <128 x i8> %1764, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1766 = getelementptr inbounds i8, i8* %1698, i32 32
  %1767 = bitcast i8* %1766 to <32 x i8>*
  store <32 x i8> %1765, <32 x i8>* %1767, align 1, !tbaa !111
  %1768 = sext <32 x i32> %sum_input187312.sroa.74.6.us.us to <32 x i64>
  %a232.us.us = mul nsw <32 x i64> %1768, %1035
  %1769 = icmp slt <32 x i64> %a232.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1770 = select <32 x i1> %1769, <32 x i64> %a232.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1771 = add nsw <32 x i64> %1770, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a231.us.us = ashr <32 x i64> %1771, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1772 = icmp slt <32 x i64> %a231.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a230.us.us = select <32 x i1> %1772, <32 x i64> %a231.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1773 = icmp sgt <32 x i64> %a230.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1774 = select <32 x i1> %1773, <32 x i64> %a230.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1775 = trunc <32 x i64> %1774 to <32 x i32>
  %1776 = sext <32 x i32> %sum_input187312.sroa.83.6.us.us to <32 x i64>
  %a236.us.us = mul nsw <32 x i64> %1776, %1035
  %1777 = icmp slt <32 x i64> %a236.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1778 = select <32 x i1> %1777, <32 x i64> %a236.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1779 = add nsw <32 x i64> %1778, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a235.us.us = ashr <32 x i64> %1779, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1780 = icmp slt <32 x i64> %a235.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a234.us.us = select <32 x i1> %1780, <32 x i64> %a235.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1781 = icmp sgt <32 x i64> %a234.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1782 = select <32 x i1> %1781, <32 x i64> %a234.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1783 = trunc <32 x i64> %1782 to <32 x i32>
  %1784 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1785 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1786 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1785, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1787 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1784, <1 x i32> zeroinitializer, <32 x i32> %1786, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1788 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1789 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1790 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1789, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1791 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1788, <1 x i32> zeroinitializer, <32 x i32> %1790, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1792 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1787, <32 x i32> %1791, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1793 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1792, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1794 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1793, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1795 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1794, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1796 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1797 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1798 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1797, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1799 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1796, <1 x i32> zeroinitializer, <32 x i32> %1798, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1800 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1801 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1802 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1801, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1803 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1800, <1 x i32> zeroinitializer, <32 x i32> %1802, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1804 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1799, <32 x i32> %1803, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1805 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1804, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1806 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1805, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1807 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1806, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1808 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1795, <32 x i32> %1807, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1809 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1808, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1810 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1809, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1811 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1810, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1812 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1813 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1814 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1813, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1815 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1812, <1 x i32> zeroinitializer, <32 x i32> %1814, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1816 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1817 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1818 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1817, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1819 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1816, <1 x i32> zeroinitializer, <32 x i32> %1818, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1820 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1815, <32 x i32> %1819, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1821 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1820, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1822 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1821, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1823 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1822, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1824 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1825 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1826 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1825, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1827 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1824, <1 x i32> zeroinitializer, <32 x i32> %1826, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1828 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1829 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1830 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1829, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1831 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1828, <1 x i32> zeroinitializer, <32 x i32> %1830, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1832 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1827, <32 x i32> %1831, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1833 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1832, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1834 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1833, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1835 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1834, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1836 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1823, <32 x i32> %1835, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1837 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1836, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1838 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1837, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1839 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1838, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1840 = trunc <64 x i16> %1839 to <64 x i8>
  %1841 = bitcast <64 x i8> %1840 to <8 x i64>
  %1842 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1843 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1844 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1843, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1845 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1842, <1 x i32> zeroinitializer, <32 x i32> %1844, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1846 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1847 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1848 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1847, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1849 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1846, <1 x i32> zeroinitializer, <32 x i32> %1848, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1850 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1845, <32 x i32> %1849, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1851 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1850, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1852 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1851, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1853 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1852, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1854 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1855 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1856 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1855, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1857 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1854, <1 x i32> zeroinitializer, <32 x i32> %1856, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1858 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1859 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1860 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1859, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1861 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1858, <1 x i32> zeroinitializer, <32 x i32> %1860, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1862 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1857, <32 x i32> %1861, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1863 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1862, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1864 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1863, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1865 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1864, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1866 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1853, <32 x i32> %1865, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1867 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1866, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1868 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1867, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1869 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1868, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1870 = shufflevector <8 x i64> %1841, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1871 = bitcast <4 x i64> %1870 to <32 x i8>
  %1872 = shufflevector <32 x i8> %1871, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1873 = bitcast <128 x i8> %1872 to <32 x i32>
  %1874 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1873, <32 x i32> %1047) #11
  %1875 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1874, <32 x i32> %1050) #11
  %1876 = bitcast <32 x i32> %1875 to <128 x i8>
  %1877 = shufflevector <128 x i8> %1876, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1878 = add i32 %1334, %2717
  %1879 = getelementptr inbounds i8, i8* %23, i32 %1878
  %1880 = bitcast i8* %1879 to <32 x i8>*
  store <32 x i8> %1877, <32 x i8>* %1880, align 1, !tbaa !111
  %1881 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1882 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1883 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1882, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1884 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1881, <1 x i32> zeroinitializer, <32 x i32> %1883, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1885 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1886 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1887 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1886, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1888 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1885, <1 x i32> zeroinitializer, <32 x i32> %1887, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1889 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1884, <32 x i32> %1888, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1890 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1889, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1891 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1890, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1892 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1891, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1893 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1894 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1895 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1894, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1896 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1893, <1 x i32> zeroinitializer, <32 x i32> %1895, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1897 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1898 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1899 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1898, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1900 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1897, <1 x i32> zeroinitializer, <32 x i32> %1899, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1901 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1896, <32 x i32> %1900, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1902 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1901, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1903 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1902, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1904 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1903, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1905 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1892, <32 x i32> %1904, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1906 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1905, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1907 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1906, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1908 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1907, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1909 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1910 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1911 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1910, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1912 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1909, <1 x i32> zeroinitializer, <32 x i32> %1911, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1913 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1914 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1915 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1914, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1916 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1913, <1 x i32> zeroinitializer, <32 x i32> %1915, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1917 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1912, <32 x i32> %1916, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1918 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1917, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1919 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1918, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1920 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1919, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1921 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1922 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1923 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1775, <32 x i32> %1922, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1924 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1921, <1 x i32> zeroinitializer, <32 x i32> %1923, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1925 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1926 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1927 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1783, <32 x i32> %1926, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1928 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1925, <1 x i32> zeroinitializer, <32 x i32> %1927, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1929 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1924, <32 x i32> %1928, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1930 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1929, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1931 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1930, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1932 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1931, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1933 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1920, <32 x i32> %1932, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1934 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1933, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1935 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1934, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1936 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1935, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1937 = trunc <64 x i16> %1936 to <64 x i8>
  %1938 = bitcast <64 x i8> %1937 to <8 x i64>
  %1939 = shufflevector <8 x i64> %1938, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %1940 = bitcast <4 x i64> %1939 to <32 x i8>
  %1941 = shufflevector <32 x i8> %1940, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1942 = bitcast <128 x i8> %1941 to <32 x i32>
  %1943 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %1942, <32 x i32> %1047) #11
  %1944 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %1943, <32 x i32> %1050) #11
  %1945 = bitcast <32 x i32> %1944 to <128 x i8>
  %1946 = shufflevector <128 x i8> %1945, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %1947 = getelementptr inbounds i8, i8* %1879, i32 32
  %1948 = bitcast i8* %1947 to <32 x i8>*
  store <32 x i8> %1946, <32 x i8>* %1948, align 1, !tbaa !111
  %1949 = sext <32 x i32> %sum_input187312.sroa.92.6.us.us to <32 x i64>
  %a272.us.us = mul nsw <32 x i64> %1949, %1035
  %1950 = icmp slt <32 x i64> %a272.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1951 = select <32 x i1> %1950, <32 x i64> %a272.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1952 = add nsw <32 x i64> %1951, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a271.us.us = ashr <32 x i64> %1952, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1953 = icmp slt <32 x i64> %a271.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a270.us.us = select <32 x i1> %1953, <32 x i64> %a271.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1954 = icmp sgt <32 x i64> %a270.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1955 = select <32 x i1> %1954, <32 x i64> %a270.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1956 = trunc <32 x i64> %1955 to <32 x i32>
  %1957 = sext <32 x i32> %sum_input187312.sroa.101.6.us.us to <32 x i64>
  %a276.us.us = mul nsw <32 x i64> %1957, %1035
  %1958 = icmp slt <32 x i64> %a276.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1959 = select <32 x i1> %1958, <32 x i64> %a276.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %1960 = add nsw <32 x i64> %1959, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a275.us.us = ashr <32 x i64> %1960, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %1961 = icmp slt <32 x i64> %a275.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a274.us.us = select <32 x i1> %1961, <32 x i64> %a275.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %1962 = icmp sgt <32 x i64> %a274.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1963 = select <32 x i1> %1962, <32 x i64> %a274.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %1964 = trunc <32 x i64> %1963 to <32 x i32>
  %1965 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1966 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1967 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %1966, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1968 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1965, <1 x i32> zeroinitializer, <32 x i32> %1967, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1969 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1970 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1971 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %1970, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1972 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1969, <1 x i32> zeroinitializer, <32 x i32> %1971, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1973 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1968, <32 x i32> %1972, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1974 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %1973, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1975 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %1974, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1976 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1975, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1977 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1978 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1979 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %1978, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1980 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1977, <1 x i32> zeroinitializer, <32 x i32> %1979, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1981 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1982 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1983 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %1982, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1984 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1981, <1 x i32> zeroinitializer, <32 x i32> %1983, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1985 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1980, <32 x i32> %1984, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %1986 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %1985, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %1987 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %1986, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1988 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %1987, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1989 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %1976, <32 x i32> %1988, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %1990 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %1989, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1991 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %1990, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1992 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %1991, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %1993 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1994 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1995 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %1994, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1996 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1993, <1 x i32> zeroinitializer, <32 x i32> %1995, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %1997 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1998 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %1999 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %1998, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2000 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %1997, <1 x i32> zeroinitializer, <32 x i32> %1999, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2001 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %1996, <32 x i32> %2000, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2002 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2001, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2003 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2002, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2004 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2003, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2005 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2006 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2007 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2006, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2008 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2005, <1 x i32> zeroinitializer, <32 x i32> %2007, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2009 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2010 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2011 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2010, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2012 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2009, <1 x i32> zeroinitializer, <32 x i32> %2011, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2013 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2008, <32 x i32> %2012, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2014 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2013, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2015 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2014, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2016 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2015, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2017 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2004, <32 x i32> %2016, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2018 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2017, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2019 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2018, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2020 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2019, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2021 = trunc <64 x i16> %2020 to <64 x i8>
  %2022 = bitcast <64 x i8> %2021 to <8 x i64>
  %2023 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2024 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2025 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2024, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2026 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2023, <1 x i32> zeroinitializer, <32 x i32> %2025, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2027 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2028 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2029 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2028, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2030 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2027, <1 x i32> zeroinitializer, <32 x i32> %2029, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2031 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2026, <32 x i32> %2030, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2032 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2031, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2033 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2032, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2034 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2033, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2035 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2036 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2037 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2036, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2038 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2035, <1 x i32> zeroinitializer, <32 x i32> %2037, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2039 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2040 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2041 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2040, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2042 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2039, <1 x i32> zeroinitializer, <32 x i32> %2041, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2043 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2038, <32 x i32> %2042, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2044 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2043, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2045 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2046 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2045, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2047 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2034, <32 x i32> %2046, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2048 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2047, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2049 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2048, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2050 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2049, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2051 = shufflevector <8 x i64> %2022, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2052 = bitcast <4 x i64> %2051 to <32 x i8>
  %2053 = shufflevector <32 x i8> %2052, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2054 = bitcast <128 x i8> %2053 to <32 x i32>
  %2055 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2054, <32 x i32> %1047) #11
  %2056 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2055, <32 x i32> %1050) #11
  %2057 = bitcast <32 x i32> %2056 to <128 x i8>
  %2058 = shufflevector <128 x i8> %2057, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2059 = add i32 %1334, %2718
  %2060 = getelementptr inbounds i8, i8* %23, i32 %2059
  %2061 = bitcast i8* %2060 to <32 x i8>*
  store <32 x i8> %2058, <32 x i8>* %2061, align 1, !tbaa !111
  %2062 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2063 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2064 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2063, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2065 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2062, <1 x i32> zeroinitializer, <32 x i32> %2064, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2066 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2067 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2068 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2067, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2069 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2066, <1 x i32> zeroinitializer, <32 x i32> %2068, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2070 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2065, <32 x i32> %2069, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2071 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2070, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2072 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2071, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2073 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2072, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2074 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2075 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2076 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2075, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2077 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2074, <1 x i32> zeroinitializer, <32 x i32> %2076, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2078 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2079 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2080 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2079, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2081 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2078, <1 x i32> zeroinitializer, <32 x i32> %2080, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2082 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2077, <32 x i32> %2081, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2083 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2082, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2084 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2083, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2085 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2084, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2086 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2073, <32 x i32> %2085, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2087 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2086, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2088 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2087, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2089 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2088, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2090 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2091 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2092 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2091, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2093 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2090, <1 x i32> zeroinitializer, <32 x i32> %2092, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2094 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2095 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2096 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2095, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2097 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2094, <1 x i32> zeroinitializer, <32 x i32> %2096, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2098 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2093, <32 x i32> %2097, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2099 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2098, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2100 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2099, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2101 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2102 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2103 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2104 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1956, <32 x i32> %2103, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2105 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2102, <1 x i32> zeroinitializer, <32 x i32> %2104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2106 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2107 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2108 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %1964, <32 x i32> %2107, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2109 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2106, <1 x i32> zeroinitializer, <32 x i32> %2108, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2110 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2105, <32 x i32> %2109, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2111 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2112 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2111, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2113 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2112, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2114 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2101, <32 x i32> %2113, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2115 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2114, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2116 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2115, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2117 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2116, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2118 = trunc <64 x i16> %2117 to <64 x i8>
  %2119 = bitcast <64 x i8> %2118 to <8 x i64>
  %2120 = shufflevector <8 x i64> %2119, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %2121 = bitcast <4 x i64> %2120 to <32 x i8>
  %2122 = shufflevector <32 x i8> %2121, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2123 = bitcast <128 x i8> %2122 to <32 x i32>
  %2124 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2123, <32 x i32> %1047) #11
  %2125 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2124, <32 x i32> %1050) #11
  %2126 = bitcast <32 x i32> %2125 to <128 x i8>
  %2127 = shufflevector <128 x i8> %2126, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2128 = getelementptr inbounds i8, i8* %2060, i32 32
  %2129 = bitcast i8* %2128 to <32 x i8>*
  store <32 x i8> %2127, <32 x i8>* %2129, align 1, !tbaa !111
  %2130 = sext <32 x i32> %sum_input187312.sroa.110.6.us.us to <32 x i64>
  %a312.us.us = mul nsw <32 x i64> %2130, %1035
  %2131 = icmp slt <32 x i64> %a312.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2132 = select <32 x i1> %2131, <32 x i64> %a312.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2133 = add nsw <32 x i64> %2132, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a311.us.us = ashr <32 x i64> %2133, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2134 = icmp slt <32 x i64> %a311.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a310.us.us = select <32 x i1> %2134, <32 x i64> %a311.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2135 = icmp sgt <32 x i64> %a310.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2136 = select <32 x i1> %2135, <32 x i64> %a310.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2137 = trunc <32 x i64> %2136 to <32 x i32>
  %2138 = sext <32 x i32> %sum_input187312.sroa.119.6.us.us to <32 x i64>
  %a316.us.us = mul nsw <32 x i64> %2138, %1035
  %2139 = icmp slt <32 x i64> %a316.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2140 = select <32 x i1> %2139, <32 x i64> %a316.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2141 = add nsw <32 x i64> %2140, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a315.us.us = ashr <32 x i64> %2141, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2142 = icmp slt <32 x i64> %a315.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a314.us.us = select <32 x i1> %2142, <32 x i64> %a315.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2143 = icmp sgt <32 x i64> %a314.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2144 = select <32 x i1> %2143, <32 x i64> %a314.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2145 = trunc <32 x i64> %2144 to <32 x i32>
  %2146 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2147 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2148 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2147, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2149 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2146, <1 x i32> zeroinitializer, <32 x i32> %2148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2150 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2151 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2152 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2151, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2153 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2150, <1 x i32> zeroinitializer, <32 x i32> %2152, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2154 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2149, <32 x i32> %2153, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2155 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2154, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2156 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2155, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2157 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2156, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2158 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2159 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2160 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2159, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2161 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2158, <1 x i32> zeroinitializer, <32 x i32> %2160, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2162 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2163 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2164 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2165 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2162, <1 x i32> zeroinitializer, <32 x i32> %2164, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2166 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2161, <32 x i32> %2165, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2167 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2166, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2168 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2169 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2170 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2157, <32 x i32> %2169, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2171 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2170, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2172 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2171, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2173 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2172, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2174 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2175 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2176 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2175, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2177 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2174, <1 x i32> zeroinitializer, <32 x i32> %2176, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2178 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2179 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2180 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2181 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2178, <1 x i32> zeroinitializer, <32 x i32> %2180, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2182 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2177, <32 x i32> %2181, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2183 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2182, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2184 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2183, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2185 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2186 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2187 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2188 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2187, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2189 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2186, <1 x i32> zeroinitializer, <32 x i32> %2188, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2190 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2191 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2192 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2193 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2190, <1 x i32> zeroinitializer, <32 x i32> %2192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2194 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2189, <32 x i32> %2193, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2195 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2194, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2196 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2197 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2198 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2185, <32 x i32> %2197, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2199 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2198, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2200 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2199, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2201 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2200, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2202 = trunc <64 x i16> %2201 to <64 x i8>
  %2203 = bitcast <64 x i8> %2202 to <8 x i64>
  %2204 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2205 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2206 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2207 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2204, <1 x i32> zeroinitializer, <32 x i32> %2206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2208 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2209 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2210 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2209, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2211 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2208, <1 x i32> zeroinitializer, <32 x i32> %2210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2212 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2207, <32 x i32> %2211, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2213 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2212, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2214 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2213, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2215 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2214, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2216 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2217 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2218 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2217, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2219 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2216, <1 x i32> zeroinitializer, <32 x i32> %2218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2220 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2221 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2222 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2221, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2223 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2220, <1 x i32> zeroinitializer, <32 x i32> %2222, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2224 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2219, <32 x i32> %2223, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2225 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2224, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2226 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2227 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2226, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2228 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2215, <32 x i32> %2227, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2229 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2228, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2230 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2229, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2231 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2230, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2232 = shufflevector <8 x i64> %2203, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2233 = bitcast <4 x i64> %2232 to <32 x i8>
  %2234 = shufflevector <32 x i8> %2233, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2235 = bitcast <128 x i8> %2234 to <32 x i32>
  %2236 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2235, <32 x i32> %1047) #11
  %2237 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2236, <32 x i32> %1050) #11
  %2238 = bitcast <32 x i32> %2237 to <128 x i8>
  %2239 = shufflevector <128 x i8> %2238, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2240 = add i32 %1334, %2719
  %2241 = getelementptr inbounds i8, i8* %23, i32 %2240
  %2242 = bitcast i8* %2241 to <32 x i8>*
  store <32 x i8> %2239, <32 x i8>* %2242, align 1, !tbaa !111
  %2243 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2244 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2245 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2244, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2246 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2243, <1 x i32> zeroinitializer, <32 x i32> %2245, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2247 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2248 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2249 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2250 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2247, <1 x i32> zeroinitializer, <32 x i32> %2249, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2251 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2246, <32 x i32> %2250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2252 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2251, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2253 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2252, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2254 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2253, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2255 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2256 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2257 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2258 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2255, <1 x i32> zeroinitializer, <32 x i32> %2257, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2259 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2260 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2261 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2262 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2259, <1 x i32> zeroinitializer, <32 x i32> %2261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2263 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2258, <32 x i32> %2262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2264 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2265 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2266 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2265, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2267 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2254, <32 x i32> %2266, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2268 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2267, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2269 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2268, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2270 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2269, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2271 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2272 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2273 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2272, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2274 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2271, <1 x i32> zeroinitializer, <32 x i32> %2273, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2275 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2276 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2277 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2278 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2275, <1 x i32> zeroinitializer, <32 x i32> %2277, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2279 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2274, <32 x i32> %2278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2280 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2279, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2281 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2280, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2282 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2281, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2283 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2284 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2285 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2137, <32 x i32> %2284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2286 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2283, <1 x i32> zeroinitializer, <32 x i32> %2285, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2287 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2288 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2289 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2145, <32 x i32> %2288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2290 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2287, <1 x i32> zeroinitializer, <32 x i32> %2289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2291 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2286, <32 x i32> %2290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2292 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2293 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2294 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2293, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2295 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2282, <32 x i32> %2294, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2296 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2295, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2297 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2296, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2298 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2297, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2299 = trunc <64 x i16> %2298 to <64 x i8>
  %2300 = bitcast <64 x i8> %2299 to <8 x i64>
  %2301 = shufflevector <8 x i64> %2300, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %2302 = bitcast <4 x i64> %2301 to <32 x i8>
  %2303 = shufflevector <32 x i8> %2302, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2304 = bitcast <128 x i8> %2303 to <32 x i32>
  %2305 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2304, <32 x i32> %1047) #11
  %2306 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2305, <32 x i32> %1050) #11
  %2307 = bitcast <32 x i32> %2306 to <128 x i8>
  %2308 = shufflevector <128 x i8> %2307, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2309 = getelementptr inbounds i8, i8* %2241, i32 32
  %2310 = bitcast i8* %2309 to <32 x i8>*
  store <32 x i8> %2308, <32 x i8>* %2310, align 1, !tbaa !111
  %2311 = sext <32 x i32> %sum_input187312.sroa.128.6.us.us to <32 x i64>
  %a352.us.us = mul nsw <32 x i64> %2311, %1035
  %2312 = icmp slt <32 x i64> %a352.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2313 = select <32 x i1> %2312, <32 x i64> %a352.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2314 = add nsw <32 x i64> %2313, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a351.us.us = ashr <32 x i64> %2314, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2315 = icmp slt <32 x i64> %a351.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a350.us.us = select <32 x i1> %2315, <32 x i64> %a351.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2316 = icmp sgt <32 x i64> %a350.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2317 = select <32 x i1> %2316, <32 x i64> %a350.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2318 = trunc <32 x i64> %2317 to <32 x i32>
  %2319 = sext <32 x i32> %sum_input187312.sroa.137.6.us.us to <32 x i64>
  %a356.us.us = mul nsw <32 x i64> %2319, %1035
  %2320 = icmp slt <32 x i64> %a356.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2321 = select <32 x i1> %2320, <32 x i64> %a356.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2322 = add nsw <32 x i64> %2321, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a355.us.us = ashr <32 x i64> %2322, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2323 = icmp slt <32 x i64> %a355.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a354.us.us = select <32 x i1> %2323, <32 x i64> %a355.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2324 = icmp sgt <32 x i64> %a354.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2325 = select <32 x i1> %2324, <32 x i64> %a354.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2326 = trunc <32 x i64> %2325 to <32 x i32>
  %2327 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2328 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2329 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2330 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2327, <1 x i32> zeroinitializer, <32 x i32> %2329, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2331 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2332 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2333 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2334 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2331, <1 x i32> zeroinitializer, <32 x i32> %2333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2335 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2330, <32 x i32> %2334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2336 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2337 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2336, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2338 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2337, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2339 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2340 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2341 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2342 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2339, <1 x i32> zeroinitializer, <32 x i32> %2341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2343 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2344 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2345 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2346 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2343, <1 x i32> zeroinitializer, <32 x i32> %2345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2347 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2342, <32 x i32> %2346, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2348 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2349 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2348, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2350 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2351 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2338, <32 x i32> %2350, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2352 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2351, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2353 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2352, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2354 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2353, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2355 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2356 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2357 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2356, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2358 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2355, <1 x i32> zeroinitializer, <32 x i32> %2357, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2359 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2360 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2361 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2362 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2359, <1 x i32> zeroinitializer, <32 x i32> %2361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2363 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2358, <32 x i32> %2362, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2364 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2363, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2365 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2364, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2366 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2367 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2368 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2369 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2368, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2370 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2367, <1 x i32> zeroinitializer, <32 x i32> %2369, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2371 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2372 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2373 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2372, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2374 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2371, <1 x i32> zeroinitializer, <32 x i32> %2373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2375 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2370, <32 x i32> %2374, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2376 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2375, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2377 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2376, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2378 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2377, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2379 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2366, <32 x i32> %2378, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2380 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2379, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2381 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2380, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2382 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2381, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2383 = trunc <64 x i16> %2382 to <64 x i8>
  %2384 = bitcast <64 x i8> %2383 to <8 x i64>
  %2385 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2386 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2387 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2386, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2388 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2385, <1 x i32> zeroinitializer, <32 x i32> %2387, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2389 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2390 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2391 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2392 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2389, <1 x i32> zeroinitializer, <32 x i32> %2391, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2393 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2388, <32 x i32> %2392, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2394 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2393, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2395 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2394, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2396 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2397 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2398 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2399 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2398, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2400 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2397, <1 x i32> zeroinitializer, <32 x i32> %2399, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2401 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2402 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2403 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2404 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2401, <1 x i32> zeroinitializer, <32 x i32> %2403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2405 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2400, <32 x i32> %2404, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2406 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2405, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2407 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2408 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2409 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2396, <32 x i32> %2408, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2410 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2409, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2411 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2410, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2412 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2411, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2413 = shufflevector <8 x i64> %2384, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2414 = bitcast <4 x i64> %2413 to <32 x i8>
  %2415 = shufflevector <32 x i8> %2414, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2416 = bitcast <128 x i8> %2415 to <32 x i32>
  %2417 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2416, <32 x i32> %1047) #11
  %2418 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2417, <32 x i32> %1050) #11
  %2419 = bitcast <32 x i32> %2418 to <128 x i8>
  %2420 = shufflevector <128 x i8> %2419, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2421 = add i32 %1334, %2720
  %2422 = getelementptr inbounds i8, i8* %23, i32 %2421
  %2423 = bitcast i8* %2422 to <32 x i8>*
  store <32 x i8> %2420, <32 x i8>* %2423, align 1, !tbaa !111
  %2424 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2425 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2426 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2425, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2427 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2424, <1 x i32> zeroinitializer, <32 x i32> %2426, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2428 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2429 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2430 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2429, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2431 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2428, <1 x i32> zeroinitializer, <32 x i32> %2430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2432 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2427, <32 x i32> %2431, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2433 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2432, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2434 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2433, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2435 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2434, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2436 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2437 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2438 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2439 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2436, <1 x i32> zeroinitializer, <32 x i32> %2438, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2440 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2441 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2442 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2441, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2443 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2440, <1 x i32> zeroinitializer, <32 x i32> %2442, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2444 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2439, <32 x i32> %2443, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2445 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2444, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2446 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2447 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2448 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2435, <32 x i32> %2447, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2449 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2448, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2450 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2449, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2451 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2450, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2452 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2453 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2454 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2453, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2455 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2452, <1 x i32> zeroinitializer, <32 x i32> %2454, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2456 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2457 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2458 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2457, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2459 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2456, <1 x i32> zeroinitializer, <32 x i32> %2458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2460 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2455, <32 x i32> %2459, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2461 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2460, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2462 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2461, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2463 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2462, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2464 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2465 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2466 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2318, <32 x i32> %2465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2467 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2464, <1 x i32> zeroinitializer, <32 x i32> %2466, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2468 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2469 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2470 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2326, <32 x i32> %2469, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2471 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2468, <1 x i32> zeroinitializer, <32 x i32> %2470, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2472 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2467, <32 x i32> %2471, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2473 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2474 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2473, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2475 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2474, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2476 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2463, <32 x i32> %2475, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2477 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2476, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2478 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2477, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2479 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2478, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2480 = trunc <64 x i16> %2479 to <64 x i8>
  %2481 = bitcast <64 x i8> %2480 to <8 x i64>
  %2482 = shufflevector <8 x i64> %2481, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %2483 = bitcast <4 x i64> %2482 to <32 x i8>
  %2484 = shufflevector <32 x i8> %2483, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2485 = bitcast <128 x i8> %2484 to <32 x i32>
  %2486 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2485, <32 x i32> %1047) #11
  %2487 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2486, <32 x i32> %1050) #11
  %2488 = bitcast <32 x i32> %2487 to <128 x i8>
  %2489 = shufflevector <128 x i8> %2488, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2490 = getelementptr inbounds i8, i8* %2422, i32 32
  %2491 = bitcast i8* %2490 to <32 x i8>*
  store <32 x i8> %2489, <32 x i8>* %2491, align 1, !tbaa !111
  %2492 = sext <32 x i32> %sum_input187312.sroa.146.6.us.us to <32 x i64>
  %a392.us.us = mul nsw <32 x i64> %2492, %1035
  %2493 = icmp slt <32 x i64> %a392.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2494 = select <32 x i1> %2493, <32 x i64> %a392.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2495 = add nsw <32 x i64> %2494, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a391.us.us = ashr <32 x i64> %2495, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2496 = icmp slt <32 x i64> %a391.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a390.us.us = select <32 x i1> %2496, <32 x i64> %a391.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2497 = icmp sgt <32 x i64> %a390.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2498 = select <32 x i1> %2497, <32 x i64> %a390.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2499 = trunc <32 x i64> %2498 to <32 x i32>
  %2500 = sext <32 x i32> %sum_input187312.sroa.155.6.us.us to <32 x i64>
  %a396.us.us = mul nsw <32 x i64> %2500, %1035
  %2501 = icmp slt <32 x i64> %a396.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2502 = select <32 x i1> %2501, <32 x i64> %a396.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %2503 = add nsw <32 x i64> %2502, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a395.us.us = ashr <32 x i64> %2503, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %2504 = icmp slt <32 x i64> %a395.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a394.us.us = select <32 x i1> %2504, <32 x i64> %a395.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %2505 = icmp sgt <32 x i64> %a394.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2506 = select <32 x i1> %2505, <32 x i64> %a394.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %2507 = trunc <32 x i64> %2506 to <32 x i32>
  %2508 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2509 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2510 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2509, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2511 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2508, <1 x i32> zeroinitializer, <32 x i32> %2510, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2512 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2513 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2514 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2513, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2515 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2512, <1 x i32> zeroinitializer, <32 x i32> %2514, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2516 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2511, <32 x i32> %2515, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2517 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2516, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2518 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2517, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2519 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2518, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2520 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2521 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2522 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2521, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2523 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2520, <1 x i32> zeroinitializer, <32 x i32> %2522, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2524 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2525 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2526 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2525, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2527 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2524, <1 x i32> zeroinitializer, <32 x i32> %2526, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2528 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2523, <32 x i32> %2527, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2529 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2528, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2530 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2529, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2531 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2530, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2532 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2519, <32 x i32> %2531, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2533 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2532, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2534 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2533, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2535 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2534, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2536 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2537 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2538 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2537, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2539 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2536, <1 x i32> zeroinitializer, <32 x i32> %2538, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2540 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2541 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2542 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2541, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2543 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2540, <1 x i32> zeroinitializer, <32 x i32> %2542, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2544 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2539, <32 x i32> %2543, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2545 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2544, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2546 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2545, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2547 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2546, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2548 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2549 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2550 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2549, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2551 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2548, <1 x i32> zeroinitializer, <32 x i32> %2550, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2552 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2553 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2554 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2553, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2555 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2552, <1 x i32> zeroinitializer, <32 x i32> %2554, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2556 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2551, <32 x i32> %2555, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2557 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2556, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2558 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2557, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2559 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2558, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2560 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2547, <32 x i32> %2559, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2561 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2560, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2562 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2561, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2563 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2562, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2564 = trunc <64 x i16> %2563 to <64 x i8>
  %2565 = bitcast <64 x i8> %2564 to <8 x i64>
  %2566 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2567 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2568 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2567, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2569 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2566, <1 x i32> zeroinitializer, <32 x i32> %2568, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2570 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2571 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2572 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2571, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2573 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2570, <1 x i32> zeroinitializer, <32 x i32> %2572, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2574 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2569, <32 x i32> %2573, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2575 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2574, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2576 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2575, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2577 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2576, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2578 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2579 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2580 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2579, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2581 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2578, <1 x i32> zeroinitializer, <32 x i32> %2580, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2582 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2583 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2584 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2583, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2585 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2582, <1 x i32> zeroinitializer, <32 x i32> %2584, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2586 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2581, <32 x i32> %2585, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2587 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2586, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2588 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2587, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2589 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2588, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2590 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2577, <32 x i32> %2589, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2591 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2590, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2592 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2591, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2593 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2592, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2594 = shufflevector <8 x i64> %2565, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2595 = bitcast <4 x i64> %2594 to <32 x i8>
  %2596 = shufflevector <32 x i8> %2595, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2597 = bitcast <128 x i8> %2596 to <32 x i32>
  %2598 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2597, <32 x i32> %1047) #11
  %2599 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2598, <32 x i32> %1050) #11
  %2600 = bitcast <32 x i32> %2599 to <128 x i8>
  %2601 = shufflevector <128 x i8> %2600, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2602 = add i32 %1334, %2721
  %2603 = getelementptr inbounds i8, i8* %23, i32 %2602
  %2604 = bitcast i8* %2603 to <32 x i8>*
  store <32 x i8> %2601, <32 x i8>* %2604, align 1, !tbaa !111
  %2605 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2606 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2607 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2606, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2608 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2605, <1 x i32> zeroinitializer, <32 x i32> %2607, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2609 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2610 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2611 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2610, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2612 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2609, <1 x i32> zeroinitializer, <32 x i32> %2611, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2613 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2608, <32 x i32> %2612, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2614 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2613, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2615 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2614, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2616 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2615, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2617 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2618 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2619 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2618, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2620 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2617, <1 x i32> zeroinitializer, <32 x i32> %2619, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2621 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2622 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2623 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2622, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2624 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2621, <1 x i32> zeroinitializer, <32 x i32> %2623, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2625 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2620, <32 x i32> %2624, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2626 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2625, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2627 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2626, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2628 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2627, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2629 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2616, <32 x i32> %2628, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2630 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2629, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2631 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2630, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2632 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2631, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2633 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2634 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2635 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2634, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2636 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2633, <1 x i32> zeroinitializer, <32 x i32> %2635, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2637 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2638 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2639 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2638, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2640 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2637, <1 x i32> zeroinitializer, <32 x i32> %2639, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2641 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2636, <32 x i32> %2640, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2642 = call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %2641, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2643 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %2642, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2644 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2643, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2645 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2646 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2647 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2499, <32 x i32> %2646, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2648 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2645, <1 x i32> zeroinitializer, <32 x i32> %2647, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2649 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1044, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2650 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %1043, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2651 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %2507, <32 x i32> %2650, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2652 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %2649, <1 x i32> zeroinitializer, <32 x i32> %2651, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2653 = call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %2648, <32 x i32> %2652, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0) #11
  %2654 = call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %2653, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0) #11
  %2655 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %2654, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2656 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %2655, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %2657 = call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %2644, <32 x i32> %2656, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0) #11
  %2658 = call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %1042, <64 x i16> %2657, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2659 = call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %2658, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2660 = call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %2659, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0) #11
  %2661 = trunc <64 x i16> %2660 to <64 x i8>
  %2662 = bitcast <64 x i8> %2661 to <8 x i64>
  %2663 = shufflevector <8 x i64> %2662, <8 x i64> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %2664 = bitcast <4 x i64> %2663 to <32 x i8>
  %2665 = shufflevector <32 x i8> %2664, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2666 = bitcast <128 x i8> %2665 to <32 x i32>
  %2667 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %2666, <32 x i32> %1047) #11
  %2668 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %2667, <32 x i32> %1050) #11
  %2669 = bitcast <32 x i32> %2668 to <128 x i8>
  %2670 = shufflevector <128 x i8> %2669, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %2671 = getelementptr inbounds i8, i8* %2603, i32 32
  %2672 = bitcast i8* %2671 to <32 x i8>*
  store <32 x i8> %2670, <32 x i8>* %2672, align 1, !tbaa !111
  %2673 = add nuw nsw i32 %output.s0.c.co59.us.us, 1
  %.not361.us.us = icmp eq i32 %2673, %1031
  br i1 %.not361.us.us, label %"end for output.s0.c.co58.us.us", label %"for output.s0.c.co57.us.us"

"end for output.s0.c.co58.us.us":                 ; preds = %"consume convolved73.us.us", %"consume sum_input56.us.us"
  %2674 = add nuw nsw i32 %output.s0.x.xo31.us.us, 1
  %.not360.us.us = icmp eq i32 %2674, %1027
  br i1 %.not360.us.us, label %"end for output.s0.x.xo30.loopexit.us.us", label %"for output.s0.x.xo29.us.us"

"for convolved.s1.r19$y64.preheader.us.us":       ; preds = %after_bb61.us.us
  %2675 = shl nuw nsw i32 %output.s0.c.co59.us.us, 1
  %2676 = or i32 %2675, 1
  %2677 = mul nsw i32 %2676, %8
  %2678 = mul nsw i32 %output.s0.c.co59.us.us, %8
  br i1 %1029, label %"for convolved.s1.r19$y64.us.us.us", label %"consume convolved73.us.us", !prof !96

"for sum_input.s1.r19$x44.preheader.us.us":       ; preds = %"for sum_input.s1.r19$y41.us.us"
  %2679 = mul nsw i32 %"sum_input.s1.r19$y43.us.us", %dilation_y
  %2680 = add nsw i32 %2679, %1064
  %2681 = mul nsw i32 %2680, %19
  %t973.us.us = add i32 %1059, %2681
  br i1 %1054, label %"end for sum_input.s1.r19$x45.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x44.us.us"

"for output.s0.c.co57.preheader.us.us":           ; preds = %"consume sum_input56.us.us"
  %convolved313.sroa.0.0.vec.extract571.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 0
  %2682 = mul nsw i32 %convolved313.sroa.0.0.vec.extract571.us.us, %168
  %2683 = insertelement <1 x i32> poison, i32 %2682, i32 0
  %convolved313.sroa.0.4.vec.extract573.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 1
  %2684 = mul nsw i32 %convolved313.sroa.0.4.vec.extract573.us.us, %168
  %2685 = insertelement <1 x i32> poison, i32 %2684, i32 0
  %convolved313.sroa.0.8.vec.extract575.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 2
  %2686 = mul nsw i32 %convolved313.sroa.0.8.vec.extract575.us.us, %168
  %2687 = insertelement <1 x i32> poison, i32 %2686, i32 0
  %convolved313.sroa.0.12.vec.extract577.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 3
  %2688 = mul nsw i32 %convolved313.sroa.0.12.vec.extract577.us.us, %168
  %2689 = insertelement <1 x i32> poison, i32 %2688, i32 0
  %convolved313.sroa.0.16.vec.extract579.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 4
  %2690 = mul nsw i32 %convolved313.sroa.0.16.vec.extract579.us.us, %168
  %2691 = insertelement <1 x i32> poison, i32 %2690, i32 0
  %convolved313.sroa.0.20.vec.extract581.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 5
  %2692 = mul nsw i32 %convolved313.sroa.0.20.vec.extract581.us.us, %168
  %2693 = insertelement <1 x i32> poison, i32 %2692, i32 0
  %convolved313.sroa.0.24.vec.extract583.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 6
  %2694 = mul nsw i32 %convolved313.sroa.0.24.vec.extract583.us.us, %168
  %2695 = insertelement <1 x i32> poison, i32 %2694, i32 0
  %convolved313.sroa.0.28.vec.extract585.us.us = extractelement <32 x i32> %convolved313.sroa.0.20.us.us, i32 7
  %2696 = mul nsw i32 %convolved313.sroa.0.28.vec.extract585.us.us, %168
  %2697 = insertelement <1 x i32> poison, i32 %2696, i32 0
  %2698 = add nsw i32 %output.s0.x.x.base.s32.us.us, %25
  %2699 = add nsw i32 %2698, 7
  %2700 = mul nsw i32 %2699, %stride_x
  %2701 = add nsw i32 %2698, 6
  %2702 = mul nsw i32 %2701, %stride_x
  %2703 = add nsw i32 %2698, 5
  %2704 = mul nsw i32 %2703, %stride_x
  %2705 = add nsw i32 %2698, 4
  %2706 = mul nsw i32 %2705, %stride_x
  %2707 = add nsw i32 %2698, 3
  %2708 = mul nsw i32 %2707, %stride_x
  %2709 = add nsw i32 %2698, 2
  %2710 = mul nsw i32 %2709, %stride_x
  %2711 = add nsw i32 %2698, 1
  %2712 = mul nsw i32 %2711, %stride_x
  %2713 = mul nsw i32 %2698, %stride_x
  %2714 = mul nsw i32 %2698, %27
  %2715 = mul nsw i32 %2711, %27
  %2716 = mul nsw i32 %2709, %27
  %2717 = mul nsw i32 %2707, %27
  %2718 = mul nsw i32 %2705, %27
  %2719 = mul nsw i32 %2703, %27
  %2720 = mul nsw i32 %2701, %27
  %2721 = mul nsw i32 %2699, %27
  br label %"for output.s0.c.co57.us.us"

"for sum_input.s1.r19$y41.preheader.us.us":       ; preds = %then_bb39.us.us
  %2722 = add nsw i32 %output.s0.x.x.base.s32.us.us, %25
  %2723 = sub i32 %2722, %16
  br label %"for sum_input.s1.r19$y41.us.us"

"for sum_input.s1.r19$y47.preheader.us.us":       ; preds = %next_bb40.us.us
  %2724 = add nsw i32 %output.s0.x.x.base.s32.us.us, %25
  %2725 = mul nsw i32 %2724, %stride_x
  br i1 %brmerge1308.demorgan, label %"for sum_input.s1.r19$y47.us.us.us.us", label %"consume sum_input56.us.us", !prof !103

"end for output.s0.x.xo30.loopexit.us.us":        ; preds = %"end for output.s0.c.co58.us.us"
  %2726 = add nuw nsw i32 %output.s0.y.rebased28.us.us, 1
  %.not359.us.us = icmp eq i32 %2726, %29
  br i1 %.not359.us.us, label %"end for output.s0.y.rebased27.loopexit.us", label %"for output.s0.y.rebased26.us.us"

"for sum_input.s1.r19$y47.us.us.us.us":           ; preds = %"for sum_input.s1.r19$y47.preheader.us.us", %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us"
  %convolved313.sroa.0.15.us.us.us.us = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us" ], [ %convolved313.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y47.preheader.us.us" ]
  %"sum_input.s1.r19$y49.us.us.us.us" = phi i32 [ %2917, %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y47.preheader.us.us" ]
  %2727 = mul nsw i32 %"sum_input.s1.r19$y49.us.us.us.us", %dilation_y
  %t975.s.us.us.us.us = add nsw i32 %2727, %1064
  %2728 = mul nsw i32 %t975.s.us.us.us.us, %19
  br label %"for sum_input.s1.r19$x50.us.us.us.us.us"

"for sum_input.s1.r19$x50.us.us.us.us.us":        ; preds = %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us", %"for sum_input.s1.r19$y47.us.us.us.us"
  %convolved313.sroa.0.16.us.us.us.us.us = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us" ], [ %convolved313.sroa.0.15.us.us.us.us, %"for sum_input.s1.r19$y47.us.us.us.us" ]
  %"sum_input.s1.r19$x52.us.us.us.us.us" = phi i32 [ %2916, %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y47.us.us.us.us" ]
  %2729 = mul nsw i32 %"sum_input.s1.r19$x52.us.us.us.us.us", %dilation_x
  %t976.s.us.us.us.us.us = add nsw i32 %2729, %2725
  %t1226.us.us.us.us.us = mul nsw i32 %t976.s.us.us.us.us.us, %17
  %2730 = add i32 %t1226.us.us.us.us.us, %2728
  %t977.us.us.us.us.us = sub i32 %2730, %t941
  %2731 = add i32 %t977.us.us.us.us.us, %1058
  %t949.us.us.us.us.us = add i32 %2730, %1024
  %2732 = sub i32 %t949.us.us.us.us.us, %1011
  %t978.us.us.us.us.us = sub i32 %2732, %1012
  %2733 = add i32 %t978.us.us.us.us.us, %1058
  %2734 = add i32 %2730, %1022
  %2735 = sub i32 %2734, %1051
  %t979.us.us.us.us.us = sub i32 %2735, %1012
  %2736 = add i32 %t979.us.us.us.us.us, %1058
  %2737 = add i32 %2730, %1021
  %2738 = sub i32 %2737, %1051
  %t980.us.us.us.us.us = sub i32 %2738, %1012
  %2739 = add i32 %t980.us.us.us.us.us, %1058
  %2740 = add i32 %2730, %1020
  %2741 = sub i32 %2740, %1051
  %t981.us.us.us.us.us = sub i32 %2741, %1012
  %2742 = add i32 %t981.us.us.us.us.us, %1058
  %2743 = add i32 %2730, %1019
  %2744 = sub i32 %2743, %1051
  %t982.us.us.us.us.us = sub i32 %2744, %1012
  %2745 = add i32 %t982.us.us.us.us.us, %1058
  %2746 = add i32 %2730, %1018
  %2747 = sub i32 %2746, %1051
  %t983.us.us.us.us.us = sub i32 %2747, %1012
  %2748 = add i32 %t983.us.us.us.us.us, %1058
  %2749 = add i32 %2730, %1017
  %2750 = sub i32 %2749, %1051
  %t984.us.us.us.us.us = sub i32 %2750, %1012
  %2751 = add i32 %t984.us.us.us.us.us, %1058
  br i1 %1053, label %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r12453.us.us.us.us.us"

"for sum_input.s1.r19$z.r12453.us.us.us.us.us":   ; preds = %"for sum_input.s1.r19$x50.us.us.us.us.us", %"for sum_input.s1.r19$z.r12453.us.us.us.us.us"
  %convolved313.sroa.0.18.us.us.us.us.us = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ], [ %convolved313.sroa.0.16.us.us.us.us.us, %"for sum_input.s1.r19$x50.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r12455.us.us.us.us.us" = phi i32 [ %2861, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$x50.us.us.us.us.us" ]
  %niter1503 = phi i32 [ %niter1503.nsub.1, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ], [ %unroll_iter1502, %"for sum_input.s1.r19$x50.us.us.us.us.us" ]
  %2752 = shl nsw i32 %"sum_input.s1.r19$z.r12455.us.us.us.us.us", 2
  %2753 = add i32 %2731, %2752
  %2754 = getelementptr inbounds i8, i8* %13, i32 %2753
  %2755 = bitcast i8* %2754 to <4 x i8>*
  %2756 = load <4 x i8>, <4 x i8>* %2755, align 4, !tbaa !108
  %2757 = add i32 %2733, %2752
  %2758 = getelementptr inbounds i8, i8* %13, i32 %2757
  %2759 = bitcast i8* %2758 to <4 x i8>*
  %2760 = load <4 x i8>, <4 x i8>* %2759, align 4, !tbaa !108
  %2761 = add i32 %2736, %2752
  %2762 = getelementptr inbounds i8, i8* %13, i32 %2761
  %2763 = bitcast i8* %2762 to <4 x i8>*
  %2764 = load <4 x i8>, <4 x i8>* %2763, align 4, !tbaa !108
  %2765 = add i32 %2739, %2752
  %2766 = getelementptr inbounds i8, i8* %13, i32 %2765
  %2767 = bitcast i8* %2766 to <4 x i8>*
  %2768 = load <4 x i8>, <4 x i8>* %2767, align 4, !tbaa !108
  %2769 = add i32 %2742, %2752
  %2770 = getelementptr inbounds i8, i8* %13, i32 %2769
  %2771 = bitcast i8* %2770 to <4 x i8>*
  %2772 = load <4 x i8>, <4 x i8>* %2771, align 4, !tbaa !108
  %2773 = add i32 %2745, %2752
  %2774 = getelementptr inbounds i8, i8* %13, i32 %2773
  %2775 = bitcast i8* %2774 to <4 x i8>*
  %2776 = load <4 x i8>, <4 x i8>* %2775, align 4, !tbaa !108
  %2777 = add i32 %2748, %2752
  %2778 = getelementptr inbounds i8, i8* %13, i32 %2777
  %2779 = bitcast i8* %2778 to <4 x i8>*
  %2780 = load <4 x i8>, <4 x i8>* %2779, align 4, !tbaa !108
  %2781 = add i32 %2751, %2752
  %2782 = getelementptr inbounds i8, i8* %13, i32 %2781
  %2783 = bitcast i8* %2782 to <4 x i8>*
  %2784 = load <4 x i8>, <4 x i8>* %2783, align 4, !tbaa !108
  %2785 = shufflevector <4 x i8> %2756, <4 x i8> %2760, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2786 = shufflevector <4 x i8> %2764, <4 x i8> %2768, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2787 = shufflevector <4 x i8> %2772, <4 x i8> %2776, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2788 = shufflevector <4 x i8> %2780, <4 x i8> %2784, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2789 = shufflevector <8 x i8> %2785, <8 x i8> %2786, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2790 = shufflevector <8 x i8> %2787, <8 x i8> %2788, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2791 = shufflevector <16 x i8> %2789, <16 x i8> %2790, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1228.us.us.us.us.us = zext <32 x i8> %2791 to <32 x i16>
  %2792 = shufflevector <32 x i16> %t1228.us.us.us.us.us, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2793 = bitcast <64 x i16> %2792 to <32 x i32>
  %2794 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %2793)
  %2795 = bitcast <32 x i32> %2794 to <64 x i16>
  %2796 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %2793)
  %2797 = bitcast <32 x i32> %2796 to <64 x i16>
  %2798 = add <64 x i16> %2797, %2795
  %2799 = shufflevector <64 x i16> %2798, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1227.us.us.us.us.us = zext <16 x i16> %2799 to <16 x i32>
  %2800 = shufflevector <16 x i32> %t1227.us.us.us.us.us, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2801 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %2800, i32 -4)
  %2802 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %2801)
  %2803 = add nsw <32 x i32> %2802, %convolved313.sroa.0.18.us.us.us.us.us
  %2804 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %2801)
  %2805 = add nsw <32 x i32> %2803, %2804
  %convolved313.sroa.0.0.vecblend567.us.us.us.us.us = shufflevector <32 x i32> %2805, <32 x i32> %convolved313.sroa.0.18.us.us.us.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2806 = shl i32 %"sum_input.s1.r19$z.r12455.us.us.us.us.us", 2
  %2807 = or i32 %2806, 4
  %2808 = add i32 %2731, %2807
  %2809 = getelementptr inbounds i8, i8* %13, i32 %2808
  %2810 = bitcast i8* %2809 to <4 x i8>*
  %2811 = load <4 x i8>, <4 x i8>* %2810, align 4, !tbaa !108
  %2812 = add i32 %2733, %2807
  %2813 = getelementptr inbounds i8, i8* %13, i32 %2812
  %2814 = bitcast i8* %2813 to <4 x i8>*
  %2815 = load <4 x i8>, <4 x i8>* %2814, align 4, !tbaa !108
  %2816 = add i32 %2736, %2807
  %2817 = getelementptr inbounds i8, i8* %13, i32 %2816
  %2818 = bitcast i8* %2817 to <4 x i8>*
  %2819 = load <4 x i8>, <4 x i8>* %2818, align 4, !tbaa !108
  %2820 = add i32 %2739, %2807
  %2821 = getelementptr inbounds i8, i8* %13, i32 %2820
  %2822 = bitcast i8* %2821 to <4 x i8>*
  %2823 = load <4 x i8>, <4 x i8>* %2822, align 4, !tbaa !108
  %2824 = add i32 %2742, %2807
  %2825 = getelementptr inbounds i8, i8* %13, i32 %2824
  %2826 = bitcast i8* %2825 to <4 x i8>*
  %2827 = load <4 x i8>, <4 x i8>* %2826, align 4, !tbaa !108
  %2828 = add i32 %2745, %2807
  %2829 = getelementptr inbounds i8, i8* %13, i32 %2828
  %2830 = bitcast i8* %2829 to <4 x i8>*
  %2831 = load <4 x i8>, <4 x i8>* %2830, align 4, !tbaa !108
  %2832 = add i32 %2748, %2807
  %2833 = getelementptr inbounds i8, i8* %13, i32 %2832
  %2834 = bitcast i8* %2833 to <4 x i8>*
  %2835 = load <4 x i8>, <4 x i8>* %2834, align 4, !tbaa !108
  %2836 = add i32 %2751, %2807
  %2837 = getelementptr inbounds i8, i8* %13, i32 %2836
  %2838 = bitcast i8* %2837 to <4 x i8>*
  %2839 = load <4 x i8>, <4 x i8>* %2838, align 4, !tbaa !108
  %2840 = shufflevector <4 x i8> %2811, <4 x i8> %2815, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2841 = shufflevector <4 x i8> %2819, <4 x i8> %2823, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2842 = shufflevector <4 x i8> %2827, <4 x i8> %2831, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2843 = shufflevector <4 x i8> %2835, <4 x i8> %2839, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2844 = shufflevector <8 x i8> %2840, <8 x i8> %2841, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2845 = shufflevector <8 x i8> %2842, <8 x i8> %2843, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2846 = shufflevector <16 x i8> %2844, <16 x i8> %2845, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1228.us.us.us.us.us.1 = zext <32 x i8> %2846 to <32 x i16>
  %2847 = shufflevector <32 x i16> %t1228.us.us.us.us.us.1, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2848 = bitcast <64 x i16> %2847 to <32 x i32>
  %2849 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %2848)
  %2850 = bitcast <32 x i32> %2849 to <64 x i16>
  %2851 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %2848)
  %2852 = bitcast <32 x i32> %2851 to <64 x i16>
  %2853 = add <64 x i16> %2852, %2850
  %2854 = shufflevector <64 x i16> %2853, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1227.us.us.us.us.us.1 = zext <16 x i16> %2854 to <16 x i32>
  %2855 = shufflevector <16 x i32> %t1227.us.us.us.us.us.1, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2856 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %2855, i32 -4)
  %2857 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %2856)
  %2858 = add nsw <32 x i32> %2857, %convolved313.sroa.0.0.vecblend567.us.us.us.us.us
  %2859 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %2856)
  %2860 = add nsw <32 x i32> %2858, %2859
  %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.1 = shufflevector <32 x i32> %2860, <32 x i32> %convolved313.sroa.0.0.vecblend567.us.us.us.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %2861 = add nuw nsw i32 %"sum_input.s1.r19$z.r12455.us.us.us.us.us", 2
  %niter1503.nsub.1 = add i32 %niter1503, -2
  %niter1503.ncmp.1 = icmp eq i32 %niter1503.nsub.1, 0
  br i1 %niter1503.ncmp.1, label %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r12453.us.us.us.us.us"

"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa": ; preds = %"for sum_input.s1.r19$z.r12453.us.us.us.us.us", %"for sum_input.s1.r19$x50.us.us.us.us.us"
  %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x50.us.us.us.us.us" ], [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ]
  %convolved313.sroa.0.18.us.us.us.us.us.unr = phi <32 x i32> [ %convolved313.sroa.0.16.us.us.us.us.us, %"for sum_input.s1.r19$x50.us.us.us.us.us" ], [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r12455.us.us.us.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x50.us.us.us.us.us" ], [ %2861, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us" ]
  br i1 %lcmp.mod1501.not, label %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us", label %"for sum_input.s1.r19$z.r12453.us.us.us.us.us.epil"

"for sum_input.s1.r19$z.r12453.us.us.us.us.us.epil": ; preds = %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa"
  %2862 = shl nsw i32 %"sum_input.s1.r19$z.r12455.us.us.us.us.us.unr", 2
  %2863 = add i32 %2731, %2862
  %2864 = getelementptr inbounds i8, i8* %13, i32 %2863
  %2865 = bitcast i8* %2864 to <4 x i8>*
  %2866 = load <4 x i8>, <4 x i8>* %2865, align 4, !tbaa !108
  %2867 = add i32 %2733, %2862
  %2868 = getelementptr inbounds i8, i8* %13, i32 %2867
  %2869 = bitcast i8* %2868 to <4 x i8>*
  %2870 = load <4 x i8>, <4 x i8>* %2869, align 4, !tbaa !108
  %2871 = add i32 %2736, %2862
  %2872 = getelementptr inbounds i8, i8* %13, i32 %2871
  %2873 = bitcast i8* %2872 to <4 x i8>*
  %2874 = load <4 x i8>, <4 x i8>* %2873, align 4, !tbaa !108
  %2875 = add i32 %2739, %2862
  %2876 = getelementptr inbounds i8, i8* %13, i32 %2875
  %2877 = bitcast i8* %2876 to <4 x i8>*
  %2878 = load <4 x i8>, <4 x i8>* %2877, align 4, !tbaa !108
  %2879 = add i32 %2742, %2862
  %2880 = getelementptr inbounds i8, i8* %13, i32 %2879
  %2881 = bitcast i8* %2880 to <4 x i8>*
  %2882 = load <4 x i8>, <4 x i8>* %2881, align 4, !tbaa !108
  %2883 = add i32 %2745, %2862
  %2884 = getelementptr inbounds i8, i8* %13, i32 %2883
  %2885 = bitcast i8* %2884 to <4 x i8>*
  %2886 = load <4 x i8>, <4 x i8>* %2885, align 4, !tbaa !108
  %2887 = add i32 %2748, %2862
  %2888 = getelementptr inbounds i8, i8* %13, i32 %2887
  %2889 = bitcast i8* %2888 to <4 x i8>*
  %2890 = load <4 x i8>, <4 x i8>* %2889, align 4, !tbaa !108
  %2891 = add i32 %2751, %2862
  %2892 = getelementptr inbounds i8, i8* %13, i32 %2891
  %2893 = bitcast i8* %2892 to <4 x i8>*
  %2894 = load <4 x i8>, <4 x i8>* %2893, align 4, !tbaa !108
  %2895 = shufflevector <4 x i8> %2866, <4 x i8> %2870, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2896 = shufflevector <4 x i8> %2874, <4 x i8> %2878, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2897 = shufflevector <4 x i8> %2882, <4 x i8> %2886, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2898 = shufflevector <4 x i8> %2890, <4 x i8> %2894, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2899 = shufflevector <8 x i8> %2895, <8 x i8> %2896, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2900 = shufflevector <8 x i8> %2897, <8 x i8> %2898, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %2901 = shufflevector <16 x i8> %2899, <16 x i8> %2900, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1228.us.us.us.us.us.epil = zext <32 x i8> %2901 to <32 x i16>
  %2902 = shufflevector <32 x i16> %t1228.us.us.us.us.us.epil, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2903 = bitcast <64 x i16> %2902 to <32 x i32>
  %2904 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %2903)
  %2905 = bitcast <32 x i32> %2904 to <64 x i16>
  %2906 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %2903)
  %2907 = bitcast <32 x i32> %2906 to <64 x i16>
  %2908 = add <64 x i16> %2907, %2905
  %2909 = shufflevector <64 x i16> %2908, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1227.us.us.us.us.us.epil = zext <16 x i16> %2909 to <16 x i32>
  %2910 = shufflevector <16 x i32> %t1227.us.us.us.us.us.epil, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %2911 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %2910, i32 -4)
  %2912 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %2911)
  %2913 = add nsw <32 x i32> %2912, %convolved313.sroa.0.18.us.us.us.us.us.unr
  %2914 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %2911)
  %2915 = add nsw <32 x i32> %2913, %2914
  %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.epil = shufflevector <32 x i32> %2915, <32 x i32> %convolved313.sroa.0.18.us.us.us.us.us.unr, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  br label %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us"

"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa", %"for sum_input.s1.r19$z.r12453.us.us.us.us.us.epil"
  %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa = phi <32 x i32> [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.lcssa.ph, %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us.unr-lcssa" ], [ %convolved313.sroa.0.0.vecblend567.us.us.us.us.us.epil, %"for sum_input.s1.r19$z.r12453.us.us.us.us.us.epil" ]
  %2916 = add nuw nsw i32 %"sum_input.s1.r19$x52.us.us.us.us.us", 1
  %.not366.us.us.us.us.us = icmp eq i32 %2916, %9
  br i1 %.not366.us.us.us.us.us, label %"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us", label %"for sum_input.s1.r19$x50.us.us.us.us.us"

"end for sum_input.s1.r19$x51.loopexit.split.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r12454.loopexit.us.us.us.us.us"
  %2917 = add nuw nsw i32 %"sum_input.s1.r19$y49.us.us.us.us", 1
  %.not365.us.us.us.us = icmp eq i32 %2917, %11
  br i1 %.not365.us.us.us.us, label %"consume sum_input56.us.us", label %"for sum_input.s1.r19$y47.us.us.us.us"

"for convolved.s1.r19$y64.us.us.us":              ; preds = %"for convolved.s1.r19$y64.preheader.us.us", %"end for convolved.s1.r19$x68.loopexit.us.us.us"
  %sum_input187312.sroa.155.1.us.us.us = phi <32 x i32> [ %.us-phi1041.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.155.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.146.1.us.us.us = phi <32 x i32> [ %.us-phi1042.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.146.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.137.1.us.us.us = phi <32 x i32> [ %.us-phi1043.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.137.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.128.1.us.us.us = phi <32 x i32> [ %.us-phi1044.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.128.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.119.1.us.us.us = phi <32 x i32> [ %.us-phi1045.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.119.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.110.1.us.us.us = phi <32 x i32> [ %.us-phi1046.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.110.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.101.1.us.us.us = phi <32 x i32> [ %.us-phi1047.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.101.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.92.1.us.us.us = phi <32 x i32> [ %.us-phi1048.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.92.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.83.1.us.us.us = phi <32 x i32> [ %.us-phi1049.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.83.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.74.1.us.us.us = phi <32 x i32> [ %.us-phi1050.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.74.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.65.1.us.us.us = phi <32 x i32> [ %.us-phi1051.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.65.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.56.1.us.us.us = phi <32 x i32> [ %.us-phi1052.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.56.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.47.1.us.us.us = phi <32 x i32> [ %.us-phi1053.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.47.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.38.1.us.us.us = phi <32 x i32> [ %.us-phi1054.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.38.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.29.1.us.us.us = phi <32 x i32> [ %.us-phi1055.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.29.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %sum_input187312.sroa.0.1.us.us.us = phi <32 x i32> [ %.us-phi1056.us.us.us, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ %sum_input187312.sroa.0.0.us.us, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %"convolved.s1.r19$y66.us.us.us" = phi i32 [ %2922, %"end for convolved.s1.r19$x68.loopexit.us.us.us" ], [ 0, %"for convolved.s1.r19$y64.preheader.us.us" ]
  %2918 = mul nsw i32 %"convolved.s1.r19$y66.us.us.us", %dilation_y
  %2919 = add nsw i32 %2918, %1064
  %2920 = mul nsw i32 %2919, %19
  %t1011.us.us.us = add nsw i32 %2920, %1060
  %2921 = mul nsw i32 %"convolved.s1.r19$y66.us.us.us", %12
  br i1 %1030, label %"for convolved.s1.r19$x67.us.us.us.us", label %"end for convolved.s1.r19$x68.loopexit.us.us.us", !prof !96

"end for convolved.s1.r19$x68.loopexit.us.us.us": ; preds = %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us", %"for convolved.s1.r19$y64.us.us.us"
  %.us-phi1041.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.155.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3033, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1042.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.146.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3029, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1043.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.137.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3022, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1044.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.128.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3018, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1045.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.119.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3011, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1046.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.110.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3007, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1047.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.101.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %3000, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1048.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.92.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2996, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1049.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.83.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2989, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1050.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.74.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2985, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1051.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.65.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2978, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1052.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.56.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2974, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1053.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.47.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2967, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1054.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.38.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2963, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1055.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.29.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2956, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %.us-phi1056.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ], [ %2948, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ]
  %2922 = add nuw nsw i32 %"convolved.s1.r19$y66.us.us.us", 1
  %.not362.us.us.us = icmp eq i32 %2922, %11
  br i1 %.not362.us.us.us, label %"consume convolved73.us.us", label %"for convolved.s1.r19$y64.us.us.us"

"for convolved.s1.r19$x67.us.us.us.us":           ; preds = %"for convolved.s1.r19$y64.us.us.us", %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us"
  %sum_input187312.sroa.155.2.us.us.us.us = phi <32 x i32> [ %3033, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.155.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.146.2.us.us.us.us = phi <32 x i32> [ %3029, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.146.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.137.2.us.us.us.us = phi <32 x i32> [ %3022, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.137.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.128.2.us.us.us.us = phi <32 x i32> [ %3018, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.128.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.119.2.us.us.us.us = phi <32 x i32> [ %3011, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.119.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.110.2.us.us.us.us = phi <32 x i32> [ %3007, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.110.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.101.2.us.us.us.us = phi <32 x i32> [ %3000, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.101.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.92.2.us.us.us.us = phi <32 x i32> [ %2996, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.92.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.83.2.us.us.us.us = phi <32 x i32> [ %2989, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.83.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.74.2.us.us.us.us = phi <32 x i32> [ %2985, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.74.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.65.2.us.us.us.us = phi <32 x i32> [ %2978, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.65.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.56.2.us.us.us.us = phi <32 x i32> [ %2974, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.56.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.47.2.us.us.us.us = phi <32 x i32> [ %2967, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.47.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.38.2.us.us.us.us = phi <32 x i32> [ %2963, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.38.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.29.2.us.us.us.us = phi <32 x i32> [ %2956, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.29.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %sum_input187312.sroa.0.2.us.us.us.us = phi <32 x i32> [ %2948, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ %sum_input187312.sroa.0.1.us.us.us, %"for convolved.s1.r19$y64.us.us.us" ]
  %"convolved.s1.r19$x69.us.us.us.us" = phi i32 [ %3035, %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y64.us.us.us" ]
  %2923 = mul nsw i32 %"convolved.s1.r19$x69.us.us.us.us", %dilation_x
  %t1024.s.us.us.us.us = add nsw i32 %2923, %2700
  %t1023.s.us.us.us.us = add nsw i32 %2923, %2702
  %t1022.s.us.us.us.us = add nsw i32 %2923, %2704
  %t1021.s.us.us.us.us = add nsw i32 %2923, %2706
  %t1020.s.us.us.us.us = add nsw i32 %2923, %2708
  %t1019.s.us.us.us.us = add nsw i32 %2923, %2710
  %t1018.s.us.us.us.us = add nsw i32 %2923, %2712
  %t1015.s.us.us.us.us = add nsw i32 %2923, %2713
  %2924 = mul nsw i32 %"convolved.s1.r19$x69.us.us.us.us", %10
  %t1016.us.us.us.us = add nsw i32 %2924, %2921
  %2925 = mul nsw i32 %t1015.s.us.us.us.us, %17
  %2926 = add i32 %t1016.us.us.us.us, %2677
  %2927 = mul nsw i32 %t1018.s.us.us.us.us, %17
  %2928 = mul nsw i32 %t1019.s.us.us.us.us, %17
  %2929 = mul nsw i32 %t1020.s.us.us.us.us, %17
  %2930 = mul nsw i32 %t1021.s.us.us.us.us, %17
  %2931 = mul nsw i32 %t1022.s.us.us.us.us, %17
  %2932 = mul nsw i32 %t1023.s.us.us.us.us, %17
  %2933 = mul nsw i32 %t1024.s.us.us.us.us, %17
  br label %"for convolved.s1.r19$z.r12470.us.us.us.us"

"for convolved.s1.r19$z.r12470.us.us.us.us":      ; preds = %"for convolved.s1.r19$z.r12470.us.us.us.us", %"for convolved.s1.r19$x67.us.us.us.us"
  %sum_input187312.sroa.155.4.us.us.us.us = phi <32 x i32> [ %3033, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.155.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.146.4.us.us.us.us = phi <32 x i32> [ %3029, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.146.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.137.4.us.us.us.us = phi <32 x i32> [ %3022, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.137.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.128.4.us.us.us.us = phi <32 x i32> [ %3018, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.128.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.119.4.us.us.us.us = phi <32 x i32> [ %3011, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.119.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.110.4.us.us.us.us = phi <32 x i32> [ %3007, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.110.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.101.4.us.us.us.us = phi <32 x i32> [ %3000, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.101.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.92.4.us.us.us.us = phi <32 x i32> [ %2996, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.92.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.83.4.us.us.us.us = phi <32 x i32> [ %2989, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.83.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.74.4.us.us.us.us = phi <32 x i32> [ %2985, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.74.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.65.4.us.us.us.us = phi <32 x i32> [ %2978, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.65.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.56.4.us.us.us.us = phi <32 x i32> [ %2974, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.56.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.47.4.us.us.us.us = phi <32 x i32> [ %2967, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.47.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.38.4.us.us.us.us = phi <32 x i32> [ %2963, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.38.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.29.4.us.us.us.us = phi <32 x i32> [ %2956, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.29.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %sum_input187312.sroa.0.4.us.us.us.us = phi <32 x i32> [ %2948, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ %sum_input187312.sroa.0.2.us.us.us.us, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %"convolved.s1.r19$z.r12472.us.us.us.us" = phi i32 [ %3034, %"for convolved.s1.r19$z.r12470.us.us.us.us" ], [ 0, %"for convolved.s1.r19$x67.us.us.us.us" ]
  %2934 = shl nsw i32 %"convolved.s1.r19$z.r12472.us.us.us.us", 2
  %2935 = add i32 %2934, %t1011.us.us.us
  %2936 = add i32 %2935, %2925
  %2937 = getelementptr inbounds i8, i8* %13, i32 %2936
  %2938 = bitcast i8* %2937 to <4 x i8>*
  %2939 = load <4 x i8>, <4 x i8>* %2938, align 4, !tbaa !108
  %2940 = shl nsw i32 %"convolved.s1.r19$z.r12472.us.us.us.us", 6
  %2941 = add nsw i32 %2940, %2678
  %2942 = shl nsw i32 %2941, 1
  %2943 = add nsw i32 %t1016.us.us.us.us, %2942
  %2944 = getelementptr inbounds i8, i8* %5, i32 %2943
  %2945 = bitcast i8* %2944 to <128 x i8>*
  %2946 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %2947 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2939, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2948 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.0.4.us.us.us.us, <128 x i8> %2946, <32 x i32> %2947, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2949 = load <4 x i8>, <4 x i8>* %2938, align 4, !tbaa !108
  %2950 = shl nsw i32 %"convolved.s1.r19$z.r12472.us.us.us.us", 7
  %2951 = add i32 %2926, %2950
  %2952 = getelementptr inbounds i8, i8* %5, i32 %2951
  %2953 = bitcast i8* %2952 to <128 x i8>*
  %2954 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %2955 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2949, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2956 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.29.4.us.us.us.us, <128 x i8> %2954, <32 x i32> %2955, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2957 = add i32 %2935, %2927
  %2958 = getelementptr inbounds i8, i8* %13, i32 %2957
  %2959 = bitcast i8* %2958 to <4 x i8>*
  %2960 = load <4 x i8>, <4 x i8>* %2959, align 4, !tbaa !108
  %2961 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %2962 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2960, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2963 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.38.4.us.us.us.us, <128 x i8> %2961, <32 x i32> %2962, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2964 = load <4 x i8>, <4 x i8>* %2959, align 4, !tbaa !108
  %2965 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %2966 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2964, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2967 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.47.4.us.us.us.us, <128 x i8> %2965, <32 x i32> %2966, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2968 = add i32 %2935, %2928
  %2969 = getelementptr inbounds i8, i8* %13, i32 %2968
  %2970 = bitcast i8* %2969 to <4 x i8>*
  %2971 = load <4 x i8>, <4 x i8>* %2970, align 4, !tbaa !108
  %2972 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %2973 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2971, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2974 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.56.4.us.us.us.us, <128 x i8> %2972, <32 x i32> %2973, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2975 = load <4 x i8>, <4 x i8>* %2970, align 4, !tbaa !108
  %2976 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %2977 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2975, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2978 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.65.4.us.us.us.us, <128 x i8> %2976, <32 x i32> %2977, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2979 = add i32 %2935, %2929
  %2980 = getelementptr inbounds i8, i8* %13, i32 %2979
  %2981 = bitcast i8* %2980 to <4 x i8>*
  %2982 = load <4 x i8>, <4 x i8>* %2981, align 4, !tbaa !108
  %2983 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %2984 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2982, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2985 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.74.4.us.us.us.us, <128 x i8> %2983, <32 x i32> %2984, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2986 = load <4 x i8>, <4 x i8>* %2981, align 4, !tbaa !108
  %2987 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %2988 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2986, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2989 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.83.4.us.us.us.us, <128 x i8> %2987, <32 x i32> %2988, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2990 = add i32 %2935, %2930
  %2991 = getelementptr inbounds i8, i8* %13, i32 %2990
  %2992 = bitcast i8* %2991 to <4 x i8>*
  %2993 = load <4 x i8>, <4 x i8>* %2992, align 4, !tbaa !108
  %2994 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %2995 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2993, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %2996 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.92.4.us.us.us.us, <128 x i8> %2994, <32 x i32> %2995, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %2997 = load <4 x i8>, <4 x i8>* %2992, align 4, !tbaa !108
  %2998 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %2999 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %2997, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3000 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.101.4.us.us.us.us, <128 x i8> %2998, <32 x i32> %2999, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3001 = add i32 %2935, %2931
  %3002 = getelementptr inbounds i8, i8* %13, i32 %3001
  %3003 = bitcast i8* %3002 to <4 x i8>*
  %3004 = load <4 x i8>, <4 x i8>* %3003, align 4, !tbaa !108
  %3005 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %3006 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3004, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3007 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.110.4.us.us.us.us, <128 x i8> %3005, <32 x i32> %3006, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3008 = load <4 x i8>, <4 x i8>* %3003, align 4, !tbaa !108
  %3009 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %3010 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3008, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3011 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.119.4.us.us.us.us, <128 x i8> %3009, <32 x i32> %3010, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3012 = add i32 %2935, %2932
  %3013 = getelementptr inbounds i8, i8* %13, i32 %3012
  %3014 = bitcast i8* %3013 to <4 x i8>*
  %3015 = load <4 x i8>, <4 x i8>* %3014, align 4, !tbaa !108
  %3016 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %3017 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3015, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3018 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.128.4.us.us.us.us, <128 x i8> %3016, <32 x i32> %3017, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3019 = load <4 x i8>, <4 x i8>* %3014, align 4, !tbaa !108
  %3020 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %3021 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3019, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3022 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.137.4.us.us.us.us, <128 x i8> %3020, <32 x i32> %3021, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3023 = add i32 %2935, %2933
  %3024 = getelementptr inbounds i8, i8* %13, i32 %3023
  %3025 = bitcast i8* %3024 to <4 x i8>*
  %3026 = load <4 x i8>, <4 x i8>* %3025, align 4, !tbaa !108
  %3027 = load <128 x i8>, <128 x i8>* %2945, align 128, !tbaa !106
  %3028 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3026, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3029 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.146.4.us.us.us.us, <128 x i8> %3027, <32 x i32> %3028, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3030 = load <4 x i8>, <4 x i8>* %3025, align 4, !tbaa !108
  %3031 = load <128 x i8>, <128 x i8>* %2953, align 128, !tbaa !106
  %3032 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3030, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3033 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %sum_input187312.sroa.155.4.us.us.us.us, <128 x i8> %3031, <32 x i32> %3032, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3034 = add nuw nsw i32 %"convolved.s1.r19$z.r12472.us.us.us.us", 1
  %.not364.us.us.us.us = icmp eq i32 %3034, %7
  br i1 %.not364.us.us.us.us, label %"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us", label %"for convolved.s1.r19$z.r12470.us.us.us.us"

"end for convolved.s1.r19$z.r12471.loopexit.us.us.us.us": ; preds = %"for convolved.s1.r19$z.r12470.us.us.us.us"
  %3035 = add nuw nsw i32 %"convolved.s1.r19$x69.us.us.us.us", 1
  %.not363.us.us.us.us = icmp eq i32 %3035, %9
  br i1 %.not363.us.us.us.us, label %"end for convolved.s1.r19$x68.loopexit.us.us.us", label %"for convolved.s1.r19$x67.us.us.us.us"

next_bb22:                                        ; preds = %next_bb5
  br i1 %98, label %then_bb74, label %next_bb75

then_bb74:                                        ; preds = %next_bb22
  %3036 = mul nsw i32 %19, %18
  %3037 = mul nsw i32 %22, %20
  %3038 = mul nsw i32 %17, %16
  %3039 = add i32 %3037, %3036
  %t1037 = add i32 %3039, %3038
  %3040 = icmp sgt i32 %21, 0
  br i1 %3040, label %"for output.s0.b.rebased76.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased76.preheader":            ; preds = %then_bb74
  %3041 = mul nsw i32 %17, %stride_x
  %3042 = mul nsw i32 %3041, 7
  %3043 = mul nsw i32 %3041, 6
  %3044 = mul nsw i32 %3041, 5
  %3045 = shl nsw i32 %3041, 2
  %3046 = mul nsw i32 %3041, 3
  %3047 = shl nsw i32 %3041, 1
  %3048 = sub nsw i32 %stride_x, %16
  %3049 = mul nsw i32 %3048, %17
  %3050 = icmp sgt i32 %29, 0
  %.neg766 = mul i32 %30, %28
  %.neg767 = mul i32 %27, %25
  %.neg768 = mul i32 %31, %20
  %reass.add770 = add i32 %.neg766, %.neg767
  %reass.add771 = add i32 %reass.add770, %.neg768
  %3051 = add nuw nsw i32 %26, 7
  %3052 = ashr i32 %3051, 3
  %b432 = add nsw i32 %26, -8
  %3053 = icmp sgt i32 %11, 0
  %3054 = icmp sgt i32 %9, 0
  %3055 = icmp sgt i32 %7, 0
  %3056 = ashr i32 %4, 5
  %3057 = icmp sgt i32 %4, 31
  %3058 = insertelement <32 x i32> undef, i32 %output_multiplier, i32 0
  %3059 = shufflevector <32 x i32> %3058, <32 x i32> undef, <32 x i32> zeroinitializer
  %3060 = sext <32 x i32> %3059 to <32 x i64>
  %3061 = icmp sgt i32 %a497, 0
  %3062 = select i1 %3061, i32 %a497, i32 0
  %3063 = shl nuw i32 1, %3062
  %3064 = ashr i32 %3063, 1
  %3065 = insertelement <1 x i32> poison, i32 %3064, i32 0
  %3066 = insertelement <1 x i32> poison, i32 %a497, i32 0
  %3067 = zext i8 %output_zero to i16
  %3068 = insertelement <32 x i16> undef, i16 %3067, i32 0
  %3069 = shufflevector <32 x i16> %3068, <32 x i16> undef, <64 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3070 = bitcast <64 x i16> %3069 to <32 x i32>
  %3071 = insertelement <32 x i8> undef, i8 %output_max, i32 0
  %3072 = shufflevector <32 x i8> %3071, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3073 = bitcast <128 x i8> %3072 to <32 x i32>
  %3074 = insertelement <32 x i8> undef, i8 %output_min, i32 0
  %3075 = shufflevector <32 x i8> %3074, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3076 = bitcast <128 x i8> %3075 to <32 x i32>
  br i1 %3050, label %"for output.s0.b.rebased76.us.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased76.us.preheader":         ; preds = %"for output.s0.b.rebased76.preheader"
  %3077 = add i32 %3038, %3036
  %3078 = add i32 %9, -1
  %brmerge1311.demorgan = and i1 %3054, %3055
  %xtraiter1490 = and i32 %7, 1
  %3079 = icmp eq i32 %7, 1
  %unroll_iter1492 = and i32 %7, -2
  %lcmp.mod1491.not = icmp eq i32 %xtraiter1490, 0
  %xtraiter1494 = and i32 %9, 3
  %3080 = icmp ult i32 %3078, 3
  %unroll_iter1498 = and i32 %9, -4
  %lcmp.mod1496.not = icmp eq i32 %xtraiter1494, 0
  br label %"for output.s0.b.rebased76.us"

"for output.s0.b.rebased76.us":                   ; preds = %"for output.s0.b.rebased76.us.preheader", %"end for output.s0.y.rebased80.loopexit.us"
  %sum_input187312.sroa.0.7.us = phi <32 x i32> [ %.us-phi1028.us, %"end for output.s0.y.rebased80.loopexit.us" ], [ undef, %"for output.s0.b.rebased76.us.preheader" ]
  %output.s0.b.rebased78.us = phi i32 [ %3087, %"end for output.s0.y.rebased80.loopexit.us" ], [ 0, %"for output.s0.b.rebased76.us.preheader" ]
  %3081 = add nsw i32 %output.s0.b.rebased78.us, %20
  %3082 = mul nsw i32 %3081, %31
  %3083 = sub i32 %3082, %reass.add771
  %3084 = mul nsw i32 %3081, %22
  %3085 = sub i32 %3084, %3039
  %3086 = sub nsw i32 %3084, %t1037
  br i1 %100, label %"for output.s0.y.rebased79.us.us", label %"end for output.s0.y.rebased80.loopexit.us", !prof !96

"end for output.s0.y.rebased80.loopexit.us":      ; preds = %"end for output.s0.x.xo83.loopexit.us.us", %"for output.s0.b.rebased76.us"
  %.us-phi1028.us = phi <32 x i32> [ %sum_input187312.sroa.0.7.us, %"for output.s0.b.rebased76.us" ], [ %sum_input187312.sroa.0.20.us.us, %"end for output.s0.x.xo83.loopexit.us.us" ]
  %3087 = add nuw nsw i32 %output.s0.b.rebased78.us, 1
  %.not346.us = icmp eq i32 %3087, %21
  br i1 %.not346.us, label %after_bb3, label %"for output.s0.b.rebased76.us"

"for output.s0.y.rebased79.us.us":                ; preds = %"for output.s0.b.rebased76.us", %"end for output.s0.x.xo83.loopexit.us.us"
  %sum_input187312.sroa.0.8.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.20.us.us, %"end for output.s0.x.xo83.loopexit.us.us" ], [ %sum_input187312.sroa.0.7.us, %"for output.s0.b.rebased76.us" ]
  %output.s0.y.rebased81.us.us = phi i32 [ %3528, %"end for output.s0.x.xo83.loopexit.us.us" ], [ 0, %"for output.s0.b.rebased76.us" ]
  %3088 = add nsw i32 %output.s0.y.rebased81.us.us, %28
  %3089 = mul nsw i32 %3088, %30
  %t1066.us.us = add i32 %3083, %3089
  %3090 = mul nsw i32 %3088, %stride_y
  br label %"for output.s0.x.xo82.us.us"

"for output.s0.x.xo82.us.us":                     ; preds = %"end for output.s0.c.co111.us.us", %"for output.s0.y.rebased79.us.us"
  %sum_input187312.sroa.0.10.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.20.us.us, %"end for output.s0.c.co111.us.us" ], [ %sum_input187312.sroa.0.8.us.us, %"for output.s0.y.rebased79.us.us" ]
  %output.s0.x.xo84.us.us = phi i32 [ %3479, %"end for output.s0.c.co111.us.us" ], [ 0, %"for output.s0.y.rebased79.us.us" ]
  %a430.us.us = shl nsw i32 %output.s0.x.xo84.us.us, 3
  %3091 = icmp slt i32 %a430.us.us, %b432
  %output.s0.x.x.base.s85.us.us = select i1 %3091, i32 %a430.us.us, i32 %b432
  br i1 %t843.not, label %"consume sum_input109.us.us", label %then_bb89.us.us

then_bb89.us.us:                                  ; preds = %"for output.s0.x.xo82.us.us"
  %sum_input187312.sroa.0.0.vecblend.us.us = shufflevector <32 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>, <32 x i32> %sum_input187312.sroa.0.10.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  br i1 %t844, label %then_bb92.us.us, label %next_bb93.us.us

next_bb93.us.us:                                  ; preds = %then_bb89.us.us
  br i1 %3053, label %"for sum_input.s1.r19$y100.preheader.us.us", label %"consume sum_input109.us.us", !prof !96

then_bb92.us.us:                                  ; preds = %then_bb89.us.us
  br i1 %3053, label %"for sum_input.s1.r19$y94.preheader.us.us", label %"consume sum_input109.us.us", !prof !96

"for sum_input.s1.r19$y94.us.us":                 ; preds = %"for sum_input.s1.r19$y94.preheader.us.us", %"end for sum_input.s1.r19$x98.us.us"
  %sum_input187312.sroa.0.12.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.14.us.us, %"end for sum_input.s1.r19$x98.us.us" ], [ %sum_input187312.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y94.preheader.us.us" ]
  %"sum_input.s1.r19$y96.us.us" = phi i32 [ %3192, %"end for sum_input.s1.r19$x98.us.us" ], [ 0, %"for sum_input.s1.r19$y94.preheader.us.us" ]
  br i1 %3054, label %"for sum_input.s1.r19$x97.preheader.us.us", label %"end for sum_input.s1.r19$x98.us.us", !prof !96

"for sum_input.s1.r19$x97.us.us":                 ; preds = %"for sum_input.s1.r19$x97.preheader.us.us", %"for sum_input.s1.r19$x97.us.us"
  %sum_input187312.sroa.0.13.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend637.us.us.3, %"for sum_input.s1.r19$x97.us.us" ], [ %sum_input187312.sroa.0.12.us.us, %"for sum_input.s1.r19$x97.preheader.us.us" ]
  %"sum_input.s1.r19$x99.us.us" = phi i32 [ %3171, %"for sum_input.s1.r19$x97.us.us" ], [ 0, %"for sum_input.s1.r19$x97.preheader.us.us" ]
  %niter1499 = phi i32 [ %niter1499.nsub.3, %"for sum_input.s1.r19$x97.us.us" ], [ %unroll_iter1498, %"for sum_input.s1.r19$x97.preheader.us.us" ]
  %3092 = mul nsw i32 %"sum_input.s1.r19$x99.us.us", %dilation_x
  %reass.add776.us.us = add i32 %3525, %3092
  %reass.mul777.us.us = shl i32 %reass.add776.us.us, 2
  %3093 = add i32 %t1069.us.us, %reass.mul777.us.us
  %3094 = getelementptr inbounds i8, i8* %13, i32 %3093
  %3095 = bitcast i8* %3094 to <32 x i8>*
  %3096 = load <32 x i8>, <32 x i8>* %3095, align 4, !tbaa !108
  %t1230.us.us = zext <32 x i8> %3096 to <32 x i16>
  %3097 = shufflevector <32 x i16> %t1230.us.us, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3098 = bitcast <64 x i16> %3097 to <32 x i32>
  %3099 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3098)
  %3100 = bitcast <32 x i32> %3099 to <64 x i16>
  %3101 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3098)
  %3102 = bitcast <32 x i32> %3101 to <64 x i16>
  %3103 = add <64 x i16> %3102, %3100
  %3104 = shufflevector <64 x i16> %3103, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1229.us.us = zext <16 x i16> %3104 to <16 x i32>
  %3105 = shufflevector <16 x i32> %t1229.us.us, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3106 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3105, i32 -4)
  %3107 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3106)
  %3108 = add nsw <32 x i32> %3107, %sum_input187312.sroa.0.13.us.us
  %3109 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3106)
  %3110 = add nsw <32 x i32> %3108, %3109
  %sum_input187312.sroa.0.0.vecblend637.us.us = shufflevector <32 x i32> %3110, <32 x i32> %sum_input187312.sroa.0.13.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3111 = or i32 %"sum_input.s1.r19$x99.us.us", 1
  %3112 = mul nsw i32 %3111, %dilation_x
  %reass.add776.us.us.1 = add i32 %3525, %3112
  %reass.mul777.us.us.1 = shl i32 %reass.add776.us.us.1, 2
  %3113 = add i32 %t1069.us.us, %reass.mul777.us.us.1
  %3114 = getelementptr inbounds i8, i8* %13, i32 %3113
  %3115 = bitcast i8* %3114 to <32 x i8>*
  %3116 = load <32 x i8>, <32 x i8>* %3115, align 4, !tbaa !108
  %t1230.us.us.1 = zext <32 x i8> %3116 to <32 x i16>
  %3117 = shufflevector <32 x i16> %t1230.us.us.1, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3118 = bitcast <64 x i16> %3117 to <32 x i32>
  %3119 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3118)
  %3120 = bitcast <32 x i32> %3119 to <64 x i16>
  %3121 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3118)
  %3122 = bitcast <32 x i32> %3121 to <64 x i16>
  %3123 = add <64 x i16> %3122, %3120
  %3124 = shufflevector <64 x i16> %3123, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1229.us.us.1 = zext <16 x i16> %3124 to <16 x i32>
  %3125 = shufflevector <16 x i32> %t1229.us.us.1, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3126 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3125, i32 -4)
  %3127 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3126)
  %3128 = add nsw <32 x i32> %3127, %sum_input187312.sroa.0.0.vecblend637.us.us
  %3129 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3126)
  %3130 = add nsw <32 x i32> %3128, %3129
  %sum_input187312.sroa.0.0.vecblend637.us.us.1 = shufflevector <32 x i32> %3130, <32 x i32> %sum_input187312.sroa.0.0.vecblend637.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3131 = or i32 %"sum_input.s1.r19$x99.us.us", 2
  %3132 = mul nsw i32 %3131, %dilation_x
  %reass.add776.us.us.2 = add i32 %3525, %3132
  %reass.mul777.us.us.2 = shl i32 %reass.add776.us.us.2, 2
  %3133 = add i32 %t1069.us.us, %reass.mul777.us.us.2
  %3134 = getelementptr inbounds i8, i8* %13, i32 %3133
  %3135 = bitcast i8* %3134 to <32 x i8>*
  %3136 = load <32 x i8>, <32 x i8>* %3135, align 4, !tbaa !108
  %t1230.us.us.2 = zext <32 x i8> %3136 to <32 x i16>
  %3137 = shufflevector <32 x i16> %t1230.us.us.2, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3138 = bitcast <64 x i16> %3137 to <32 x i32>
  %3139 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3138)
  %3140 = bitcast <32 x i32> %3139 to <64 x i16>
  %3141 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3138)
  %3142 = bitcast <32 x i32> %3141 to <64 x i16>
  %3143 = add <64 x i16> %3142, %3140
  %3144 = shufflevector <64 x i16> %3143, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1229.us.us.2 = zext <16 x i16> %3144 to <16 x i32>
  %3145 = shufflevector <16 x i32> %t1229.us.us.2, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3146 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3145, i32 -4)
  %3147 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3146)
  %3148 = add nsw <32 x i32> %3147, %sum_input187312.sroa.0.0.vecblend637.us.us.1
  %3149 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3146)
  %3150 = add nsw <32 x i32> %3148, %3149
  %sum_input187312.sroa.0.0.vecblend637.us.us.2 = shufflevector <32 x i32> %3150, <32 x i32> %sum_input187312.sroa.0.0.vecblend637.us.us.1, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3151 = or i32 %"sum_input.s1.r19$x99.us.us", 3
  %3152 = mul nsw i32 %3151, %dilation_x
  %reass.add776.us.us.3 = add i32 %3525, %3152
  %reass.mul777.us.us.3 = shl i32 %reass.add776.us.us.3, 2
  %3153 = add i32 %t1069.us.us, %reass.mul777.us.us.3
  %3154 = getelementptr inbounds i8, i8* %13, i32 %3153
  %3155 = bitcast i8* %3154 to <32 x i8>*
  %3156 = load <32 x i8>, <32 x i8>* %3155, align 4, !tbaa !108
  %t1230.us.us.3 = zext <32 x i8> %3156 to <32 x i16>
  %3157 = shufflevector <32 x i16> %t1230.us.us.3, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3158 = bitcast <64 x i16> %3157 to <32 x i32>
  %3159 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3158)
  %3160 = bitcast <32 x i32> %3159 to <64 x i16>
  %3161 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3158)
  %3162 = bitcast <32 x i32> %3161 to <64 x i16>
  %3163 = add <64 x i16> %3162, %3160
  %3164 = shufflevector <64 x i16> %3163, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1229.us.us.3 = zext <16 x i16> %3164 to <16 x i32>
  %3165 = shufflevector <16 x i32> %t1229.us.us.3, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3166 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3165, i32 -4)
  %3167 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3166)
  %3168 = add nsw <32 x i32> %3167, %sum_input187312.sroa.0.0.vecblend637.us.us.2
  %3169 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3166)
  %3170 = add nsw <32 x i32> %3168, %3169
  %sum_input187312.sroa.0.0.vecblend637.us.us.3 = shufflevector <32 x i32> %3170, <32 x i32> %sum_input187312.sroa.0.0.vecblend637.us.us.2, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3171 = add nuw nsw i32 %"sum_input.s1.r19$x99.us.us", 4
  %niter1499.nsub.3 = add i32 %niter1499, -4
  %niter1499.ncmp.3 = icmp eq i32 %niter1499.nsub.3, 0
  br i1 %niter1499.ncmp.3, label %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x97.us.us"

"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa": ; preds = %"for sum_input.s1.r19$x97.us.us", %"for sum_input.s1.r19$x97.preheader.us.us"
  %sum_input187312.sroa.0.0.vecblend637.us.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x97.preheader.us.us" ], [ %sum_input187312.sroa.0.0.vecblend637.us.us.3, %"for sum_input.s1.r19$x97.us.us" ]
  %sum_input187312.sroa.0.13.us.us.unr = phi <32 x i32> [ %sum_input187312.sroa.0.12.us.us, %"for sum_input.s1.r19$x97.preheader.us.us" ], [ %sum_input187312.sroa.0.0.vecblend637.us.us.3, %"for sum_input.s1.r19$x97.us.us" ]
  %"sum_input.s1.r19$x99.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x97.preheader.us.us" ], [ %3171, %"for sum_input.s1.r19$x97.us.us" ]
  br i1 %lcmp.mod1496.not, label %"end for sum_input.s1.r19$x98.us.us", label %"for sum_input.s1.r19$x97.us.us.epil"

"for sum_input.s1.r19$x97.us.us.epil":            ; preds = %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x97.us.us.epil"
  %sum_input187312.sroa.0.13.us.us.epil = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend637.us.us.epil, %"for sum_input.s1.r19$x97.us.us.epil" ], [ %sum_input187312.sroa.0.13.us.us.unr, %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa" ]
  %"sum_input.s1.r19$x99.us.us.epil" = phi i32 [ %3191, %"for sum_input.s1.r19$x97.us.us.epil" ], [ %"sum_input.s1.r19$x99.us.us.unr", %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa" ]
  %epil.iter1495 = phi i32 [ %epil.iter1495.sub, %"for sum_input.s1.r19$x97.us.us.epil" ], [ %xtraiter1494, %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa" ]
  %3172 = mul nsw i32 %"sum_input.s1.r19$x99.us.us.epil", %dilation_x
  %reass.add776.us.us.epil = add i32 %3525, %3172
  %reass.mul777.us.us.epil = shl i32 %reass.add776.us.us.epil, 2
  %3173 = add i32 %t1069.us.us, %reass.mul777.us.us.epil
  %3174 = getelementptr inbounds i8, i8* %13, i32 %3173
  %3175 = bitcast i8* %3174 to <32 x i8>*
  %3176 = load <32 x i8>, <32 x i8>* %3175, align 4, !tbaa !108
  %t1230.us.us.epil = zext <32 x i8> %3176 to <32 x i16>
  %3177 = shufflevector <32 x i16> %t1230.us.us.epil, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3178 = bitcast <64 x i16> %3177 to <32 x i32>
  %3179 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3178)
  %3180 = bitcast <32 x i32> %3179 to <64 x i16>
  %3181 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3178)
  %3182 = bitcast <32 x i32> %3181 to <64 x i16>
  %3183 = add <64 x i16> %3182, %3180
  %3184 = shufflevector <64 x i16> %3183, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1229.us.us.epil = zext <16 x i16> %3184 to <16 x i32>
  %3185 = shufflevector <16 x i32> %t1229.us.us.epil, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3186 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3185, i32 -4)
  %3187 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3186)
  %3188 = add nsw <32 x i32> %3187, %sum_input187312.sroa.0.13.us.us.epil
  %3189 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3186)
  %3190 = add nsw <32 x i32> %3188, %3189
  %sum_input187312.sroa.0.0.vecblend637.us.us.epil = shufflevector <32 x i32> %3190, <32 x i32> %sum_input187312.sroa.0.13.us.us.epil, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3191 = add nuw nsw i32 %"sum_input.s1.r19$x99.us.us.epil", 1
  %epil.iter1495.sub = add i32 %epil.iter1495, -1
  %epil.iter1495.cmp.not = icmp eq i32 %epil.iter1495.sub, 0
  br i1 %epil.iter1495.cmp.not, label %"end for sum_input.s1.r19$x98.us.us", label %"for sum_input.s1.r19$x97.us.us.epil", !llvm.loop !114

"end for sum_input.s1.r19$x98.us.us":             ; preds = %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x97.us.us.epil", %"for sum_input.s1.r19$y94.us.us"
  %sum_input187312.sroa.0.14.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.12.us.us, %"for sum_input.s1.r19$y94.us.us" ], [ %sum_input187312.sroa.0.0.vecblend637.us.us.lcssa.ph, %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa" ], [ %sum_input187312.sroa.0.0.vecblend637.us.us.epil, %"for sum_input.s1.r19$x97.us.us.epil" ]
  %3192 = add nuw nsw i32 %"sum_input.s1.r19$y96.us.us", 1
  %.not356.us.us = icmp eq i32 %3192, %11
  br i1 %.not356.us.us, label %"consume sum_input109.us.us", label %"for sum_input.s1.r19$y94.us.us"

"consume sum_input109.us.us":                     ; preds = %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us", %"end for sum_input.s1.r19$x98.us.us", %"for sum_input.s1.r19$y100.preheader.us.us", %then_bb92.us.us, %next_bb93.us.us, %"for output.s0.x.xo82.us.us"
  %sum_input187312.sroa.0.20.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.10.us.us, %"for output.s0.x.xo82.us.us" ], [ %sum_input187312.sroa.0.0.vecblend.us.us, %then_bb92.us.us ], [ %sum_input187312.sroa.0.0.vecblend.us.us, %next_bb93.us.us ], [ %sum_input187312.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y100.preheader.us.us" ], [ %sum_input187312.sroa.0.14.us.us, %"end for sum_input.s1.r19$x98.us.us" ], [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us" ]
  br i1 %3057, label %"for output.s0.c.co110.preheader.us.us", label %"end for output.s0.c.co111.us.us", !prof !96

"for output.s0.c.co110.us.us":                    ; preds = %"for output.s0.c.co110.preheader.us.us", %"consume convolved126.us.us"
  %output.s0.c.co112.us.us = phi i32 [ %3478, %"consume convolved126.us.us" ], [ 0, %"for output.s0.c.co110.preheader.us.us" ]
  %3193 = shl nsw i32 %output.s0.c.co112.us.us, 5
  %3194 = getelementptr inbounds i32, i32* %offset_c, i32 %3193
  %3195 = bitcast i32* %3194 to <32 x i32>*
  %3196 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  br i1 %t843.not, label %after_bb114.us.us, label %next_bb116.us.us

next_bb116.us.us:                                 ; preds = %"for output.s0.c.co110.us.us"
  %3197 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3485, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3198 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3196, <32 x i32> %3197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3199 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3200 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3487, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3201 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3199, <32 x i32> %3200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3202 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3203 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3489, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3204 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3202, <32 x i32> %3203, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3205 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3206 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3491, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3207 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3205, <32 x i32> %3206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3208 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3209 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3493, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3210 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3208, <32 x i32> %3209, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3211 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3212 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3495, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3213 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3211, <32 x i32> %3212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3214 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3215 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3497, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3216 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3214, <32 x i32> %3215, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3217 = load <32 x i32>, <32 x i32>* %3195, align 128, !tbaa !104
  %3218 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3499, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3219 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3217, <32 x i32> %3218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb114.us.us

after_bb114.us.us:                                ; preds = %"for output.s0.c.co110.us.us", %next_bb116.us.us
  %convolved313.sroa.122.7.us.us = phi <32 x i32> [ %3219, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.112.7.us.us = phi <32 x i32> [ %3216, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.102.7.us.us = phi <32 x i32> [ %3213, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.92.7.us.us = phi <32 x i32> [ %3210, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.77.7.us.us = phi <32 x i32> [ %3207, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.62.7.us.us = phi <32 x i32> [ %3204, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.47.7.us.us = phi <32 x i32> [ %3201, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  %convolved313.sroa.0.21.us.us = phi <32 x i32> [ %3198, %next_bb116.us.us ], [ %3196, %"for output.s0.c.co110.us.us" ]
  br i1 %3053, label %"for convolved.s1.r19$y117.preheader.us.us", label %"consume convolved126.us.us", !prof !96

"consume convolved126.us.us":                     ; preds = %"end for convolved.s1.r19$x121.loopexit.us.us.us", %"for convolved.s1.r19$y117.preheader.us.us", %after_bb114.us.us
  %convolved313.sroa.122.13.us.us = phi <32 x i32> [ %convolved313.sroa.122.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.122.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi991.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.112.13.us.us = phi <32 x i32> [ %convolved313.sroa.112.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.112.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi992.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.102.13.us.us = phi <32 x i32> [ %convolved313.sroa.102.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.102.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi993.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.92.13.us.us = phi <32 x i32> [ %convolved313.sroa.92.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.92.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi994.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.77.13.us.us = phi <32 x i32> [ %convolved313.sroa.77.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.77.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi995.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.62.13.us.us = phi <32 x i32> [ %convolved313.sroa.62.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.62.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi996.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.47.13.us.us = phi <32 x i32> [ %convolved313.sroa.47.7.us.us, %after_bb114.us.us ], [ %convolved313.sroa.47.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi997.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %convolved313.sroa.0.27.us.us = phi <32 x i32> [ %convolved313.sroa.0.21.us.us, %after_bb114.us.us ], [ %convolved313.sroa.0.21.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ], [ %.us-phi998.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ]
  %3220 = sext <32 x i32> %convolved313.sroa.0.27.us.us to <32 x i64>
  %a433.us.us = mul nsw <32 x i64> %3220, %3060
  %3221 = icmp slt <32 x i64> %a433.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3222 = select <32 x i1> %3221, <32 x i64> %a433.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3223 = add nsw <32 x i64> %3222, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a432.us.us = ashr <32 x i64> %3223, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3224 = icmp slt <32 x i64> %a432.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a431.us.us = select <32 x i1> %3224, <32 x i64> %a432.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3225 = icmp sgt <32 x i64> %a431.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3226 = select <32 x i1> %3225, <32 x i64> %a431.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3227 = trunc <32 x i64> %3226 to <32 x i32>
  %3228 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3229 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3230 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3227, <32 x i32> %3229, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3231 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3228, <1 x i32> zeroinitializer, <32 x i32> %3230, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3232 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3231, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3233 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3232, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3234 = trunc <32 x i32> %3233 to <32 x i16>
  %3235 = shufflevector <32 x i16> %3234, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3236 = bitcast <64 x i16> %3235 to <32 x i32>
  %3237 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3236, <32 x i32> %3070) #11
  %3238 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3237, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3239 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3238, <32 x i32> zeroinitializer) #11
  %3240 = bitcast <32 x i32> %3239 to <64 x i16>
  %3241 = shufflevector <64 x i16> %3240, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3242 = trunc <32 x i16> %3241 to <32 x i8>
  %3243 = shufflevector <32 x i8> %3242, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3244 = bitcast <128 x i8> %3243 to <32 x i32>
  %3245 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3244, <32 x i32> %3073) #11
  %3246 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3245, <32 x i32> %3076) #11
  %3247 = bitcast <32 x i32> %3246 to <128 x i8>
  %3248 = shufflevector <128 x i8> %3247, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3249 = shl nsw i32 %output.s0.c.co112.us.us, 5
  %3250 = add i32 %3249, %t1066.us.us
  %3251 = add i32 %3250, %3516
  %3252 = getelementptr inbounds i8, i8* %23, i32 %3251
  %3253 = bitcast i8* %3252 to <32 x i8>*
  store <32 x i8> %3248, <32 x i8>* %3253, align 1, !tbaa !111
  %3254 = sext <32 x i32> %convolved313.sroa.47.13.us.us to <32 x i64>
  %a437.us.us = mul nsw <32 x i64> %3254, %3060
  %3255 = icmp slt <32 x i64> %a437.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3256 = select <32 x i1> %3255, <32 x i64> %a437.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3257 = add nsw <32 x i64> %3256, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a436.us.us = ashr <32 x i64> %3257, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3258 = icmp slt <32 x i64> %a436.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a435.us.us = select <32 x i1> %3258, <32 x i64> %a436.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3259 = icmp sgt <32 x i64> %a435.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3260 = select <32 x i1> %3259, <32 x i64> %a435.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3261 = trunc <32 x i64> %3260 to <32 x i32>
  %3262 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3263 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3264 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3261, <32 x i32> %3263, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3265 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3262, <1 x i32> zeroinitializer, <32 x i32> %3264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3266 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3265, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3267 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3266, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3268 = trunc <32 x i32> %3267 to <32 x i16>
  %3269 = shufflevector <32 x i16> %3268, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3270 = bitcast <64 x i16> %3269 to <32 x i32>
  %3271 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3270, <32 x i32> %3070) #11
  %3272 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3271, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3273 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3272, <32 x i32> zeroinitializer) #11
  %3274 = bitcast <32 x i32> %3273 to <64 x i16>
  %3275 = shufflevector <64 x i16> %3274, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3276 = trunc <32 x i16> %3275 to <32 x i8>
  %3277 = shufflevector <32 x i8> %3276, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3278 = bitcast <128 x i8> %3277 to <32 x i32>
  %3279 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3278, <32 x i32> %3073) #11
  %3280 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3279, <32 x i32> %3076) #11
  %3281 = bitcast <32 x i32> %3280 to <128 x i8>
  %3282 = shufflevector <128 x i8> %3281, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3283 = add i32 %3250, %3517
  %3284 = getelementptr inbounds i8, i8* %23, i32 %3283
  %3285 = bitcast i8* %3284 to <32 x i8>*
  store <32 x i8> %3282, <32 x i8>* %3285, align 1, !tbaa !111
  %3286 = sext <32 x i32> %convolved313.sroa.62.13.us.us to <32 x i64>
  %a441.us.us = mul nsw <32 x i64> %3286, %3060
  %3287 = icmp slt <32 x i64> %a441.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3288 = select <32 x i1> %3287, <32 x i64> %a441.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3289 = add nsw <32 x i64> %3288, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a440.us.us = ashr <32 x i64> %3289, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3290 = icmp slt <32 x i64> %a440.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a439.us.us = select <32 x i1> %3290, <32 x i64> %a440.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3291 = icmp sgt <32 x i64> %a439.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3292 = select <32 x i1> %3291, <32 x i64> %a439.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3293 = trunc <32 x i64> %3292 to <32 x i32>
  %3294 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3295 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3296 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3293, <32 x i32> %3295, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3297 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3294, <1 x i32> zeroinitializer, <32 x i32> %3296, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3298 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3297, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3299 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3298, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3300 = trunc <32 x i32> %3299 to <32 x i16>
  %3301 = shufflevector <32 x i16> %3300, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3302 = bitcast <64 x i16> %3301 to <32 x i32>
  %3303 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3302, <32 x i32> %3070) #11
  %3304 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3303, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3305 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3304, <32 x i32> zeroinitializer) #11
  %3306 = bitcast <32 x i32> %3305 to <64 x i16>
  %3307 = shufflevector <64 x i16> %3306, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3308 = trunc <32 x i16> %3307 to <32 x i8>
  %3309 = shufflevector <32 x i8> %3308, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3310 = bitcast <128 x i8> %3309 to <32 x i32>
  %3311 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3310, <32 x i32> %3073) #11
  %3312 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3311, <32 x i32> %3076) #11
  %3313 = bitcast <32 x i32> %3312 to <128 x i8>
  %3314 = shufflevector <128 x i8> %3313, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3315 = add i32 %3250, %3518
  %3316 = getelementptr inbounds i8, i8* %23, i32 %3315
  %3317 = bitcast i8* %3316 to <32 x i8>*
  store <32 x i8> %3314, <32 x i8>* %3317, align 1, !tbaa !111
  %3318 = sext <32 x i32> %convolved313.sroa.77.13.us.us to <32 x i64>
  %a445.us.us = mul nsw <32 x i64> %3318, %3060
  %3319 = icmp slt <32 x i64> %a445.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3320 = select <32 x i1> %3319, <32 x i64> %a445.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3321 = add nsw <32 x i64> %3320, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a444.us.us = ashr <32 x i64> %3321, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3322 = icmp slt <32 x i64> %a444.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a443.us.us = select <32 x i1> %3322, <32 x i64> %a444.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3323 = icmp sgt <32 x i64> %a443.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3324 = select <32 x i1> %3323, <32 x i64> %a443.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3325 = trunc <32 x i64> %3324 to <32 x i32>
  %3326 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3327 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3328 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3325, <32 x i32> %3327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3329 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3326, <1 x i32> zeroinitializer, <32 x i32> %3328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3330 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3329, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3331 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3330, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3332 = trunc <32 x i32> %3331 to <32 x i16>
  %3333 = shufflevector <32 x i16> %3332, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3334 = bitcast <64 x i16> %3333 to <32 x i32>
  %3335 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3334, <32 x i32> %3070) #11
  %3336 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3335, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3337 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3336, <32 x i32> zeroinitializer) #11
  %3338 = bitcast <32 x i32> %3337 to <64 x i16>
  %3339 = shufflevector <64 x i16> %3338, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3340 = trunc <32 x i16> %3339 to <32 x i8>
  %3341 = shufflevector <32 x i8> %3340, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3342 = bitcast <128 x i8> %3341 to <32 x i32>
  %3343 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3342, <32 x i32> %3073) #11
  %3344 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3343, <32 x i32> %3076) #11
  %3345 = bitcast <32 x i32> %3344 to <128 x i8>
  %3346 = shufflevector <128 x i8> %3345, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3347 = add i32 %3250, %3519
  %3348 = getelementptr inbounds i8, i8* %23, i32 %3347
  %3349 = bitcast i8* %3348 to <32 x i8>*
  store <32 x i8> %3346, <32 x i8>* %3349, align 1, !tbaa !111
  %3350 = sext <32 x i32> %convolved313.sroa.92.13.us.us to <32 x i64>
  %a449.us.us = mul nsw <32 x i64> %3350, %3060
  %3351 = icmp slt <32 x i64> %a449.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3352 = select <32 x i1> %3351, <32 x i64> %a449.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3353 = add nsw <32 x i64> %3352, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a448.us.us = ashr <32 x i64> %3353, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3354 = icmp slt <32 x i64> %a448.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a447.us.us = select <32 x i1> %3354, <32 x i64> %a448.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3355 = icmp sgt <32 x i64> %a447.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3356 = select <32 x i1> %3355, <32 x i64> %a447.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3357 = trunc <32 x i64> %3356 to <32 x i32>
  %3358 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3359 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3360 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3357, <32 x i32> %3359, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3361 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3358, <1 x i32> zeroinitializer, <32 x i32> %3360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3362 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3363 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3362, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3364 = trunc <32 x i32> %3363 to <32 x i16>
  %3365 = shufflevector <32 x i16> %3364, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3366 = bitcast <64 x i16> %3365 to <32 x i32>
  %3367 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3366, <32 x i32> %3070) #11
  %3368 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3367, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3369 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3368, <32 x i32> zeroinitializer) #11
  %3370 = bitcast <32 x i32> %3369 to <64 x i16>
  %3371 = shufflevector <64 x i16> %3370, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3372 = trunc <32 x i16> %3371 to <32 x i8>
  %3373 = shufflevector <32 x i8> %3372, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3374 = bitcast <128 x i8> %3373 to <32 x i32>
  %3375 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3374, <32 x i32> %3073) #11
  %3376 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3375, <32 x i32> %3076) #11
  %3377 = bitcast <32 x i32> %3376 to <128 x i8>
  %3378 = shufflevector <128 x i8> %3377, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3379 = add i32 %3250, %3520
  %3380 = getelementptr inbounds i8, i8* %23, i32 %3379
  %3381 = bitcast i8* %3380 to <32 x i8>*
  store <32 x i8> %3378, <32 x i8>* %3381, align 1, !tbaa !111
  %3382 = sext <32 x i32> %convolved313.sroa.102.13.us.us to <32 x i64>
  %a453.us.us = mul nsw <32 x i64> %3382, %3060
  %3383 = icmp slt <32 x i64> %a453.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3384 = select <32 x i1> %3383, <32 x i64> %a453.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3385 = add nsw <32 x i64> %3384, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a452.us.us = ashr <32 x i64> %3385, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3386 = icmp slt <32 x i64> %a452.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a451.us.us = select <32 x i1> %3386, <32 x i64> %a452.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3387 = icmp sgt <32 x i64> %a451.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3388 = select <32 x i1> %3387, <32 x i64> %a451.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3389 = trunc <32 x i64> %3388 to <32 x i32>
  %3390 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3391 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3392 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3389, <32 x i32> %3391, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3393 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3390, <1 x i32> zeroinitializer, <32 x i32> %3392, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3394 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3395 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3394, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3396 = trunc <32 x i32> %3395 to <32 x i16>
  %3397 = shufflevector <32 x i16> %3396, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3398 = bitcast <64 x i16> %3397 to <32 x i32>
  %3399 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3398, <32 x i32> %3070) #11
  %3400 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3399, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3401 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3400, <32 x i32> zeroinitializer) #11
  %3402 = bitcast <32 x i32> %3401 to <64 x i16>
  %3403 = shufflevector <64 x i16> %3402, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3404 = trunc <32 x i16> %3403 to <32 x i8>
  %3405 = shufflevector <32 x i8> %3404, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3406 = bitcast <128 x i8> %3405 to <32 x i32>
  %3407 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3406, <32 x i32> %3073) #11
  %3408 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3407, <32 x i32> %3076) #11
  %3409 = bitcast <32 x i32> %3408 to <128 x i8>
  %3410 = shufflevector <128 x i8> %3409, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3411 = add i32 %3250, %3521
  %3412 = getelementptr inbounds i8, i8* %23, i32 %3411
  %3413 = bitcast i8* %3412 to <32 x i8>*
  store <32 x i8> %3410, <32 x i8>* %3413, align 1, !tbaa !111
  %3414 = sext <32 x i32> %convolved313.sroa.112.13.us.us to <32 x i64>
  %a457.us.us = mul nsw <32 x i64> %3414, %3060
  %3415 = icmp slt <32 x i64> %a457.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3416 = select <32 x i1> %3415, <32 x i64> %a457.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3417 = add nsw <32 x i64> %3416, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a456.us.us = ashr <32 x i64> %3417, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3418 = icmp slt <32 x i64> %a456.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a455.us.us = select <32 x i1> %3418, <32 x i64> %a456.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3419 = icmp sgt <32 x i64> %a455.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3420 = select <32 x i1> %3419, <32 x i64> %a455.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3421 = trunc <32 x i64> %3420 to <32 x i32>
  %3422 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3423 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3424 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3421, <32 x i32> %3423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3425 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3422, <1 x i32> zeroinitializer, <32 x i32> %3424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3426 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3425, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3427 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3426, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3428 = trunc <32 x i32> %3427 to <32 x i16>
  %3429 = shufflevector <32 x i16> %3428, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3430 = bitcast <64 x i16> %3429 to <32 x i32>
  %3431 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3430, <32 x i32> %3070) #11
  %3432 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3431, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3433 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3432, <32 x i32> zeroinitializer) #11
  %3434 = bitcast <32 x i32> %3433 to <64 x i16>
  %3435 = shufflevector <64 x i16> %3434, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3436 = trunc <32 x i16> %3435 to <32 x i8>
  %3437 = shufflevector <32 x i8> %3436, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3438 = bitcast <128 x i8> %3437 to <32 x i32>
  %3439 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3438, <32 x i32> %3073) #11
  %3440 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3439, <32 x i32> %3076) #11
  %3441 = bitcast <32 x i32> %3440 to <128 x i8>
  %3442 = shufflevector <128 x i8> %3441, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3443 = add i32 %3250, %3522
  %3444 = getelementptr inbounds i8, i8* %23, i32 %3443
  %3445 = bitcast i8* %3444 to <32 x i8>*
  store <32 x i8> %3442, <32 x i8>* %3445, align 1, !tbaa !111
  %3446 = sext <32 x i32> %convolved313.sroa.122.13.us.us to <32 x i64>
  %a461.us.us = mul nsw <32 x i64> %3446, %3060
  %3447 = icmp slt <32 x i64> %a461.us.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3448 = select <32 x i1> %3447, <32 x i64> %a461.us.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3449 = add nsw <32 x i64> %3448, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a460.us.us = ashr <32 x i64> %3449, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3450 = icmp slt <32 x i64> %a460.us.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a459.us.us = select <32 x i1> %3450, <32 x i64> %a460.us.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3451 = icmp sgt <32 x i64> %a459.us.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3452 = select <32 x i1> %3451, <32 x i64> %a459.us.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3453 = trunc <32 x i64> %3452 to <32 x i32>
  %3454 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3066, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3455 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3065, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3456 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %3453, <32 x i32> %3455, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3457 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %3454, <1 x i32> zeroinitializer, <32 x i32> %3456, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3458 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3457, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3459 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %3458, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %3460 = trunc <32 x i32> %3459 to <32 x i16>
  %3461 = shufflevector <32 x i16> %3460, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3462 = bitcast <64 x i16> %3461 to <32 x i32>
  %3463 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %3462, <32 x i32> %3070) #11
  %3464 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %3463, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %3465 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %3464, <32 x i32> zeroinitializer) #11
  %3466 = bitcast <32 x i32> %3465 to <64 x i16>
  %3467 = shufflevector <64 x i16> %3466, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3468 = trunc <32 x i16> %3467 to <32 x i8>
  %3469 = shufflevector <32 x i8> %3468, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3470 = bitcast <128 x i8> %3469 to <32 x i32>
  %3471 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %3470, <32 x i32> %3073) #11
  %3472 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %3471, <32 x i32> %3076) #11
  %3473 = bitcast <32 x i32> %3472 to <128 x i8>
  %3474 = shufflevector <128 x i8> %3473, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %3475 = add i32 %3250, %3523
  %3476 = getelementptr inbounds i8, i8* %23, i32 %3475
  %3477 = bitcast i8* %3476 to <32 x i8>*
  store <32 x i8> %3474, <32 x i8>* %3477, align 1, !tbaa !111
  %3478 = add nuw nsw i32 %output.s0.c.co112.us.us, 1
  %.not349.us.us = icmp eq i32 %3478, %3056
  br i1 %.not349.us.us, label %"end for output.s0.c.co111.us.us", label %"for output.s0.c.co110.us.us"

"end for output.s0.c.co111.us.us":                ; preds = %"consume convolved126.us.us", %"consume sum_input109.us.us"
  %3479 = add nuw nsw i32 %output.s0.x.xo84.us.us, 1
  %.not348.us.us = icmp eq i32 %3479, %3052
  br i1 %.not348.us.us, label %"end for output.s0.x.xo83.loopexit.us.us", label %"for output.s0.x.xo82.us.us"

"for convolved.s1.r19$y117.preheader.us.us":      ; preds = %after_bb114.us.us
  %3480 = mul nsw i32 %output.s0.c.co112.us.us, %8
  br i1 %3054, label %"for convolved.s1.r19$y117.us.us.us", label %"consume convolved126.us.us", !prof !96

"for sum_input.s1.r19$x97.preheader.us.us":       ; preds = %"for sum_input.s1.r19$y94.us.us"
  %3481 = mul nsw i32 %"sum_input.s1.r19$y96.us.us", %dilation_y
  %3482 = add nsw i32 %3481, %3090
  %3483 = mul nsw i32 %3482, %19
  %t1069.us.us = add i32 %3085, %3483
  br i1 %3080, label %"end for sum_input.s1.r19$x98.us.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x97.us.us"

"for output.s0.c.co110.preheader.us.us":          ; preds = %"consume sum_input109.us.us"
  %sum_input187312.sroa.0.0.vec.extract657.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 0
  %3484 = mul nsw i32 %sum_input187312.sroa.0.0.vec.extract657.us.us, %168
  %3485 = insertelement <1 x i32> poison, i32 %3484, i32 0
  %sum_input187312.sroa.0.4.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 1
  %3486 = mul nsw i32 %sum_input187312.sroa.0.4.vec.extract.us.us, %168
  %3487 = insertelement <1 x i32> poison, i32 %3486, i32 0
  %sum_input187312.sroa.0.8.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 2
  %3488 = mul nsw i32 %sum_input187312.sroa.0.8.vec.extract.us.us, %168
  %3489 = insertelement <1 x i32> poison, i32 %3488, i32 0
  %sum_input187312.sroa.0.12.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 3
  %3490 = mul nsw i32 %sum_input187312.sroa.0.12.vec.extract.us.us, %168
  %3491 = insertelement <1 x i32> poison, i32 %3490, i32 0
  %sum_input187312.sroa.0.16.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 4
  %3492 = mul nsw i32 %sum_input187312.sroa.0.16.vec.extract.us.us, %168
  %3493 = insertelement <1 x i32> poison, i32 %3492, i32 0
  %sum_input187312.sroa.0.20.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 5
  %3494 = mul nsw i32 %sum_input187312.sroa.0.20.vec.extract.us.us, %168
  %3495 = insertelement <1 x i32> poison, i32 %3494, i32 0
  %sum_input187312.sroa.0.24.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 6
  %3496 = mul nsw i32 %sum_input187312.sroa.0.24.vec.extract.us.us, %168
  %3497 = insertelement <1 x i32> poison, i32 %3496, i32 0
  %sum_input187312.sroa.0.28.vec.extract.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.20.us.us, i32 7
  %3498 = mul nsw i32 %sum_input187312.sroa.0.28.vec.extract.us.us, %168
  %3499 = insertelement <1 x i32> poison, i32 %3498, i32 0
  %3500 = add nsw i32 %output.s0.x.x.base.s85.us.us, %25
  %3501 = add nsw i32 %3500, 7
  %3502 = mul nsw i32 %3501, %stride_x
  %3503 = add nsw i32 %3500, 6
  %3504 = mul nsw i32 %3503, %stride_x
  %3505 = add nsw i32 %3500, 5
  %3506 = mul nsw i32 %3505, %stride_x
  %3507 = add nsw i32 %3500, 4
  %3508 = mul nsw i32 %3507, %stride_x
  %3509 = add nsw i32 %3500, 3
  %3510 = mul nsw i32 %3509, %stride_x
  %3511 = add nsw i32 %3500, 2
  %3512 = mul nsw i32 %3511, %stride_x
  %3513 = add nsw i32 %3500, 1
  %3514 = mul nsw i32 %3513, %stride_x
  %3515 = mul nsw i32 %3500, %stride_x
  %3516 = mul nsw i32 %3500, %27
  %3517 = mul nsw i32 %3513, %27
  %3518 = mul nsw i32 %3511, %27
  %3519 = mul nsw i32 %3509, %27
  %3520 = mul nsw i32 %3507, %27
  %3521 = mul nsw i32 %3505, %27
  %3522 = mul nsw i32 %3503, %27
  %3523 = mul nsw i32 %3501, %27
  br label %"for output.s0.c.co110.us.us"

"for sum_input.s1.r19$y94.preheader.us.us":       ; preds = %then_bb92.us.us
  %3524 = add nsw i32 %output.s0.x.x.base.s85.us.us, %25
  %3525 = sub i32 %3524, %16
  br label %"for sum_input.s1.r19$y94.us.us"

"for sum_input.s1.r19$y100.preheader.us.us":      ; preds = %next_bb93.us.us
  %3526 = add nsw i32 %output.s0.x.x.base.s85.us.us, %25
  %3527 = mul nsw i32 %3526, %stride_x
  br i1 %brmerge1311.demorgan, label %"for sum_input.s1.r19$y100.us.us.us.us", label %"consume sum_input109.us.us", !prof !103

"end for output.s0.x.xo83.loopexit.us.us":        ; preds = %"end for output.s0.c.co111.us.us"
  %3528 = add nuw nsw i32 %output.s0.y.rebased81.us.us, 1
  %.not347.us.us = icmp eq i32 %3528, %29
  br i1 %.not347.us.us, label %"end for output.s0.y.rebased80.loopexit.us", label %"for output.s0.y.rebased79.us.us"

"for sum_input.s1.r19$y100.us.us.us.us":          ; preds = %"for sum_input.s1.r19$y100.preheader.us.us", %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us"
  %sum_input187312.sroa.0.15.us.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us" ], [ %sum_input187312.sroa.0.0.vecblend.us.us, %"for sum_input.s1.r19$y100.preheader.us.us" ]
  %"sum_input.s1.r19$y102.us.us.us.us" = phi i32 [ %3719, %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y100.preheader.us.us" ]
  %3529 = mul nsw i32 %"sum_input.s1.r19$y102.us.us.us.us", %dilation_y
  %t1071.s.us.us.us.us = add nsw i32 %3529, %3090
  %3530 = mul nsw i32 %t1071.s.us.us.us.us, %19
  br label %"for sum_input.s1.r19$x103.us.us.us.us.us"

"for sum_input.s1.r19$x103.us.us.us.us.us":       ; preds = %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us", %"for sum_input.s1.r19$y100.us.us.us.us"
  %sum_input187312.sroa.0.16.us.us.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa, %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us" ], [ %sum_input187312.sroa.0.15.us.us.us.us, %"for sum_input.s1.r19$y100.us.us.us.us" ]
  %"sum_input.s1.r19$x105.us.us.us.us.us" = phi i32 [ %3718, %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y100.us.us.us.us" ]
  %3531 = mul nsw i32 %"sum_input.s1.r19$x105.us.us.us.us.us", %dilation_x
  %t1072.s.us.us.us.us.us = add nsw i32 %3531, %3527
  %t1231.us.us.us.us.us = mul nsw i32 %t1072.s.us.us.us.us.us, %17
  %3532 = add i32 %t1231.us.us.us.us.us, %3530
  %t1073.us.us.us.us.us = sub i32 %3532, %t1037
  %3533 = add i32 %t1073.us.us.us.us.us, %3084
  %t1045.us.us.us.us.us = add i32 %3532, %3049
  %3534 = sub i32 %t1045.us.us.us.us.us, %3036
  %t1074.us.us.us.us.us = sub i32 %3534, %3037
  %3535 = add i32 %t1074.us.us.us.us.us, %3084
  %3536 = add i32 %3532, %3047
  %3537 = sub i32 %3536, %3077
  %t1075.us.us.us.us.us = sub i32 %3537, %3037
  %3538 = add i32 %t1075.us.us.us.us.us, %3084
  %3539 = add i32 %3532, %3046
  %3540 = sub i32 %3539, %3077
  %t1076.us.us.us.us.us = sub i32 %3540, %3037
  %3541 = add i32 %t1076.us.us.us.us.us, %3084
  %3542 = add i32 %3532, %3045
  %3543 = sub i32 %3542, %3077
  %t1077.us.us.us.us.us = sub i32 %3543, %3037
  %3544 = add i32 %t1077.us.us.us.us.us, %3084
  %3545 = add i32 %3532, %3044
  %3546 = sub i32 %3545, %3077
  %t1078.us.us.us.us.us = sub i32 %3546, %3037
  %3547 = add i32 %t1078.us.us.us.us.us, %3084
  %3548 = add i32 %3532, %3043
  %3549 = sub i32 %3548, %3077
  %t1079.us.us.us.us.us = sub i32 %3549, %3037
  %3550 = add i32 %t1079.us.us.us.us.us, %3084
  %3551 = add i32 %3532, %3042
  %3552 = sub i32 %3551, %3077
  %t1080.us.us.us.us.us = sub i32 %3552, %3037
  %3553 = add i32 %t1080.us.us.us.us.us, %3084
  br i1 %3079, label %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124106.us.us.us.us.us"

"for sum_input.s1.r19$z.r124106.us.us.us.us.us":  ; preds = %"for sum_input.s1.r19$x103.us.us.us.us.us", %"for sum_input.s1.r19$z.r124106.us.us.us.us.us"
  %sum_input187312.sroa.0.18.us.us.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ], [ %sum_input187312.sroa.0.16.us.us.us.us.us, %"for sum_input.s1.r19$x103.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r124108.us.us.us.us.us" = phi i32 [ %3663, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$x103.us.us.us.us.us" ]
  %niter1493 = phi i32 [ %niter1493.nsub.1, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ], [ %unroll_iter1492, %"for sum_input.s1.r19$x103.us.us.us.us.us" ]
  %3554 = shl nsw i32 %"sum_input.s1.r19$z.r124108.us.us.us.us.us", 2
  %3555 = add i32 %3533, %3554
  %3556 = getelementptr inbounds i8, i8* %13, i32 %3555
  %3557 = bitcast i8* %3556 to <4 x i8>*
  %3558 = load <4 x i8>, <4 x i8>* %3557, align 4, !tbaa !108
  %3559 = add i32 %3535, %3554
  %3560 = getelementptr inbounds i8, i8* %13, i32 %3559
  %3561 = bitcast i8* %3560 to <4 x i8>*
  %3562 = load <4 x i8>, <4 x i8>* %3561, align 4, !tbaa !108
  %3563 = add i32 %3538, %3554
  %3564 = getelementptr inbounds i8, i8* %13, i32 %3563
  %3565 = bitcast i8* %3564 to <4 x i8>*
  %3566 = load <4 x i8>, <4 x i8>* %3565, align 4, !tbaa !108
  %3567 = add i32 %3541, %3554
  %3568 = getelementptr inbounds i8, i8* %13, i32 %3567
  %3569 = bitcast i8* %3568 to <4 x i8>*
  %3570 = load <4 x i8>, <4 x i8>* %3569, align 4, !tbaa !108
  %3571 = add i32 %3544, %3554
  %3572 = getelementptr inbounds i8, i8* %13, i32 %3571
  %3573 = bitcast i8* %3572 to <4 x i8>*
  %3574 = load <4 x i8>, <4 x i8>* %3573, align 4, !tbaa !108
  %3575 = add i32 %3547, %3554
  %3576 = getelementptr inbounds i8, i8* %13, i32 %3575
  %3577 = bitcast i8* %3576 to <4 x i8>*
  %3578 = load <4 x i8>, <4 x i8>* %3577, align 4, !tbaa !108
  %3579 = add i32 %3550, %3554
  %3580 = getelementptr inbounds i8, i8* %13, i32 %3579
  %3581 = bitcast i8* %3580 to <4 x i8>*
  %3582 = load <4 x i8>, <4 x i8>* %3581, align 4, !tbaa !108
  %3583 = add i32 %3553, %3554
  %3584 = getelementptr inbounds i8, i8* %13, i32 %3583
  %3585 = bitcast i8* %3584 to <4 x i8>*
  %3586 = load <4 x i8>, <4 x i8>* %3585, align 4, !tbaa !108
  %3587 = shufflevector <4 x i8> %3558, <4 x i8> %3562, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3588 = shufflevector <4 x i8> %3566, <4 x i8> %3570, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3589 = shufflevector <4 x i8> %3574, <4 x i8> %3578, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3590 = shufflevector <4 x i8> %3582, <4 x i8> %3586, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3591 = shufflevector <8 x i8> %3587, <8 x i8> %3588, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3592 = shufflevector <8 x i8> %3589, <8 x i8> %3590, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3593 = shufflevector <16 x i8> %3591, <16 x i8> %3592, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1233.us.us.us.us.us = zext <32 x i8> %3593 to <32 x i16>
  %3594 = shufflevector <32 x i16> %t1233.us.us.us.us.us, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3595 = bitcast <64 x i16> %3594 to <32 x i32>
  %3596 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3595)
  %3597 = bitcast <32 x i32> %3596 to <64 x i16>
  %3598 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3595)
  %3599 = bitcast <32 x i32> %3598 to <64 x i16>
  %3600 = add <64 x i16> %3599, %3597
  %3601 = shufflevector <64 x i16> %3600, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1232.us.us.us.us.us = zext <16 x i16> %3601 to <16 x i32>
  %3602 = shufflevector <16 x i32> %t1232.us.us.us.us.us, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3603 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3602, i32 -4)
  %3604 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3603)
  %3605 = add nsw <32 x i32> %3604, %sum_input187312.sroa.0.18.us.us.us.us.us
  %3606 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3603)
  %3607 = add nsw <32 x i32> %3605, %3606
  %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us = shufflevector <32 x i32> %3607, <32 x i32> %sum_input187312.sroa.0.18.us.us.us.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3608 = shl i32 %"sum_input.s1.r19$z.r124108.us.us.us.us.us", 2
  %3609 = or i32 %3608, 4
  %3610 = add i32 %3533, %3609
  %3611 = getelementptr inbounds i8, i8* %13, i32 %3610
  %3612 = bitcast i8* %3611 to <4 x i8>*
  %3613 = load <4 x i8>, <4 x i8>* %3612, align 4, !tbaa !108
  %3614 = add i32 %3535, %3609
  %3615 = getelementptr inbounds i8, i8* %13, i32 %3614
  %3616 = bitcast i8* %3615 to <4 x i8>*
  %3617 = load <4 x i8>, <4 x i8>* %3616, align 4, !tbaa !108
  %3618 = add i32 %3538, %3609
  %3619 = getelementptr inbounds i8, i8* %13, i32 %3618
  %3620 = bitcast i8* %3619 to <4 x i8>*
  %3621 = load <4 x i8>, <4 x i8>* %3620, align 4, !tbaa !108
  %3622 = add i32 %3541, %3609
  %3623 = getelementptr inbounds i8, i8* %13, i32 %3622
  %3624 = bitcast i8* %3623 to <4 x i8>*
  %3625 = load <4 x i8>, <4 x i8>* %3624, align 4, !tbaa !108
  %3626 = add i32 %3544, %3609
  %3627 = getelementptr inbounds i8, i8* %13, i32 %3626
  %3628 = bitcast i8* %3627 to <4 x i8>*
  %3629 = load <4 x i8>, <4 x i8>* %3628, align 4, !tbaa !108
  %3630 = add i32 %3547, %3609
  %3631 = getelementptr inbounds i8, i8* %13, i32 %3630
  %3632 = bitcast i8* %3631 to <4 x i8>*
  %3633 = load <4 x i8>, <4 x i8>* %3632, align 4, !tbaa !108
  %3634 = add i32 %3550, %3609
  %3635 = getelementptr inbounds i8, i8* %13, i32 %3634
  %3636 = bitcast i8* %3635 to <4 x i8>*
  %3637 = load <4 x i8>, <4 x i8>* %3636, align 4, !tbaa !108
  %3638 = add i32 %3553, %3609
  %3639 = getelementptr inbounds i8, i8* %13, i32 %3638
  %3640 = bitcast i8* %3639 to <4 x i8>*
  %3641 = load <4 x i8>, <4 x i8>* %3640, align 4, !tbaa !108
  %3642 = shufflevector <4 x i8> %3613, <4 x i8> %3617, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3643 = shufflevector <4 x i8> %3621, <4 x i8> %3625, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3644 = shufflevector <4 x i8> %3629, <4 x i8> %3633, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3645 = shufflevector <4 x i8> %3637, <4 x i8> %3641, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3646 = shufflevector <8 x i8> %3642, <8 x i8> %3643, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3647 = shufflevector <8 x i8> %3644, <8 x i8> %3645, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3648 = shufflevector <16 x i8> %3646, <16 x i8> %3647, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1233.us.us.us.us.us.1 = zext <32 x i8> %3648 to <32 x i16>
  %3649 = shufflevector <32 x i16> %t1233.us.us.us.us.us.1, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3650 = bitcast <64 x i16> %3649 to <32 x i32>
  %3651 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3650)
  %3652 = bitcast <32 x i32> %3651 to <64 x i16>
  %3653 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3650)
  %3654 = bitcast <32 x i32> %3653 to <64 x i16>
  %3655 = add <64 x i16> %3654, %3652
  %3656 = shufflevector <64 x i16> %3655, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1232.us.us.us.us.us.1 = zext <16 x i16> %3656 to <16 x i32>
  %3657 = shufflevector <16 x i32> %t1232.us.us.us.us.us.1, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3658 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3657, i32 -4)
  %3659 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3658)
  %3660 = add nsw <32 x i32> %3659, %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us
  %3661 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3658)
  %3662 = add nsw <32 x i32> %3660, %3661
  %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.1 = shufflevector <32 x i32> %3662, <32 x i32> %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  %3663 = add nuw nsw i32 %"sum_input.s1.r19$z.r124108.us.us.us.us.us", 2
  %niter1493.nsub.1 = add i32 %niter1493, -2
  %niter1493.ncmp.1 = icmp eq i32 %niter1493.nsub.1, 0
  br i1 %niter1493.ncmp.1, label %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124106.us.us.us.us.us"

"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa": ; preds = %"for sum_input.s1.r19$z.r124106.us.us.us.us.us", %"for sum_input.s1.r19$x103.us.us.us.us.us"
  %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x103.us.us.us.us.us" ], [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ]
  %sum_input187312.sroa.0.18.us.us.us.us.us.unr = phi <32 x i32> [ %sum_input187312.sroa.0.16.us.us.us.us.us, %"for sum_input.s1.r19$x103.us.us.us.us.us" ], [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.1, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ]
  %"sum_input.s1.r19$z.r124108.us.us.us.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x103.us.us.us.us.us" ], [ %3663, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us" ]
  br i1 %lcmp.mod1491.not, label %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us", label %"for sum_input.s1.r19$z.r124106.us.us.us.us.us.epil"

"for sum_input.s1.r19$z.r124106.us.us.us.us.us.epil": ; preds = %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa"
  %3664 = shl nsw i32 %"sum_input.s1.r19$z.r124108.us.us.us.us.us.unr", 2
  %3665 = add i32 %3533, %3664
  %3666 = getelementptr inbounds i8, i8* %13, i32 %3665
  %3667 = bitcast i8* %3666 to <4 x i8>*
  %3668 = load <4 x i8>, <4 x i8>* %3667, align 4, !tbaa !108
  %3669 = add i32 %3535, %3664
  %3670 = getelementptr inbounds i8, i8* %13, i32 %3669
  %3671 = bitcast i8* %3670 to <4 x i8>*
  %3672 = load <4 x i8>, <4 x i8>* %3671, align 4, !tbaa !108
  %3673 = add i32 %3538, %3664
  %3674 = getelementptr inbounds i8, i8* %13, i32 %3673
  %3675 = bitcast i8* %3674 to <4 x i8>*
  %3676 = load <4 x i8>, <4 x i8>* %3675, align 4, !tbaa !108
  %3677 = add i32 %3541, %3664
  %3678 = getelementptr inbounds i8, i8* %13, i32 %3677
  %3679 = bitcast i8* %3678 to <4 x i8>*
  %3680 = load <4 x i8>, <4 x i8>* %3679, align 4, !tbaa !108
  %3681 = add i32 %3544, %3664
  %3682 = getelementptr inbounds i8, i8* %13, i32 %3681
  %3683 = bitcast i8* %3682 to <4 x i8>*
  %3684 = load <4 x i8>, <4 x i8>* %3683, align 4, !tbaa !108
  %3685 = add i32 %3547, %3664
  %3686 = getelementptr inbounds i8, i8* %13, i32 %3685
  %3687 = bitcast i8* %3686 to <4 x i8>*
  %3688 = load <4 x i8>, <4 x i8>* %3687, align 4, !tbaa !108
  %3689 = add i32 %3550, %3664
  %3690 = getelementptr inbounds i8, i8* %13, i32 %3689
  %3691 = bitcast i8* %3690 to <4 x i8>*
  %3692 = load <4 x i8>, <4 x i8>* %3691, align 4, !tbaa !108
  %3693 = add i32 %3553, %3664
  %3694 = getelementptr inbounds i8, i8* %13, i32 %3693
  %3695 = bitcast i8* %3694 to <4 x i8>*
  %3696 = load <4 x i8>, <4 x i8>* %3695, align 4, !tbaa !108
  %3697 = shufflevector <4 x i8> %3668, <4 x i8> %3672, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3698 = shufflevector <4 x i8> %3676, <4 x i8> %3680, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3699 = shufflevector <4 x i8> %3684, <4 x i8> %3688, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3700 = shufflevector <4 x i8> %3692, <4 x i8> %3696, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3701 = shufflevector <8 x i8> %3697, <8 x i8> %3698, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3702 = shufflevector <8 x i8> %3699, <8 x i8> %3700, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %3703 = shufflevector <16 x i8> %3701, <16 x i8> %3702, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %t1233.us.us.us.us.us.epil = zext <32 x i8> %3703 to <32 x i16>
  %3704 = shufflevector <32 x i16> %t1233.us.us.us.us.us.epil, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3705 = bitcast <64 x i16> %3704 to <32 x i32>
  %3706 = call <32 x i32> @llvm.hexagon.V6.vpackeh.128B(<32 x i32> undef, <32 x i32> %3705)
  %3707 = bitcast <32 x i32> %3706 to <64 x i16>
  %3708 = call <32 x i32> @llvm.hexagon.V6.vpackoh.128B(<32 x i32> undef, <32 x i32> %3705)
  %3709 = bitcast <32 x i32> %3708 to <64 x i16>
  %3710 = add <64 x i16> %3709, %3707
  %3711 = shufflevector <64 x i16> %3710, <64 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %t1232.us.us.us.us.us.epil = zext <16 x i16> %3711 to <16 x i32>
  %3712 = shufflevector <16 x i32> %t1232.us.us.us.us.us.epil, <16 x i32> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %3713 = call <64 x i32> @llvm.hexagon.V6.vdealvdd.128B(<32 x i32> undef, <32 x i32> %3712, i32 -4)
  %3714 = call <32 x i32> @llvm.hexagon.V6.lo.128B(<64 x i32> %3713)
  %3715 = add nsw <32 x i32> %3714, %sum_input187312.sroa.0.18.us.us.us.us.us.unr
  %3716 = call <32 x i32> @llvm.hexagon.V6.hi.128B(<64 x i32> %3713)
  %3717 = add nsw <32 x i32> %3715, %3716
  %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.epil = shufflevector <32 x i32> %3717, <32 x i32> %sum_input187312.sroa.0.18.us.us.us.us.us.unr, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 40, i32 41, i32 42, i32 43, i32 44, i32 45, i32 46, i32 47, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55, i32 56, i32 57, i32 58, i32 59, i32 60, i32 61, i32 62, i32 63>
  br label %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us"

"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa", %"for sum_input.s1.r19$z.r124106.us.us.us.us.us.epil"
  %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa = phi <32 x i32> [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.lcssa.ph, %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us.unr-lcssa" ], [ %sum_input187312.sroa.0.0.vecblend642.us.us.us.us.us.epil, %"for sum_input.s1.r19$z.r124106.us.us.us.us.us.epil" ]
  %3718 = add nuw nsw i32 %"sum_input.s1.r19$x105.us.us.us.us.us", 1
  %.not354.us.us.us.us.us = icmp eq i32 %3718, %9
  br i1 %.not354.us.us.us.us.us, label %"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us", label %"for sum_input.s1.r19$x103.us.us.us.us.us"

"end for sum_input.s1.r19$x104.loopexit.split.us.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r124107.loopexit.us.us.us.us.us"
  %3719 = add nuw nsw i32 %"sum_input.s1.r19$y102.us.us.us.us", 1
  %.not353.us.us.us.us = icmp eq i32 %3719, %11
  br i1 %.not353.us.us.us.us, label %"consume sum_input109.us.us", label %"for sum_input.s1.r19$y100.us.us.us.us"

"for convolved.s1.r19$y117.us.us.us":             ; preds = %"for convolved.s1.r19$y117.preheader.us.us", %"end for convolved.s1.r19$x121.loopexit.us.us.us"
  %convolved313.sroa.122.8.us.us.us = phi <32 x i32> [ %.us-phi991.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.122.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.112.8.us.us.us = phi <32 x i32> [ %.us-phi992.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.112.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.102.8.us.us.us = phi <32 x i32> [ %.us-phi993.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.102.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.92.8.us.us.us = phi <32 x i32> [ %.us-phi994.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.92.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.77.8.us.us.us = phi <32 x i32> [ %.us-phi995.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.77.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.62.8.us.us.us = phi <32 x i32> [ %.us-phi996.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.62.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.47.8.us.us.us = phi <32 x i32> [ %.us-phi997.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.47.7.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %convolved313.sroa.0.22.us.us.us = phi <32 x i32> [ %.us-phi998.us.us.us, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ %convolved313.sroa.0.21.us.us, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %"convolved.s1.r19$y119.us.us.us" = phi i32 [ %3724, %"end for convolved.s1.r19$x121.loopexit.us.us.us" ], [ 0, %"for convolved.s1.r19$y117.preheader.us.us" ]
  %3720 = mul nsw i32 %"convolved.s1.r19$y119.us.us.us", %dilation_y
  %3721 = add nsw i32 %3720, %3090
  %3722 = mul nsw i32 %3721, %19
  %t1106.us.us.us = add nsw i32 %3722, %3086
  %3723 = mul nsw i32 %"convolved.s1.r19$y119.us.us.us", %12
  %t1107.us.us.us = add nsw i32 %3723, %3480
  br i1 %3055, label %"for convolved.s1.r19$x120.us.us.us.us", label %"end for convolved.s1.r19$x121.loopexit.us.us.us", !prof !96

"end for convolved.s1.r19$x121.loopexit.us.us.us": ; preds = %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us", %"for convolved.s1.r19$y117.us.us.us"
  %.us-phi991.us.us.us = phi <32 x i32> [ %convolved313.sroa.122.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3797, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi992.us.us.us = phi <32 x i32> [ %convolved313.sroa.112.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3790, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi993.us.us.us = phi <32 x i32> [ %convolved313.sroa.102.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3783, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi994.us.us.us = phi <32 x i32> [ %convolved313.sroa.92.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3776, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi995.us.us.us = phi <32 x i32> [ %convolved313.sroa.77.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3769, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi996.us.us.us = phi <32 x i32> [ %convolved313.sroa.62.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3762, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi997.us.us.us = phi <32 x i32> [ %convolved313.sroa.47.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3755, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %.us-phi998.us.us.us = phi <32 x i32> [ %convolved313.sroa.0.22.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ], [ %3748, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ]
  %3724 = add nuw nsw i32 %"convolved.s1.r19$y119.us.us.us", 1
  %.not350.us.us.us = icmp eq i32 %3724, %11
  br i1 %.not350.us.us.us, label %"consume convolved126.us.us", label %"for convolved.s1.r19$y117.us.us.us"

"for convolved.s1.r19$x120.us.us.us.us":          ; preds = %"for convolved.s1.r19$y117.us.us.us", %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us"
  %convolved313.sroa.122.9.us.us.us.us = phi <32 x i32> [ %3797, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.122.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.112.9.us.us.us.us = phi <32 x i32> [ %3790, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.112.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.102.9.us.us.us.us = phi <32 x i32> [ %3783, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.102.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.92.9.us.us.us.us = phi <32 x i32> [ %3776, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.92.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.77.9.us.us.us.us = phi <32 x i32> [ %3769, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.77.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.62.9.us.us.us.us = phi <32 x i32> [ %3762, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.62.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.47.9.us.us.us.us = phi <32 x i32> [ %3755, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.47.8.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %convolved313.sroa.0.23.us.us.us.us = phi <32 x i32> [ %3748, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ %convolved313.sroa.0.22.us.us.us, %"for convolved.s1.r19$y117.us.us.us" ]
  %"convolved.s1.r19$x122.us.us.us.us" = phi i32 [ %3799, %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y117.us.us.us" ]
  %3725 = mul nsw i32 %"convolved.s1.r19$x122.us.us.us.us", %dilation_x
  %t1116.s.us.us.us.us = add nsw i32 %3725, %3502
  %t1115.s.us.us.us.us = add nsw i32 %3725, %3504
  %t1114.s.us.us.us.us = add nsw i32 %3725, %3506
  %t1113.s.us.us.us.us = add nsw i32 %3725, %3508
  %t1112.s.us.us.us.us = add nsw i32 %3725, %3510
  %t1111.s.us.us.us.us = add nsw i32 %3725, %3512
  %t1110.s.us.us.us.us = add nsw i32 %3725, %3514
  %t1108.s.us.us.us.us = add nsw i32 %3725, %3515
  %3726 = mul nsw i32 %t1108.s.us.us.us.us, %17
  %3727 = mul nsw i32 %"convolved.s1.r19$x122.us.us.us.us", %10
  %3728 = add nsw i32 %t1107.us.us.us, %3727
  %3729 = mul nsw i32 %t1110.s.us.us.us.us, %17
  %3730 = mul nsw i32 %t1111.s.us.us.us.us, %17
  %3731 = mul nsw i32 %t1112.s.us.us.us.us, %17
  %3732 = mul nsw i32 %t1113.s.us.us.us.us, %17
  %3733 = mul nsw i32 %t1114.s.us.us.us.us, %17
  %3734 = mul nsw i32 %t1115.s.us.us.us.us, %17
  %3735 = mul nsw i32 %t1116.s.us.us.us.us, %17
  br label %"for convolved.s1.r19$z.r124123.us.us.us.us"

"for convolved.s1.r19$z.r124123.us.us.us.us":     ; preds = %"for convolved.s1.r19$z.r124123.us.us.us.us", %"for convolved.s1.r19$x120.us.us.us.us"
  %convolved313.sroa.122.11.us.us.us.us = phi <32 x i32> [ %3797, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.122.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.112.11.us.us.us.us = phi <32 x i32> [ %3790, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.112.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.102.11.us.us.us.us = phi <32 x i32> [ %3783, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.102.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.92.11.us.us.us.us = phi <32 x i32> [ %3776, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.92.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.77.11.us.us.us.us = phi <32 x i32> [ %3769, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.77.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.62.11.us.us.us.us = phi <32 x i32> [ %3762, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.62.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.47.11.us.us.us.us = phi <32 x i32> [ %3755, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.47.9.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %convolved313.sroa.0.25.us.us.us.us = phi <32 x i32> [ %3748, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ %convolved313.sroa.0.23.us.us.us.us, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %"convolved.s1.r19$z.r124125.us.us.us.us" = phi i32 [ %3798, %"for convolved.s1.r19$z.r124123.us.us.us.us" ], [ 0, %"for convolved.s1.r19$x120.us.us.us.us" ]
  %3736 = shl nsw i32 %"convolved.s1.r19$z.r124125.us.us.us.us", 2
  %3737 = add i32 %3736, %t1106.us.us.us
  %3738 = add i32 %3737, %3726
  %3739 = getelementptr inbounds i8, i8* %13, i32 %3738
  %3740 = bitcast i8* %3739 to <4 x i8>*
  %3741 = load <4 x i8>, <4 x i8>* %3740, align 4, !tbaa !108
  %3742 = shl nsw i32 %"convolved.s1.r19$z.r124125.us.us.us.us", 7
  %3743 = add nsw i32 %3728, %3742
  %3744 = getelementptr inbounds i8, i8* %5, i32 %3743
  %3745 = bitcast i8* %3744 to <128 x i8>*
  %3746 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3747 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3741, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3748 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.0.25.us.us.us.us, <128 x i8> %3746, <32 x i32> %3747, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3749 = add i32 %3737, %3729
  %3750 = getelementptr inbounds i8, i8* %13, i32 %3749
  %3751 = bitcast i8* %3750 to <4 x i8>*
  %3752 = load <4 x i8>, <4 x i8>* %3751, align 4, !tbaa !108
  %3753 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3754 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3752, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3755 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.47.11.us.us.us.us, <128 x i8> %3753, <32 x i32> %3754, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3756 = add i32 %3737, %3730
  %3757 = getelementptr inbounds i8, i8* %13, i32 %3756
  %3758 = bitcast i8* %3757 to <4 x i8>*
  %3759 = load <4 x i8>, <4 x i8>* %3758, align 4, !tbaa !108
  %3760 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3761 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3759, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3762 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.62.11.us.us.us.us, <128 x i8> %3760, <32 x i32> %3761, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3763 = add i32 %3737, %3731
  %3764 = getelementptr inbounds i8, i8* %13, i32 %3763
  %3765 = bitcast i8* %3764 to <4 x i8>*
  %3766 = load <4 x i8>, <4 x i8>* %3765, align 4, !tbaa !108
  %3767 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3768 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3766, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3769 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.77.11.us.us.us.us, <128 x i8> %3767, <32 x i32> %3768, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3770 = add i32 %3737, %3732
  %3771 = getelementptr inbounds i8, i8* %13, i32 %3770
  %3772 = bitcast i8* %3771 to <4 x i8>*
  %3773 = load <4 x i8>, <4 x i8>* %3772, align 4, !tbaa !108
  %3774 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3775 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3773, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3776 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.92.11.us.us.us.us, <128 x i8> %3774, <32 x i32> %3775, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3777 = add i32 %3737, %3733
  %3778 = getelementptr inbounds i8, i8* %13, i32 %3777
  %3779 = bitcast i8* %3778 to <4 x i8>*
  %3780 = load <4 x i8>, <4 x i8>* %3779, align 4, !tbaa !108
  %3781 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3782 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3780, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3783 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.102.11.us.us.us.us, <128 x i8> %3781, <32 x i32> %3782, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3784 = add i32 %3737, %3734
  %3785 = getelementptr inbounds i8, i8* %13, i32 %3784
  %3786 = bitcast i8* %3785 to <4 x i8>*
  %3787 = load <4 x i8>, <4 x i8>* %3786, align 4, !tbaa !108
  %3788 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3789 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3787, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3790 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.112.11.us.us.us.us, <128 x i8> %3788, <32 x i32> %3789, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3791 = add i32 %3737, %3735
  %3792 = getelementptr inbounds i8, i8* %13, i32 %3791
  %3793 = bitcast i8* %3792 to <4 x i8>*
  %3794 = load <4 x i8>, <4 x i8>* %3793, align 4, !tbaa !108
  %3795 = load <128 x i8>, <128 x i8>* %3745, align 128, !tbaa !106
  %3796 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %3794, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3797 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.122.11.us.us.us.us, <128 x i8> %3795, <32 x i32> %3796, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %3798 = add nuw nsw i32 %"convolved.s1.r19$z.r124125.us.us.us.us", 1
  %.not352.us.us.us.us = icmp eq i32 %3798, %7
  br i1 %.not352.us.us.us.us, label %"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us", label %"for convolved.s1.r19$z.r124123.us.us.us.us"

"end for convolved.s1.r19$z.r124124.loopexit.us.us.us.us": ; preds = %"for convolved.s1.r19$z.r124123.us.us.us.us"
  %3799 = add nuw nsw i32 %"convolved.s1.r19$x122.us.us.us.us", 1
  %.not351.us.us.us.us = icmp eq i32 %3799, %9
  br i1 %.not351.us.us.us.us, label %"end for convolved.s1.r19$x121.loopexit.us.us.us", label %"for convolved.s1.r19$x120.us.us.us.us"

next_bb75:                                        ; preds = %next_bb22
  br i1 %101, label %then_bb127, label %next_bb128

then_bb127:                                       ; preds = %next_bb75
  %3800 = mul nsw i32 %19, %18
  %3801 = mul nsw i32 %17, %16
  %3802 = mul nsw i32 %22, %20
  %3803 = add i32 %3802, %3800
  %t1121 = add i32 %3803, %3801
  %3804 = icmp sgt i32 %21, 0
  br i1 %3804, label %"for output.s0.b.rebased129.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased129.preheader":           ; preds = %then_bb127
  %3805 = icmp sgt i32 %29, 0
  %.neg749 = mul i32 %30, %28
  %.neg750 = mul i32 %27, %25
  %.neg751 = mul i32 %31, %20
  %3806 = icmp sgt i32 %11, 0
  %3807 = icmp sgt i32 %9, 0
  %3808 = icmp sgt i32 %7, 0
  %3809 = ashr i32 %4, 7
  %3810 = icmp sgt i32 %4, 127
  %3811 = insertelement <32 x i32> undef, i32 %output_multiplier, i32 0
  %3812 = shufflevector <32 x i32> %3811, <32 x i32> undef, <32 x i32> zeroinitializer
  %3813 = sext <32 x i32> %3812 to <32 x i64>
  %3814 = icmp sgt i32 %a497, 0
  %3815 = select i1 %3814, i32 %a497, i32 0
  %3816 = shl nuw i32 1, %3815
  %3817 = ashr i32 %3816, 1
  %3818 = zext i8 %output_zero to i16
  %3819 = insertelement <128 x i16> undef, i16 %3818, i32 0
  %3820 = shufflevector <128 x i16> %3819, <128 x i16> undef, <128 x i32> zeroinitializer
  %3821 = insertelement <128 x i8> undef, i8 %output_max, i32 0
  %3822 = shufflevector <128 x i8> %3821, <128 x i8> undef, <128 x i32> zeroinitializer
  %3823 = insertelement <128 x i8> undef, i8 %output_min, i32 0
  %3824 = shufflevector <128 x i8> %3823, <128 x i8> undef, <128 x i32> zeroinitializer
  %3825 = insertelement <1 x i32> poison, i32 %3817, i32 0
  %3826 = insertelement <1 x i32> poison, i32 %a497, i32 0
  %reass.add760 = add i32 %.neg749, %.neg750
  %reass.add761 = add i32 %reass.add760, %.neg751
  br i1 %3805, label %"for output.s0.b.rebased129.us.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased129.us.preheader":        ; preds = %"for output.s0.b.rebased129.preheader"
  %3827 = add i32 %7, -1
  %3828 = add i32 %9, -1
  %brmerge1314.demorgan = and i1 %3807, %3808
  %xtraiter1476 = and i32 %7, 7
  %3829 = icmp ult i32 %3827, 7
  %unroll_iter1481 = and i32 %7, -8
  %lcmp.mod1478.not = icmp eq i32 %xtraiter1476, 0
  %xtraiter1483 = and i32 %9, 3
  %3830 = icmp ult i32 %3828, 3
  %unroll_iter1488 = and i32 %9, -4
  %lcmp.mod1485.not = icmp eq i32 %xtraiter1483, 0
  br label %"for output.s0.b.rebased129.us"

"for output.s0.b.rebased129.us":                  ; preds = %"for output.s0.b.rebased129.us.preheader", %"end for output.s0.y.rebased133.loopexit.us"
  %sum_input314.sroa.0.14.us = phi <6 x i32> [ %sum_input314.sroa.0.26.us, %"end for output.s0.y.rebased133.loopexit.us" ], [ undef, %"for output.s0.b.rebased129.us.preheader" ]
  %output.s0.b.rebased131.us = phi i32 [ %3977, %"end for output.s0.y.rebased133.loopexit.us" ], [ 0, %"for output.s0.b.rebased129.us.preheader" ]
  %3831 = add nsw i32 %output.s0.b.rebased131.us, %20
  %3832 = mul nsw i32 %3831, %31
  %3833 = mul nsw i32 %3831, %22
  %3834 = sub i32 %3833, %t1121
  %3835 = sub i32 %3833, %3803
  %3836 = sub i32 %3832, %reass.add761
  br label %"for output.s0.y.rebased132.us"

"for output.s0.y.rebased132.us":                  ; preds = %"for output.s0.b.rebased129.us", %"end for output.s0.x.xo136.us"
  %sum_input314.sroa.0.15.us = phi <6 x i32> [ %sum_input314.sroa.0.26.us, %"end for output.s0.x.xo136.us" ], [ %sum_input314.sroa.0.14.us, %"for output.s0.b.rebased129.us" ]
  %output.s0.y.rebased134.us = phi i32 [ %3955, %"end for output.s0.x.xo136.us" ], [ 0, %"for output.s0.b.rebased129.us" ]
  %3837 = add nsw i32 %output.s0.y.rebased134.us, %28
  %3838 = mul nsw i32 %3837, %30
  %3839 = mul nsw i32 %3837, %stride_y
  %t1133.us = add i32 %3836, %3838
  br label %"for output.s0.x.xo135.us"

"for output.s0.x.xo135.us":                       ; preds = %"end for output.s0.c.co162.us", %"for output.s0.y.rebased132.us"
  %sum_input314.sroa.0.17.us = phi <6 x i32> [ %sum_input314.sroa.0.15.us, %"for output.s0.y.rebased132.us" ], [ %sum_input314.sroa.0.26.us, %"end for output.s0.c.co162.us" ]
  %output.s0.x.xo137.us = phi i32 [ 0, %"for output.s0.y.rebased132.us" ], [ %3954, %"end for output.s0.c.co162.us" ]
  br i1 %t843.not, label %"consume sum_input160.us", label %then_bb140.us

then_bb140.us:                                    ; preds = %"for output.s0.x.xo135.us"
  %sum_input314.sroa.0.0.vec.insert510.us = insertelement <6 x i32> %sum_input314.sroa.0.17.us, i32 0, i32 0
  br i1 %t844, label %then_bb143.us, label %next_bb144.us

next_bb144.us:                                    ; preds = %then_bb140.us
  br i1 %3806, label %"for sum_input.s1.r19$y151.preheader.us", label %"consume sum_input160.us", !prof !96

then_bb143.us:                                    ; preds = %then_bb140.us
  br i1 %3806, label %"for sum_input.s1.r19$y145.preheader.us", label %"consume sum_input160.us", !prof !96

"for sum_input.s1.r19$y145.us":                   ; preds = %"for sum_input.s1.r19$y145.preheader.us", %"end for sum_input.s1.r19$x149.us"
  %sum_input314.sroa.0.18.us = phi <6 x i32> [ %sum_input314.sroa.0.20.us, %"end for sum_input.s1.r19$x149.us" ], [ %sum_input314.sroa.0.0.vec.insert510.us, %"for sum_input.s1.r19$y145.preheader.us" ]
  %"sum_input.s1.r19$y147.us" = phi i32 [ %3885, %"end for sum_input.s1.r19$x149.us" ], [ 0, %"for sum_input.s1.r19$y145.preheader.us" ]
  br i1 %3807, label %"for sum_input.s1.r19$x148.preheader.us", label %"end for sum_input.s1.r19$x149.us", !prof !96

"for sum_input.s1.r19$x148.us":                   ; preds = %"for sum_input.s1.r19$x148.preheader.us", %"for sum_input.s1.r19$x148.us"
  %sum_input314.sroa.0.19.us = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert506.us.3, %"for sum_input.s1.r19$x148.us" ], [ %sum_input314.sroa.0.18.us, %"for sum_input.s1.r19$x148.preheader.us" ]
  %"sum_input.s1.r19$x150.us" = phi i32 [ %3875, %"for sum_input.s1.r19$x148.us" ], [ 0, %"for sum_input.s1.r19$x148.preheader.us" ]
  %niter1489 = phi i32 [ %niter1489.nsub.3, %"for sum_input.s1.r19$x148.us" ], [ %unroll_iter1488, %"for sum_input.s1.r19$x148.preheader.us" ]
  %sum_input314.sroa.0.0.vec.extract508.us = extractelement <6 x i32> %sum_input314.sroa.0.19.us, i32 0
  %3840 = mul nsw i32 %"sum_input.s1.r19$x150.us", %dilation_x
  %reass.add758.us = add i32 %3974, %3840
  %reass.mul759.us = shl i32 %reass.add758.us, 2
  %3841 = add i32 %t1136.us, %reass.mul759.us
  %3842 = getelementptr inbounds i8, i8* %13, i32 %3841
  %3843 = bitcast i8* %3842 to <4 x i8>*
  %3844 = load <4 x i8>, <4 x i8>* %3843, align 4, !tbaa !108
  %3845 = zext <4 x i8> %3844 to <4 x i32>
  %3846 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3845) #9
  %3847 = add nsw i32 %3846, %sum_input314.sroa.0.0.vec.extract508.us
  %3848 = or i32 %"sum_input.s1.r19$x150.us", 1
  %3849 = mul nsw i32 %3848, %dilation_x
  %reass.add758.us.1 = add i32 %3974, %3849
  %reass.mul759.us.1 = shl i32 %reass.add758.us.1, 2
  %3850 = add i32 %t1136.us, %reass.mul759.us.1
  %3851 = getelementptr inbounds i8, i8* %13, i32 %3850
  %3852 = bitcast i8* %3851 to <4 x i8>*
  %3853 = load <4 x i8>, <4 x i8>* %3852, align 4, !tbaa !108
  %3854 = zext <4 x i8> %3853 to <4 x i32>
  %3855 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3854) #9
  %3856 = add nsw i32 %3855, %3847
  %3857 = or i32 %"sum_input.s1.r19$x150.us", 2
  %3858 = mul nsw i32 %3857, %dilation_x
  %reass.add758.us.2 = add i32 %3974, %3858
  %reass.mul759.us.2 = shl i32 %reass.add758.us.2, 2
  %3859 = add i32 %t1136.us, %reass.mul759.us.2
  %3860 = getelementptr inbounds i8, i8* %13, i32 %3859
  %3861 = bitcast i8* %3860 to <4 x i8>*
  %3862 = load <4 x i8>, <4 x i8>* %3861, align 4, !tbaa !108
  %3863 = zext <4 x i8> %3862 to <4 x i32>
  %3864 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3863) #9
  %3865 = add nsw i32 %3864, %3856
  %sum_input314.sroa.0.0.vec.insert506.us.2 = insertelement <6 x i32> %sum_input314.sroa.0.19.us, i32 %3865, i32 0
  %3866 = or i32 %"sum_input.s1.r19$x150.us", 3
  %3867 = mul nsw i32 %3866, %dilation_x
  %reass.add758.us.3 = add i32 %3974, %3867
  %reass.mul759.us.3 = shl i32 %reass.add758.us.3, 2
  %3868 = add i32 %t1136.us, %reass.mul759.us.3
  %3869 = getelementptr inbounds i8, i8* %13, i32 %3868
  %3870 = bitcast i8* %3869 to <4 x i8>*
  %3871 = load <4 x i8>, <4 x i8>* %3870, align 4, !tbaa !108
  %3872 = zext <4 x i8> %3871 to <4 x i32>
  %3873 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3872) #9
  %3874 = add nsw i32 %3873, %3865
  %sum_input314.sroa.0.0.vec.insert506.us.3 = insertelement <6 x i32> %sum_input314.sroa.0.0.vec.insert506.us.2, i32 %3874, i32 0
  %3875 = add nuw nsw i32 %"sum_input.s1.r19$x150.us", 4
  %niter1489.nsub.3 = add i32 %niter1489, -4
  %niter1489.ncmp.3 = icmp eq i32 %niter1489.nsub.3, 0
  br i1 %niter1489.ncmp.3, label %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit", label %"for sum_input.s1.r19$x148.us"

"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit": ; preds = %"for sum_input.s1.r19$x148.us"
  %sum_input314.sroa.0.0.vec.insert506.us.2.le = insertelement <6 x i32> %sum_input314.sroa.0.19.us, i32 %3865, i32 0
  %sum_input314.sroa.0.0.vec.insert506.us.3.le = insertelement <6 x i32> %sum_input314.sroa.0.0.vec.insert506.us.2.le, i32 %3874, i32 0
  br label %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa"

"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa": ; preds = %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit", %"for sum_input.s1.r19$x148.preheader.us"
  %sum_input314.sroa.0.19.us.lcssa.ph = phi <6 x i32> [ undef, %"for sum_input.s1.r19$x148.preheader.us" ], [ %sum_input314.sroa.0.0.vec.insert506.us.2.le, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit" ]
  %.lcssa1450.ph = phi i32 [ undef, %"for sum_input.s1.r19$x148.preheader.us" ], [ %3874, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit" ]
  %sum_input314.sroa.0.19.us.unr = phi <6 x i32> [ %sum_input314.sroa.0.18.us, %"for sum_input.s1.r19$x148.preheader.us" ], [ %sum_input314.sroa.0.0.vec.insert506.us.3.le, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit" ]
  %"sum_input.s1.r19$x150.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x148.preheader.us" ], [ %3875, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa.loopexit" ]
  br i1 %lcmp.mod1485.not, label %"end for sum_input.s1.r19$x149.us.loopexit", label %"for sum_input.s1.r19$x148.us.epil"

"for sum_input.s1.r19$x148.us.epil":              ; preds = %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x148.us.epil"
  %sum_input314.sroa.0.19.us.epil = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert506.us.epil, %"for sum_input.s1.r19$x148.us.epil" ], [ %sum_input314.sroa.0.19.us.unr, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa" ]
  %"sum_input.s1.r19$x150.us.epil" = phi i32 [ %3884, %"for sum_input.s1.r19$x148.us.epil" ], [ %"sum_input.s1.r19$x150.us.unr", %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa" ]
  %epil.iter1484 = phi i32 [ %epil.iter1484.sub, %"for sum_input.s1.r19$x148.us.epil" ], [ %xtraiter1483, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa" ]
  %sum_input314.sroa.0.0.vec.extract508.us.epil = extractelement <6 x i32> %sum_input314.sroa.0.19.us.epil, i32 0
  %3876 = mul nsw i32 %"sum_input.s1.r19$x150.us.epil", %dilation_x
  %reass.add758.us.epil = add i32 %3974, %3876
  %reass.mul759.us.epil = shl i32 %reass.add758.us.epil, 2
  %3877 = add i32 %t1136.us, %reass.mul759.us.epil
  %3878 = getelementptr inbounds i8, i8* %13, i32 %3877
  %3879 = bitcast i8* %3878 to <4 x i8>*
  %3880 = load <4 x i8>, <4 x i8>* %3879, align 4, !tbaa !108
  %3881 = zext <4 x i8> %3880 to <4 x i32>
  %3882 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3881) #9
  %3883 = add nsw i32 %3882, %sum_input314.sroa.0.0.vec.extract508.us.epil
  %sum_input314.sroa.0.0.vec.insert506.us.epil = insertelement <6 x i32> %sum_input314.sroa.0.19.us.epil, i32 %3883, i32 0
  %3884 = add nuw nsw i32 %"sum_input.s1.r19$x150.us.epil", 1
  %epil.iter1484.sub = add i32 %epil.iter1484, -1
  %epil.iter1484.cmp.not = icmp eq i32 %epil.iter1484.sub, 0
  br i1 %epil.iter1484.cmp.not, label %"end for sum_input.s1.r19$x149.us.loopexit", label %"for sum_input.s1.r19$x148.us.epil", !llvm.loop !115

"end for sum_input.s1.r19$x149.us.loopexit":      ; preds = %"for sum_input.s1.r19$x148.us.epil", %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa"
  %sum_input314.sroa.0.19.us.lcssa = phi <6 x i32> [ %sum_input314.sroa.0.19.us.lcssa.ph, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa" ], [ %sum_input314.sroa.0.19.us.epil, %"for sum_input.s1.r19$x148.us.epil" ]
  %.lcssa1450 = phi i32 [ %.lcssa1450.ph, %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa" ], [ %3883, %"for sum_input.s1.r19$x148.us.epil" ]
  %sum_input314.sroa.0.0.vec.insert506.us.le = insertelement <6 x i32> %sum_input314.sroa.0.19.us.lcssa, i32 %.lcssa1450, i32 0
  br label %"end for sum_input.s1.r19$x149.us"

"end for sum_input.s1.r19$x149.us":               ; preds = %"end for sum_input.s1.r19$x149.us.loopexit", %"for sum_input.s1.r19$y145.us"
  %sum_input314.sroa.0.20.us = phi <6 x i32> [ %sum_input314.sroa.0.18.us, %"for sum_input.s1.r19$y145.us" ], [ %sum_input314.sroa.0.0.vec.insert506.us.le, %"end for sum_input.s1.r19$x149.us.loopexit" ]
  %3885 = add nuw nsw i32 %"sum_input.s1.r19$y147.us", 1
  %.not344.us = icmp eq i32 %3885, %11
  br i1 %.not344.us, label %"consume sum_input160.us", label %"for sum_input.s1.r19$y145.us"

"consume sum_input160.us.loopexit1238":           ; preds = %"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us"
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le.le.le = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us.lcssa, i32 %.lcssa1449, i32 0
  br label %"consume sum_input160.us"

"consume sum_input160.us":                        ; preds = %"end for sum_input.s1.r19$x149.us", %"for sum_input.s1.r19$y151.preheader.us", %"consume sum_input160.us.loopexit1238", %then_bb143.us, %next_bb144.us, %"for output.s0.x.xo135.us"
  %sum_input314.sroa.0.26.us = phi <6 x i32> [ %sum_input314.sroa.0.17.us, %"for output.s0.x.xo135.us" ], [ %sum_input314.sroa.0.0.vec.insert510.us, %then_bb143.us ], [ %sum_input314.sroa.0.0.vec.insert510.us, %next_bb144.us ], [ %sum_input314.sroa.0.0.vec.insert510.us, %"for sum_input.s1.r19$y151.preheader.us" ], [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le.le.le, %"consume sum_input160.us.loopexit1238" ], [ %sum_input314.sroa.0.20.us, %"end for sum_input.s1.r19$x149.us" ]
  br i1 %3810, label %"for output.s0.c.co161.preheader.us", label %"end for output.s0.c.co162.us", !prof !96

"for output.s0.c.co161.us":                       ; preds = %"for output.s0.c.co161.preheader.us", %"consume convolved177.us"
  %output.s0.c.co163.us = phi i32 [ %3953, %"consume convolved177.us" ], [ 0, %"for output.s0.c.co161.preheader.us" ]
  %3886 = shl nsw i32 %output.s0.c.co163.us, 7
  %3887 = getelementptr inbounds i32, i32* %offset_c, i32 %3886
  %3888 = bitcast i32* %3887 to <32 x i32>*
  %3889 = load <32 x i32>, <32 x i32>* %3888, align 128, !tbaa !104
  br i1 %t843.not, label %then_bb166.us, label %next_bb167.us

next_bb167.us:                                    ; preds = %"for output.s0.c.co161.us"
  %3890 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3968, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3891 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3889, <32 x i32> %3890, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3892 = getelementptr inbounds i32, i32* %3887, i32 32
  %3893 = bitcast i32* %3892 to <32 x i32>*
  %3894 = load <32 x i32>, <32 x i32>* %3893, align 128, !tbaa !104
  %3895 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3968, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3896 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3894, <32 x i32> %3895, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3897 = getelementptr inbounds i32, i32* %3887, i32 64
  %3898 = bitcast i32* %3897 to <32 x i32>*
  %3899 = load <32 x i32>, <32 x i32>* %3898, align 128, !tbaa !104
  %3900 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3968, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3901 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3899, <32 x i32> %3900, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  %3902 = getelementptr inbounds i32, i32* %3887, i32 96
  %3903 = bitcast i32* %3902 to <32 x i32>*
  %3904 = load <32 x i32>, <32 x i32>* %3903, align 128, !tbaa !104
  %3905 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %3968, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %3906 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %3904, <32 x i32> %3905, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb165.us

then_bb166.us:                                    ; preds = %"for output.s0.c.co161.us"
  %3907 = getelementptr inbounds i32, i32* %3887, i32 32
  %3908 = bitcast i32* %3907 to <32 x i32>*
  %3909 = load <32 x i32>, <32 x i32>* %3908, align 128, !tbaa !104
  %3910 = getelementptr inbounds i32, i32* %3887, i32 64
  %3911 = bitcast i32* %3910 to <32 x i32>*
  %3912 = load <32 x i32>, <32 x i32>* %3911, align 128, !tbaa !104
  %3913 = getelementptr inbounds i32, i32* %3887, i32 96
  %3914 = bitcast i32* %3913 to <32 x i32>*
  %3915 = load <32 x i32>, <32 x i32>* %3914, align 128, !tbaa !104
  br label %after_bb165.us

after_bb165.us:                                   ; preds = %then_bb166.us, %next_bb167.us
  %convolved313.sroa.77.14.us = phi <32 x i32> [ %3915, %then_bb166.us ], [ %3906, %next_bb167.us ]
  %convolved313.sroa.62.14.us = phi <32 x i32> [ %3912, %then_bb166.us ], [ %3901, %next_bb167.us ]
  %convolved313.sroa.47.14.us = phi <32 x i32> [ %3909, %then_bb166.us ], [ %3896, %next_bb167.us ]
  %convolved313.sroa.0.28.us = phi <32 x i32> [ %3889, %then_bb166.us ], [ %3891, %next_bb167.us ]
  br i1 %3806, label %"for convolved.s1.r19$y168.preheader.us", label %"consume convolved177.us", !prof !96

"consume convolved177.us":                        ; preds = %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us", %"for convolved.s1.r19$y168.preheader.split.us.us", %"for convolved.s1.r19$y168.preheader.us", %after_bb165.us
  %convolved313.sroa.77.20.us = phi <32 x i32> [ %convolved313.sroa.77.14.us, %after_bb165.us ], [ %convolved313.sroa.77.14.us, %"for convolved.s1.r19$y168.preheader.us" ], [ %convolved313.sroa.77.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ], [ %4113, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ]
  %convolved313.sroa.62.20.us = phi <32 x i32> [ %convolved313.sroa.62.14.us, %after_bb165.us ], [ %convolved313.sroa.62.14.us, %"for convolved.s1.r19$y168.preheader.us" ], [ %convolved313.sroa.62.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ], [ %4106, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ]
  %convolved313.sroa.47.20.us = phi <32 x i32> [ %convolved313.sroa.47.14.us, %after_bb165.us ], [ %convolved313.sroa.47.14.us, %"for convolved.s1.r19$y168.preheader.us" ], [ %convolved313.sroa.47.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ], [ %4099, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ]
  %convolved313.sroa.0.34.us = phi <32 x i32> [ %convolved313.sroa.0.28.us, %after_bb165.us ], [ %convolved313.sroa.0.28.us, %"for convolved.s1.r19$y168.preheader.us" ], [ %convolved313.sroa.0.28.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ], [ %4091, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ]
  %3916 = sext <32 x i32> %convolved313.sroa.0.34.us to <32 x i64>
  %a465.us = mul nsw <32 x i64> %3916, %3813
  %3917 = icmp slt <32 x i64> %a465.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3918 = select <32 x i1> %3917, <32 x i64> %a465.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3919 = add nsw <32 x i64> %3918, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a464.us = ashr <32 x i64> %3919, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3920 = icmp slt <32 x i64> %a464.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a463.us = select <32 x i1> %3920, <32 x i64> %a464.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3921 = icmp sgt <32 x i64> %a463.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3922 = select <32 x i1> %3921, <32 x i64> %a463.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3923 = trunc <32 x i64> %3922 to <32 x i32>
  %3924 = sext <32 x i32> %convolved313.sroa.47.20.us to <32 x i64>
  %a469.us = mul nsw <32 x i64> %3924, %3813
  %3925 = icmp slt <32 x i64> %a469.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3926 = select <32 x i1> %3925, <32 x i64> %a469.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3927 = add nsw <32 x i64> %3926, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a468.us = ashr <32 x i64> %3927, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3928 = icmp slt <32 x i64> %a468.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a467.us = select <32 x i1> %3928, <32 x i64> %a468.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3929 = icmp sgt <32 x i64> %a467.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3930 = select <32 x i1> %3929, <32 x i64> %a467.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3931 = trunc <32 x i64> %3930 to <32 x i32>
  %3932 = sext <32 x i32> %convolved313.sroa.62.20.us to <32 x i64>
  %a473.us = mul nsw <32 x i64> %3932, %3813
  %3933 = icmp slt <32 x i64> %a473.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3934 = select <32 x i1> %3933, <32 x i64> %a473.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3935 = add nsw <32 x i64> %3934, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a472.us = ashr <32 x i64> %3935, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3936 = icmp slt <32 x i64> %a472.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a471.us = select <32 x i1> %3936, <32 x i64> %a472.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3937 = icmp sgt <32 x i64> %a471.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3938 = select <32 x i1> %3937, <32 x i64> %a471.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3939 = trunc <32 x i64> %3938 to <32 x i32>
  %3940 = sext <32 x i32> %convolved313.sroa.77.20.us to <32 x i64>
  %a477.us = mul nsw <32 x i64> %3940, %3813
  %3941 = icmp slt <32 x i64> %a477.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3942 = select <32 x i1> %3941, <32 x i64> %a477.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %3943 = add nsw <32 x i64> %3942, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a476.us = ashr <32 x i64> %3943, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %3944 = icmp slt <32 x i64> %a476.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a475.us = select <32 x i1> %3944, <32 x i64> %a476.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %3945 = icmp sgt <32 x i64> %a475.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3946 = select <32 x i1> %3945, <32 x i64> %a475.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %3947 = trunc <32 x i64> %3946 to <32 x i32>
  %3948 = call <128 x i8> @hydride.node.conv_nn_hvx_depth5.136(<32 x i32> %3923, <1 x i32> %3825, <1 x i32> %3826, <32 x i32> %3931, <1 x i32> %3825, <32 x i32> %3939, <1 x i32> %3825, <32 x i32> %3947, <1 x i32> %3825, <128 x i16> %3820, <128 x i8> %3822, <128 x i8> %3824) #11
  %3949 = shl nsw i32 %output.s0.c.co163.us, 7
  %3950 = add i32 %3972, %3949
  %3951 = getelementptr inbounds i8, i8* %23, i32 %3950
  %3952 = bitcast i8* %3951 to <128 x i8>*
  store <128 x i8> %3948, <128 x i8>* %3952, align 1, !tbaa !111
  %3953 = add nuw nsw i32 %output.s0.c.co163.us, 1
  %.not337.us = icmp eq i32 %3953, %3809
  br i1 %.not337.us, label %"end for output.s0.c.co162.us", label %"for output.s0.c.co161.us"

"end for output.s0.c.co162.us":                   ; preds = %"consume convolved177.us", %"consume sum_input160.us"
  %3954 = add nuw nsw i32 %output.s0.x.xo137.us, 1
  %.not335.us = icmp eq i32 %3954, %26
  br i1 %.not335.us, label %"end for output.s0.x.xo136.us", label %"for output.s0.x.xo135.us"

"end for output.s0.x.xo136.us":                   ; preds = %"end for output.s0.c.co162.us"
  %3955 = add nuw nsw i32 %output.s0.y.rebased134.us, 1
  %.not336.us = icmp eq i32 %3955, %29
  br i1 %.not336.us, label %"end for output.s0.y.rebased133.loopexit.us", label %"for output.s0.y.rebased132.us"

"for convolved.s1.r19$y168.preheader.us":         ; preds = %after_bb165.us
  %3956 = shl nsw i32 %output.s0.c.co163.us, 2
  %3957 = or i32 %3956, 3
  %3958 = mul nsw i32 %3957, %8
  %3959 = or i32 %3956, 2
  %3960 = mul nsw i32 %3959, %8
  %3961 = or i32 %3956, 1
  %3962 = mul nsw i32 %3961, %8
  %3963 = mul nsw i32 %output.s0.c.co163.us, %8
  br i1 %3807, label %"for convolved.s1.r19$y168.preheader.split.us.us", label %"consume convolved177.us", !prof !96

"for sum_input.s1.r19$x148.preheader.us":         ; preds = %"for sum_input.s1.r19$y145.us"
  %3964 = mul nsw i32 %"sum_input.s1.r19$y147.us", %dilation_y
  %3965 = add nsw i32 %3964, %3839
  %3966 = mul nsw i32 %3965, %19
  %t1136.us = add i32 %3835, %3966
  br i1 %3830, label %"end for sum_input.s1.r19$x149.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x148.us"

"for output.s0.c.co161.preheader.us":             ; preds = %"consume sum_input160.us"
  %sum_input314.sroa.0.0.vec.extract501.us = extractelement <6 x i32> %sum_input314.sroa.0.26.us, i32 0
  %3967 = mul nsw i32 %sum_input314.sroa.0.0.vec.extract501.us, %168
  %3968 = insertelement <1 x i32> poison, i32 %3967, i32 0
  %3969 = add nsw i32 %output.s0.x.xo137.us, %25
  %3970 = mul nsw i32 %3969, %stride_x
  %3971 = mul nsw i32 %3969, %27
  %3972 = add i32 %t1133.us, %3971
  br label %"for output.s0.c.co161.us"

"for sum_input.s1.r19$y145.preheader.us":         ; preds = %then_bb143.us
  %3973 = add nsw i32 %output.s0.x.xo137.us, %25
  %3974 = sub i32 %3973, %16
  br label %"for sum_input.s1.r19$y145.us"

"for sum_input.s1.r19$y151.preheader.us":         ; preds = %next_bb144.us
  %3975 = add nsw i32 %output.s0.x.xo137.us, %25
  %3976 = mul nsw i32 %3975, %stride_x
  br i1 %brmerge1314.demorgan, label %"for sum_input.s1.r19$y151.us.us.us", label %"consume sum_input160.us", !prof !103

"end for output.s0.y.rebased133.loopexit.us":     ; preds = %"end for output.s0.x.xo136.us"
  %3977 = add nuw nsw i32 %output.s0.b.rebased131.us, 1
  %.not334.us = icmp eq i32 %3977, %21
  br i1 %.not334.us, label %after_bb3, label %"for output.s0.b.rebased129.us"

"for sum_input.s1.r19$y151.us.us.us":             ; preds = %"for sum_input.s1.r19$y151.preheader.us", %"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us"
  %sum_input314.sroa.0.21.us.us.us = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le.le, %"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us" ], [ %sum_input314.sroa.0.0.vec.insert510.us, %"for sum_input.s1.r19$y151.preheader.us" ]
  %"sum_input.s1.r19$y153.us.us.us" = phi i32 [ %4066, %"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y151.preheader.us" ]
  %3978 = mul nsw i32 %"sum_input.s1.r19$y153.us.us.us", %dilation_y
  %3979 = add nsw i32 %3978, %3839
  %3980 = mul nsw i32 %3979, %19
  %t1138.us.us.us = add nsw i32 %3834, %3980
  br label %"for sum_input.s1.r19$x154.us.us.us.us"

"for sum_input.s1.r19$x154.us.us.us.us":          ; preds = %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us", %"for sum_input.s1.r19$y151.us.us.us"
  %sum_input314.sroa.0.22.us.us.us.us = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us" ], [ %sum_input314.sroa.0.21.us.us.us, %"for sum_input.s1.r19$y151.us.us.us" ]
  %"sum_input.s1.r19$x156.us.us.us.us" = phi i32 [ %4065, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$y151.us.us.us" ]
  %3981 = mul nsw i32 %"sum_input.s1.r19$x156.us.us.us.us", %dilation_x
  %t1139.s.us.us.us.us = add nsw i32 %3981, %3976
  %3982 = mul nsw i32 %t1139.s.us.us.us.us, %17
  %3983 = add nsw i32 %t1138.us.us.us, %3982
  br i1 %3829, label %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124157.us.us.us.us"

"for sum_input.s1.r19$z.r124157.us.us.us.us":     ; preds = %"for sum_input.s1.r19$x154.us.us.us.us", %"for sum_input.s1.r19$z.r124157.us.us.us.us"
  %sum_input314.sroa.0.24.us.us.us.us = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.7, %"for sum_input.s1.r19$z.r124157.us.us.us.us" ], [ %sum_input314.sroa.0.22.us.us.us.us, %"for sum_input.s1.r19$x154.us.us.us.us" ]
  %"sum_input.s1.r19$z.r124159.us.us.us.us" = phi i32 [ %4055, %"for sum_input.s1.r19$z.r124157.us.us.us.us" ], [ 0, %"for sum_input.s1.r19$x154.us.us.us.us" ]
  %niter1482 = phi i32 [ %niter1482.nsub.7, %"for sum_input.s1.r19$z.r124157.us.us.us.us" ], [ %unroll_iter1481, %"for sum_input.s1.r19$x154.us.us.us.us" ]
  %sum_input314.sroa.0.0.vec.extract504.us.us.us.us = extractelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us, i32 0
  %3984 = shl nsw i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %3985 = add nsw i32 %3983, %3984
  %3986 = getelementptr inbounds i8, i8* %13, i32 %3985
  %3987 = bitcast i8* %3986 to <4 x i8>*
  %3988 = load <4 x i8>, <4 x i8>* %3987, align 4, !tbaa !108
  %3989 = zext <4 x i8> %3988 to <4 x i32>
  %3990 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3989) #9
  %3991 = add nsw i32 %3990, %sum_input314.sroa.0.0.vec.extract504.us.us.us.us
  %3992 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %3993 = or i32 %3992, 4
  %3994 = add nsw i32 %3983, %3993
  %3995 = getelementptr inbounds i8, i8* %13, i32 %3994
  %3996 = bitcast i8* %3995 to <4 x i8>*
  %3997 = load <4 x i8>, <4 x i8>* %3996, align 4, !tbaa !108
  %3998 = zext <4 x i8> %3997 to <4 x i32>
  %3999 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %3998) #9
  %4000 = add nsw i32 %3999, %3991
  %4001 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4002 = or i32 %4001, 8
  %4003 = add nsw i32 %3983, %4002
  %4004 = getelementptr inbounds i8, i8* %13, i32 %4003
  %4005 = bitcast i8* %4004 to <4 x i8>*
  %4006 = load <4 x i8>, <4 x i8>* %4005, align 4, !tbaa !108
  %4007 = zext <4 x i8> %4006 to <4 x i32>
  %4008 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4007) #9
  %4009 = add nsw i32 %4008, %4000
  %4010 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4011 = or i32 %4010, 12
  %4012 = add nsw i32 %3983, %4011
  %4013 = getelementptr inbounds i8, i8* %13, i32 %4012
  %4014 = bitcast i8* %4013 to <4 x i8>*
  %4015 = load <4 x i8>, <4 x i8>* %4014, align 4, !tbaa !108
  %4016 = zext <4 x i8> %4015 to <4 x i32>
  %4017 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4016) #9
  %4018 = add nsw i32 %4017, %4009
  %4019 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4020 = or i32 %4019, 16
  %4021 = add nsw i32 %3983, %4020
  %4022 = getelementptr inbounds i8, i8* %13, i32 %4021
  %4023 = bitcast i8* %4022 to <4 x i8>*
  %4024 = load <4 x i8>, <4 x i8>* %4023, align 4, !tbaa !108
  %4025 = zext <4 x i8> %4024 to <4 x i32>
  %4026 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4025) #9
  %4027 = add nsw i32 %4026, %4018
  %4028 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4029 = or i32 %4028, 20
  %4030 = add nsw i32 %3983, %4029
  %4031 = getelementptr inbounds i8, i8* %13, i32 %4030
  %4032 = bitcast i8* %4031 to <4 x i8>*
  %4033 = load <4 x i8>, <4 x i8>* %4032, align 4, !tbaa !108
  %4034 = zext <4 x i8> %4033 to <4 x i32>
  %4035 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4034) #9
  %4036 = add nsw i32 %4035, %4027
  %4037 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4038 = or i32 %4037, 24
  %4039 = add nsw i32 %3983, %4038
  %4040 = getelementptr inbounds i8, i8* %13, i32 %4039
  %4041 = bitcast i8* %4040 to <4 x i8>*
  %4042 = load <4 x i8>, <4 x i8>* %4041, align 4, !tbaa !108
  %4043 = zext <4 x i8> %4042 to <4 x i32>
  %4044 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4043) #9
  %4045 = add nsw i32 %4044, %4036
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.6 = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us, i32 %4045, i32 0
  %4046 = shl i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 2
  %4047 = or i32 %4046, 28
  %4048 = add nsw i32 %3983, %4047
  %4049 = getelementptr inbounds i8, i8* %13, i32 %4048
  %4050 = bitcast i8* %4049 to <4 x i8>*
  %4051 = load <4 x i8>, <4 x i8>* %4050, align 4, !tbaa !108
  %4052 = zext <4 x i8> %4051 to <4 x i32>
  %4053 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4052) #9
  %4054 = add nsw i32 %4053, %4045
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.7 = insertelement <6 x i32> %sum_input314.sroa.0.0.vec.insert.us.us.us.us.6, i32 %4054, i32 0
  %4055 = add nuw nsw i32 %"sum_input.s1.r19$z.r124159.us.us.us.us", 8
  %niter1482.nsub.7 = add i32 %niter1482, -8
  %niter1482.ncmp.7 = icmp eq i32 %niter1482.nsub.7, 0
  br i1 %niter1482.ncmp.7, label %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit", label %"for sum_input.s1.r19$z.r124157.us.us.us.us"

"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit": ; preds = %"for sum_input.s1.r19$z.r124157.us.us.us.us"
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.6.le = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us, i32 %4045, i32 0
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.7.le = insertelement <6 x i32> %sum_input314.sroa.0.0.vec.insert.us.us.us.us.6.le, i32 %4054, i32 0
  br label %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa"

"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa": ; preds = %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit", %"for sum_input.s1.r19$x154.us.us.us.us"
  %sum_input314.sroa.0.24.us.us.us.us.lcssa.ph = phi <6 x i32> [ undef, %"for sum_input.s1.r19$x154.us.us.us.us" ], [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.6.le, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit" ]
  %.lcssa1449.ph = phi i32 [ undef, %"for sum_input.s1.r19$x154.us.us.us.us" ], [ %4054, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit" ]
  %sum_input314.sroa.0.24.us.us.us.us.unr = phi <6 x i32> [ %sum_input314.sroa.0.22.us.us.us.us, %"for sum_input.s1.r19$x154.us.us.us.us" ], [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.7.le, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit" ]
  %"sum_input.s1.r19$z.r124159.us.us.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x154.us.us.us.us" ], [ %4055, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa.loopexit" ]
  br i1 %lcmp.mod1478.not, label %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us", label %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil"

"for sum_input.s1.r19$z.r124157.us.us.us.us.epil": ; preds = %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa", %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil"
  %sum_input314.sroa.0.24.us.us.us.us.epil = phi <6 x i32> [ %sum_input314.sroa.0.0.vec.insert.us.us.us.us.epil, %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil" ], [ %sum_input314.sroa.0.24.us.us.us.us.unr, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa" ]
  %"sum_input.s1.r19$z.r124159.us.us.us.us.epil" = phi i32 [ %4064, %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil" ], [ %"sum_input.s1.r19$z.r124159.us.us.us.us.unr", %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa" ]
  %epil.iter1477 = phi i32 [ %epil.iter1477.sub, %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil" ], [ %xtraiter1476, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa" ]
  %sum_input314.sroa.0.0.vec.extract504.us.us.us.us.epil = extractelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us.epil, i32 0
  %4056 = shl nsw i32 %"sum_input.s1.r19$z.r124159.us.us.us.us.epil", 2
  %4057 = add nsw i32 %3983, %4056
  %4058 = getelementptr inbounds i8, i8* %13, i32 %4057
  %4059 = bitcast i8* %4058 to <4 x i8>*
  %4060 = load <4 x i8>, <4 x i8>* %4059, align 4, !tbaa !108
  %4061 = zext <4 x i8> %4060 to <4 x i32>
  %4062 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4061) #9
  %4063 = add nsw i32 %4062, %sum_input314.sroa.0.0.vec.extract504.us.us.us.us.epil
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.epil = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us.epil, i32 %4063, i32 0
  %4064 = add nuw nsw i32 %"sum_input.s1.r19$z.r124159.us.us.us.us.epil", 1
  %epil.iter1477.sub = add i32 %epil.iter1477, -1
  %epil.iter1477.cmp.not = icmp eq i32 %epil.iter1477.sub, 0
  br i1 %epil.iter1477.cmp.not, label %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us", label %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil", !llvm.loop !116

"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us": ; preds = %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil", %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa"
  %sum_input314.sroa.0.24.us.us.us.us.lcssa = phi <6 x i32> [ %sum_input314.sroa.0.24.us.us.us.us.lcssa.ph, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa" ], [ %sum_input314.sroa.0.24.us.us.us.us.epil, %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil" ]
  %.lcssa1449 = phi i32 [ %.lcssa1449.ph, %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us.unr-lcssa" ], [ %4063, %"for sum_input.s1.r19$z.r124157.us.us.us.us.epil" ]
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us.lcssa, i32 %.lcssa1449, i32 0
  %4065 = add nuw nsw i32 %"sum_input.s1.r19$x156.us.us.us.us", 1
  %.not342.us.us.us.us = icmp eq i32 %4065, %9
  br i1 %.not342.us.us.us.us, label %"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us", label %"for sum_input.s1.r19$x154.us.us.us.us"

"end for sum_input.s1.r19$x155.loopexit.split.us.us.us.us": ; preds = %"end for sum_input.s1.r19$z.r124158.loopexit.us.us.us.us"
  %sum_input314.sroa.0.0.vec.insert.us.us.us.us.le.le = insertelement <6 x i32> %sum_input314.sroa.0.24.us.us.us.us.lcssa, i32 %.lcssa1449, i32 0
  %4066 = add nuw nsw i32 %"sum_input.s1.r19$y153.us.us.us", 1
  %.not341.us.us.us = icmp eq i32 %4066, %11
  br i1 %.not341.us.us.us, label %"consume sum_input160.us.loopexit1238", label %"for sum_input.s1.r19$y151.us.us.us"

"for convolved.s1.r19$y168.preheader.split.us.us": ; preds = %"for convolved.s1.r19$y168.preheader.us"
  br i1 %3808, label %"for convolved.s1.r19$y168.us.us.us", label %"consume convolved177.us", !prof !96

"for convolved.s1.r19$y168.us.us.us":             ; preds = %"for convolved.s1.r19$y168.preheader.split.us.us", %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us"
  %convolved313.sroa.77.15.us.us.us = phi <32 x i32> [ %4113, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.77.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ]
  %convolved313.sroa.62.15.us.us.us = phi <32 x i32> [ %4106, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.62.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ]
  %convolved313.sroa.47.15.us.us.us = phi <32 x i32> [ %4099, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.47.14.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ]
  %convolved313.sroa.0.29.us.us.us = phi <32 x i32> [ %4091, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.0.28.us, %"for convolved.s1.r19$y168.preheader.split.us.us" ]
  %"convolved.s1.r19$y170.us.us.us" = phi i32 [ %4116, %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y168.preheader.split.us.us" ]
  %4067 = mul nsw i32 %"convolved.s1.r19$y170.us.us.us", %dilation_y
  %4068 = add nsw i32 %4067, %3839
  %4069 = mul nsw i32 %4068, %19
  %t1148.us.us.us = add nsw i32 %3834, %4069
  %4070 = mul nsw i32 %"convolved.s1.r19$y170.us.us.us", %12
  br label %"for convolved.s1.r19$x171.us.us.us.us"

"for convolved.s1.r19$x171.us.us.us.us":          ; preds = %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us", %"for convolved.s1.r19$y168.us.us.us"
  %convolved313.sroa.77.16.us.us.us.us = phi <32 x i32> [ %4113, %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us" ], [ %convolved313.sroa.77.15.us.us.us, %"for convolved.s1.r19$y168.us.us.us" ]
  %convolved313.sroa.62.16.us.us.us.us = phi <32 x i32> [ %4106, %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us" ], [ %convolved313.sroa.62.15.us.us.us, %"for convolved.s1.r19$y168.us.us.us" ]
  %convolved313.sroa.47.16.us.us.us.us = phi <32 x i32> [ %4099, %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us" ], [ %convolved313.sroa.47.15.us.us.us, %"for convolved.s1.r19$y168.us.us.us" ]
  %convolved313.sroa.0.30.us.us.us.us = phi <32 x i32> [ %4091, %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us" ], [ %convolved313.sroa.0.29.us.us.us, %"for convolved.s1.r19$y168.us.us.us" ]
  %"convolved.s1.r19$x173.us.us.us.us" = phi i32 [ %4115, %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y168.us.us.us" ]
  %4071 = mul nsw i32 %"convolved.s1.r19$x173.us.us.us.us", %dilation_x
  %t1154.s.us.us.us.us = add nsw i32 %4071, %3970
  %4072 = mul nsw i32 %"convolved.s1.r19$x173.us.us.us.us", %10
  %t1155.us.us.us.us = add nsw i32 %4072, %4070
  %4073 = mul nsw i32 %t1154.s.us.us.us.us, %17
  %4074 = add nsw i32 %t1148.us.us.us, %4073
  %4075 = add i32 %t1155.us.us.us.us, %3962
  %4076 = add i32 %t1155.us.us.us.us, %3960
  %4077 = add i32 %t1155.us.us.us.us, %3958
  br label %"for convolved.s1.r19$z.r124174.us.us.us.us"

"for convolved.s1.r19$z.r124174.us.us.us.us":     ; preds = %"for convolved.s1.r19$z.r124174.us.us.us.us", %"for convolved.s1.r19$x171.us.us.us.us"
  %convolved313.sroa.77.18.us.us.us.us = phi <32 x i32> [ %4113, %"for convolved.s1.r19$z.r124174.us.us.us.us" ], [ %convolved313.sroa.77.16.us.us.us.us, %"for convolved.s1.r19$x171.us.us.us.us" ]
  %convolved313.sroa.62.18.us.us.us.us = phi <32 x i32> [ %4106, %"for convolved.s1.r19$z.r124174.us.us.us.us" ], [ %convolved313.sroa.62.16.us.us.us.us, %"for convolved.s1.r19$x171.us.us.us.us" ]
  %convolved313.sroa.47.18.us.us.us.us = phi <32 x i32> [ %4099, %"for convolved.s1.r19$z.r124174.us.us.us.us" ], [ %convolved313.sroa.47.16.us.us.us.us, %"for convolved.s1.r19$x171.us.us.us.us" ]
  %convolved313.sroa.0.32.us.us.us.us = phi <32 x i32> [ %4091, %"for convolved.s1.r19$z.r124174.us.us.us.us" ], [ %convolved313.sroa.0.30.us.us.us.us, %"for convolved.s1.r19$x171.us.us.us.us" ]
  %"convolved.s1.r19$z.r124176.us.us.us.us" = phi i32 [ %4114, %"for convolved.s1.r19$z.r124174.us.us.us.us" ], [ 0, %"for convolved.s1.r19$x171.us.us.us.us" ]
  %4078 = shl nsw i32 %"convolved.s1.r19$z.r124176.us.us.us.us", 2
  %4079 = add nsw i32 %4074, %4078
  %4080 = getelementptr inbounds i8, i8* %13, i32 %4079
  %4081 = bitcast i8* %4080 to <4 x i8>*
  %4082 = load <4 x i8>, <4 x i8>* %4081, align 4, !tbaa !108
  %4083 = shl nsw i32 %"convolved.s1.r19$z.r124176.us.us.us.us", 5
  %4084 = add nsw i32 %4083, %3963
  %4085 = shl nsw i32 %4084, 2
  %4086 = add nsw i32 %t1155.us.us.us.us, %4085
  %4087 = getelementptr inbounds i8, i8* %5, i32 %4086
  %4088 = bitcast i8* %4087 to <128 x i8>*
  %4089 = load <128 x i8>, <128 x i8>* %4088, align 128, !tbaa !106
  %4090 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4082, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4091 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.0.32.us.us.us.us, <128 x i8> %4089, <32 x i32> %4090, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4092 = load <4 x i8>, <4 x i8>* %4081, align 4, !tbaa !108
  %4093 = shl nsw i32 %"convolved.s1.r19$z.r124176.us.us.us.us", 7
  %4094 = add i32 %4075, %4093
  %4095 = getelementptr inbounds i8, i8* %5, i32 %4094
  %4096 = bitcast i8* %4095 to <128 x i8>*
  %4097 = load <128 x i8>, <128 x i8>* %4096, align 128, !tbaa !106
  %4098 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4092, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4099 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.47.18.us.us.us.us, <128 x i8> %4097, <32 x i32> %4098, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4100 = load <4 x i8>, <4 x i8>* %4081, align 4, !tbaa !108
  %4101 = add i32 %4076, %4093
  %4102 = getelementptr inbounds i8, i8* %5, i32 %4101
  %4103 = bitcast i8* %4102 to <128 x i8>*
  %4104 = load <128 x i8>, <128 x i8>* %4103, align 128, !tbaa !106
  %4105 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4106 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.62.18.us.us.us.us, <128 x i8> %4104, <32 x i32> %4105, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4107 = load <4 x i8>, <4 x i8>* %4081, align 4, !tbaa !108
  %4108 = add i32 %4077, %4093
  %4109 = getelementptr inbounds i8, i8* %5, i32 %4108
  %4110 = bitcast i8* %4109 to <128 x i8>*
  %4111 = load <128 x i8>, <128 x i8>* %4110, align 128, !tbaa !106
  %4112 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4107, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4113 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.77.18.us.us.us.us, <128 x i8> %4111, <32 x i32> %4112, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4114 = add nuw nsw i32 %"convolved.s1.r19$z.r124176.us.us.us.us", 1
  %.not340.us.us.us.us = icmp eq i32 %4114, %7
  br i1 %.not340.us.us.us.us, label %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us", label %"for convolved.s1.r19$z.r124174.us.us.us.us"

"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us": ; preds = %"for convolved.s1.r19$z.r124174.us.us.us.us"
  %4115 = add nuw nsw i32 %"convolved.s1.r19$x173.us.us.us.us", 1
  %.not339.us.us.us.us = icmp eq i32 %4115, %9
  br i1 %.not339.us.us.us.us, label %"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us", label %"for convolved.s1.r19$x171.us.us.us.us"

"end for convolved.s1.r19$x172.loopexit.split.us.us.us.us": ; preds = %"end for convolved.s1.r19$z.r124175.loopexit.us.us.us.us"
  %4116 = add nuw nsw i32 %"convolved.s1.r19$y170.us.us.us", 1
  %.not338.us.us.us = icmp eq i32 %4116, %11
  br i1 %.not338.us.us.us, label %"consume convolved177.us", label %"for convolved.s1.r19$y168.us.us.us"

next_bb128:                                       ; preds = %next_bb75
  %a479 = ashr i32 %4, 5
  %4117 = icmp sgt i32 %4, 31
  %4118 = select i1 %4117, i32 %a479, i32 0
  %t1167 = sub nsw i32 %122, %4118
  %4119 = mul nsw i32 %19, %18
  %4120 = mul nsw i32 %17, %16
  %4121 = mul nsw i32 %22, %20
  %4122 = add i32 %4121, %4119
  %t1163 = add i32 %4122, %4120
  %4123 = icmp sgt i32 %21, 0
  br i1 %4123, label %"for output.s0.b.rebased178.preheader", label %after_bb3, !prof !96

"for output.s0.b.rebased178.preheader":           ; preds = %next_bb128
  %4124 = icmp sgt i32 %29, 0
  %.neg = mul i32 %30, %28
  %.neg739 = mul i32 %27, %25
  %.neg740 = mul i32 %31, %20
  %reass.add = add i32 %.neg, %.neg739
  %reass.add742 = add i32 %reass.add, %.neg740
  %4125 = icmp sgt i32 %11, 0
  %4126 = icmp sgt i32 %9, 0
  %4127 = icmp sgt i32 %7, 0
  %4128 = insertelement <32 x i32> undef, i32 %output_multiplier, i32 0
  %4129 = shufflevector <32 x i32> %4128, <32 x i32> undef, <32 x i32> zeroinitializer
  %4130 = sext <32 x i32> %4129 to <32 x i64>
  %4131 = icmp sgt i32 %a497, 0
  %4132 = select i1 %4131, i32 %a497, i32 0
  %4133 = shl nuw i32 1, %4132
  %4134 = ashr i32 %4133, 1
  %4135 = insertelement <1 x i32> poison, i32 %4134, i32 0
  %4136 = insertelement <1 x i32> poison, i32 %a497, i32 0
  %4137 = zext i8 %output_zero to i16
  %4138 = insertelement <32 x i16> undef, i16 %4137, i32 0
  %4139 = shufflevector <32 x i16> %4138, <32 x i16> undef, <64 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4140 = bitcast <64 x i16> %4139 to <32 x i32>
  %4141 = insertelement <32 x i8> undef, i8 %output_max, i32 0
  %4142 = shufflevector <32 x i8> %4141, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4143 = bitcast <128 x i8> %4142 to <32 x i32>
  %4144 = insertelement <32 x i8> undef, i8 %output_min, i32 0
  %4145 = shufflevector <32 x i8> %4144, <32 x i8> undef, <128 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4146 = bitcast <128 x i8> %4145 to <32 x i32>
  %4147 = icmp sgt i32 %t1167, 0
  %4148 = insertelement <32 x i32> undef, i32 %4, i32 0
  %4149 = shufflevector <32 x i32> %4148, <32 x i32> undef, <32 x i32> zeroinitializer
  %4150 = add i32 %7, -1
  %4151 = add i32 %9, -1
  %xtraiter1462 = and i32 %7, 7
  %4152 = icmp ult i32 %4150, 7
  %unroll_iter1467 = and i32 %7, -8
  %lcmp.mod1464.not = icmp eq i32 %xtraiter1462, 0
  %xtraiter1469 = and i32 %9, 3
  %4153 = icmp ult i32 %4151, 3
  %unroll_iter1474 = and i32 %9, -4
  %lcmp.mod1471.not = icmp eq i32 %xtraiter1469, 0
  %brmerge1319.demorgan = and i1 %4126, %4127
  %or.cond1393 = and i1 %4125, %brmerge1319.demorgan
  %brmerge1322.demorgan = and i1 %4126, %4127
  %or.cond1392 = and i1 %4125, %brmerge1322.demorgan
  br label %"for output.s0.b.rebased178"

"for output.s0.b.rebased178":                     ; preds = %"for output.s0.b.rebased178.preheader", %"end for output.s0.y.rebased182"
  %sum_input187312.sroa.0.21 = phi <32 x i32> [ %sum_input187312.sroa.0.23, %"end for output.s0.y.rebased182" ], [ undef, %"for output.s0.b.rebased178.preheader" ]
  %convolved313.sroa.0.35 = phi <32 x i32> [ %convolved313.sroa.0.37, %"end for output.s0.y.rebased182" ], [ undef, %"for output.s0.b.rebased178.preheader" ]
  %output.s0.b.rebased180 = phi i32 [ %4494, %"end for output.s0.y.rebased182" ], [ 0, %"for output.s0.b.rebased178.preheader" ]
  br i1 %4124, label %"for output.s0.y.rebased181.preheader", label %"end for output.s0.y.rebased182", !prof !96

"for output.s0.y.rebased181.preheader":           ; preds = %"for output.s0.b.rebased178"
  %4154 = add nsw i32 %output.s0.b.rebased180, %20
  %4155 = mul nsw i32 %4154, %31
  %4156 = sub i32 %4155, %reass.add742
  %4157 = mul nsw i32 %4154, %22
  %4158 = sub i32 %4157, %t1163
  %4159 = sub i32 %4157, %4122
  br i1 %100, label %"for output.s0.y.rebased181.us", label %"end for output.s0.y.rebased182", !prof !96

"for output.s0.y.rebased181.us":                  ; preds = %"for output.s0.y.rebased181.preheader", %"end for output.s0.x.xo185.loopexit.us"
  %sum_input187312.sroa.0.22.us = phi <32 x i32> [ %sum_input187312.sroa.0.34.us, %"end for output.s0.x.xo185.loopexit.us" ], [ %sum_input187312.sroa.0.21, %"for output.s0.y.rebased181.preheader" ]
  %convolved313.sroa.0.36.us = phi <32 x i32> [ %convolved313.sroa.0.50.us, %"end for output.s0.x.xo185.loopexit.us" ], [ %convolved313.sroa.0.35, %"for output.s0.y.rebased181.preheader" ]
  %output.s0.y.rebased183.us = phi i32 [ %4356, %"end for output.s0.x.xo185.loopexit.us" ], [ 0, %"for output.s0.y.rebased181.preheader" ]
  %4160 = add nsw i32 %output.s0.y.rebased183.us, %28
  %4161 = mul nsw i32 %4160, %30
  %t1180.us = add i32 %4156, %4161
  %4162 = mul nsw i32 %4160, %stride_y
  br label %"for output.s0.x.xo184.us"

"for output.s0.x.xo184.us":                       ; preds = %"for output.s0.y.rebased181.us", %"end for output.s0.c.co.rebased.us"
  %sum_input187312.sroa.0.24.us = phi <32 x i32> [ %sum_input187312.sroa.0.34.us, %"end for output.s0.c.co.rebased.us" ], [ %sum_input187312.sroa.0.22.us, %"for output.s0.y.rebased181.us" ]
  %convolved313.sroa.0.38.us = phi <32 x i32> [ %convolved313.sroa.0.50.us, %"end for output.s0.c.co.rebased.us" ], [ %convolved313.sroa.0.36.us, %"for output.s0.y.rebased181.us" ]
  %output.s0.x.xo186.us = phi i32 [ %4336, %"end for output.s0.c.co.rebased.us" ], [ 0, %"for output.s0.y.rebased181.us" ]
  br i1 %t843.not, label %"consume sum_input210.us", label %then_bb190.us

then_bb190.us:                                    ; preds = %"for output.s0.x.xo184.us"
  %sum_input187312.sroa.0.0.vec.insert655.us = insertelement <32 x i32> %sum_input187312.sroa.0.24.us, i32 0, i32 0
  br i1 %t844, label %then_bb193.us, label %next_bb194.us

next_bb194.us:                                    ; preds = %then_bb190.us
  br i1 %4125, label %"for sum_input.s1.r19$y201.preheader.us", label %"consume sum_input210.us", !prof !96

then_bb193.us:                                    ; preds = %then_bb190.us
  br i1 %4125, label %"for sum_input.s1.r19$y195.preheader.us", label %"consume sum_input210.us", !prof !96

"for sum_input.s1.r19$y195.us":                   ; preds = %"for sum_input.s1.r19$y195.preheader.us", %"end for sum_input.s1.r19$x199.us"
  %sum_input187312.sroa.0.26.us = phi <32 x i32> [ %sum_input187312.sroa.0.28.us, %"end for sum_input.s1.r19$x199.us" ], [ %sum_input187312.sroa.0.0.vec.insert655.us, %"for sum_input.s1.r19$y195.preheader.us" ]
  %"sum_input.s1.r19$y197.us" = phi i32 [ %4208, %"end for sum_input.s1.r19$x199.us" ], [ 0, %"for sum_input.s1.r19$y195.preheader.us" ]
  br i1 %4126, label %"for sum_input.s1.r19$x198.preheader.us", label %"end for sum_input.s1.r19$x199.us", !prof !96

"for sum_input.s1.r19$x198.us":                   ; preds = %"for sum_input.s1.r19$x198.preheader.us", %"for sum_input.s1.r19$x198.us"
  %sum_input187312.sroa.0.27.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vec.insert651.us.3, %"for sum_input.s1.r19$x198.us" ], [ %sum_input187312.sroa.0.26.us, %"for sum_input.s1.r19$x198.preheader.us" ]
  %"sum_input.s1.r19$x200.us" = phi i32 [ %4198, %"for sum_input.s1.r19$x198.us" ], [ 0, %"for sum_input.s1.r19$x198.preheader.us" ]
  %niter1475 = phi i32 [ %niter1475.nsub.3, %"for sum_input.s1.r19$x198.us" ], [ %unroll_iter1474, %"for sum_input.s1.r19$x198.preheader.us" ]
  %sum_input187312.sroa.0.0.vec.extract653.us = extractelement <32 x i32> %sum_input187312.sroa.0.27.us, i32 0
  %4163 = mul nsw i32 %"sum_input.s1.r19$x200.us", %dilation_x
  %reass.add747.us = add i32 %4353, %4163
  %reass.mul748.us = shl i32 %reass.add747.us, 2
  %4164 = add i32 %t1183.us, %reass.mul748.us
  %4165 = getelementptr inbounds i8, i8* %13, i32 %4164
  %4166 = bitcast i8* %4165 to <4 x i8>*
  %4167 = load <4 x i8>, <4 x i8>* %4166, align 4, !tbaa !108
  %4168 = zext <4 x i8> %4167 to <4 x i32>
  %4169 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4168) #9
  %4170 = add nsw i32 %4169, %sum_input187312.sroa.0.0.vec.extract653.us
  %4171 = or i32 %"sum_input.s1.r19$x200.us", 1
  %4172 = mul nsw i32 %4171, %dilation_x
  %reass.add747.us.1 = add i32 %4353, %4172
  %reass.mul748.us.1 = shl i32 %reass.add747.us.1, 2
  %4173 = add i32 %t1183.us, %reass.mul748.us.1
  %4174 = getelementptr inbounds i8, i8* %13, i32 %4173
  %4175 = bitcast i8* %4174 to <4 x i8>*
  %4176 = load <4 x i8>, <4 x i8>* %4175, align 4, !tbaa !108
  %4177 = zext <4 x i8> %4176 to <4 x i32>
  %4178 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4177) #9
  %4179 = add nsw i32 %4178, %4170
  %4180 = or i32 %"sum_input.s1.r19$x200.us", 2
  %4181 = mul nsw i32 %4180, %dilation_x
  %reass.add747.us.2 = add i32 %4353, %4181
  %reass.mul748.us.2 = shl i32 %reass.add747.us.2, 2
  %4182 = add i32 %t1183.us, %reass.mul748.us.2
  %4183 = getelementptr inbounds i8, i8* %13, i32 %4182
  %4184 = bitcast i8* %4183 to <4 x i8>*
  %4185 = load <4 x i8>, <4 x i8>* %4184, align 4, !tbaa !108
  %4186 = zext <4 x i8> %4185 to <4 x i32>
  %4187 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4186) #9
  %4188 = add nsw i32 %4187, %4179
  %sum_input187312.sroa.0.0.vec.insert651.us.2 = insertelement <32 x i32> %sum_input187312.sroa.0.27.us, i32 %4188, i32 0
  %4189 = or i32 %"sum_input.s1.r19$x200.us", 3
  %4190 = mul nsw i32 %4189, %dilation_x
  %reass.add747.us.3 = add i32 %4353, %4190
  %reass.mul748.us.3 = shl i32 %reass.add747.us.3, 2
  %4191 = add i32 %t1183.us, %reass.mul748.us.3
  %4192 = getelementptr inbounds i8, i8* %13, i32 %4191
  %4193 = bitcast i8* %4192 to <4 x i8>*
  %4194 = load <4 x i8>, <4 x i8>* %4193, align 4, !tbaa !108
  %4195 = zext <4 x i8> %4194 to <4 x i32>
  %4196 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4195) #9
  %4197 = add nsw i32 %4196, %4188
  %sum_input187312.sroa.0.0.vec.insert651.us.3 = insertelement <32 x i32> %sum_input187312.sroa.0.0.vec.insert651.us.2, i32 %4197, i32 0
  %4198 = add nuw nsw i32 %"sum_input.s1.r19$x200.us", 4
  %niter1475.nsub.3 = add i32 %niter1475, -4
  %niter1475.ncmp.3 = icmp eq i32 %niter1475.nsub.3, 0
  br i1 %niter1475.ncmp.3, label %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit", label %"for sum_input.s1.r19$x198.us"

"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit": ; preds = %"for sum_input.s1.r19$x198.us"
  %sum_input187312.sroa.0.0.vec.insert651.us.2.le = insertelement <32 x i32> %sum_input187312.sroa.0.27.us, i32 %4188, i32 0
  %sum_input187312.sroa.0.0.vec.insert651.us.3.le = insertelement <32 x i32> %sum_input187312.sroa.0.0.vec.insert651.us.2.le, i32 %4197, i32 0
  br label %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa"

"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa": ; preds = %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit", %"for sum_input.s1.r19$x198.preheader.us"
  %sum_input187312.sroa.0.27.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x198.preheader.us" ], [ %sum_input187312.sroa.0.0.vec.insert651.us.2.le, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit" ]
  %.lcssa1458.ph = phi i32 [ undef, %"for sum_input.s1.r19$x198.preheader.us" ], [ %4197, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit" ]
  %sum_input187312.sroa.0.27.us.unr = phi <32 x i32> [ %sum_input187312.sroa.0.26.us, %"for sum_input.s1.r19$x198.preheader.us" ], [ %sum_input187312.sroa.0.0.vec.insert651.us.3.le, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit" ]
  %"sum_input.s1.r19$x200.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x198.preheader.us" ], [ %4198, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa.loopexit" ]
  br i1 %lcmp.mod1471.not, label %"end for sum_input.s1.r19$x199.us.loopexit", label %"for sum_input.s1.r19$x198.us.epil"

"for sum_input.s1.r19$x198.us.epil":              ; preds = %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa", %"for sum_input.s1.r19$x198.us.epil"
  %sum_input187312.sroa.0.27.us.epil = phi <32 x i32> [ %sum_input187312.sroa.0.0.vec.insert651.us.epil, %"for sum_input.s1.r19$x198.us.epil" ], [ %sum_input187312.sroa.0.27.us.unr, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa" ]
  %"sum_input.s1.r19$x200.us.epil" = phi i32 [ %4207, %"for sum_input.s1.r19$x198.us.epil" ], [ %"sum_input.s1.r19$x200.us.unr", %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa" ]
  %epil.iter1470 = phi i32 [ %epil.iter1470.sub, %"for sum_input.s1.r19$x198.us.epil" ], [ %xtraiter1469, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa" ]
  %sum_input187312.sroa.0.0.vec.extract653.us.epil = extractelement <32 x i32> %sum_input187312.sroa.0.27.us.epil, i32 0
  %4199 = mul nsw i32 %"sum_input.s1.r19$x200.us.epil", %dilation_x
  %reass.add747.us.epil = add i32 %4353, %4199
  %reass.mul748.us.epil = shl i32 %reass.add747.us.epil, 2
  %4200 = add i32 %t1183.us, %reass.mul748.us.epil
  %4201 = getelementptr inbounds i8, i8* %13, i32 %4200
  %4202 = bitcast i8* %4201 to <4 x i8>*
  %4203 = load <4 x i8>, <4 x i8>* %4202, align 4, !tbaa !108
  %4204 = zext <4 x i8> %4203 to <4 x i32>
  %4205 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4204) #9
  %4206 = add nsw i32 %4205, %sum_input187312.sroa.0.0.vec.extract653.us.epil
  %sum_input187312.sroa.0.0.vec.insert651.us.epil = insertelement <32 x i32> %sum_input187312.sroa.0.27.us.epil, i32 %4206, i32 0
  %4207 = add nuw nsw i32 %"sum_input.s1.r19$x200.us.epil", 1
  %epil.iter1470.sub = add i32 %epil.iter1470, -1
  %epil.iter1470.cmp.not = icmp eq i32 %epil.iter1470.sub, 0
  br i1 %epil.iter1470.cmp.not, label %"end for sum_input.s1.r19$x199.us.loopexit", label %"for sum_input.s1.r19$x198.us.epil", !llvm.loop !117

"end for sum_input.s1.r19$x199.us.loopexit":      ; preds = %"for sum_input.s1.r19$x198.us.epil", %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa"
  %sum_input187312.sroa.0.27.us.lcssa = phi <32 x i32> [ %sum_input187312.sroa.0.27.us.lcssa.ph, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa" ], [ %sum_input187312.sroa.0.27.us.epil, %"for sum_input.s1.r19$x198.us.epil" ]
  %.lcssa1458 = phi i32 [ %.lcssa1458.ph, %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa" ], [ %4206, %"for sum_input.s1.r19$x198.us.epil" ]
  %sum_input187312.sroa.0.0.vec.insert651.us.le = insertelement <32 x i32> %sum_input187312.sroa.0.27.us.lcssa, i32 %.lcssa1458, i32 0
  br label %"end for sum_input.s1.r19$x199.us"

"end for sum_input.s1.r19$x199.us":               ; preds = %"end for sum_input.s1.r19$x199.us.loopexit", %"for sum_input.s1.r19$y195.us"
  %sum_input187312.sroa.0.28.us = phi <32 x i32> [ %sum_input187312.sroa.0.26.us, %"for sum_input.s1.r19$y195.us" ], [ %sum_input187312.sroa.0.0.vec.insert651.us.le, %"end for sum_input.s1.r19$x199.us.loopexit" ]
  %4208 = add nuw nsw i32 %"sum_input.s1.r19$y197.us", 1
  %.not332.us = icmp eq i32 %4208, %11
  br i1 %.not332.us, label %"consume sum_input210.us", label %"for sum_input.s1.r19$y195.us"

"consume sum_input210.us":                        ; preds = %"end for sum_input.s1.r19$x205.loopexit.us.us", %"end for sum_input.s1.r19$x199.us", %"for sum_input.s1.r19$y201.preheader.us", %then_bb193.us, %next_bb194.us, %"for output.s0.x.xo184.us"
  %sum_input187312.sroa.0.34.us = phi <32 x i32> [ %sum_input187312.sroa.0.24.us, %"for output.s0.x.xo184.us" ], [ %sum_input187312.sroa.0.0.vec.insert655.us, %then_bb193.us ], [ %sum_input187312.sroa.0.0.vec.insert655.us, %next_bb194.us ], [ %sum_input187312.sroa.0.0.vec.insert655.us, %"for sum_input.s1.r19$y201.preheader.us" ], [ %sum_input187312.sroa.0.28.us, %"end for sum_input.s1.r19$x199.us" ], [ %.us-phi.us.us, %"end for sum_input.s1.r19$x205.loopexit.us.us" ]
  br i1 %4117, label %"for output.s0.c.co211.preheader.us", label %"end for output.s0.c.co212.us", !prof !96

"for output.s0.c.co211.us":                       ; preds = %"for output.s0.c.co211.preheader.us", %"consume convolved230.us"
  %convolved313.sroa.0.40.us = phi <32 x i32> [ %convolved313.sroa.0.48.us, %"consume convolved230.us" ], [ %convolved313.sroa.0.38.us, %"for output.s0.c.co211.preheader.us" ]
  %output.s0.c.co213.us = phi i32 [ %4249, %"consume convolved230.us" ], [ 0, %"for output.s0.c.co211.preheader.us" ]
  %4209 = shl nsw i32 %output.s0.c.co213.us, 5
  %4210 = icmp slt i32 %4209, %4
  br i1 %4210, label %then_bb216.us, label %"consume convolved230.us"

then_bb216.us:                                    ; preds = %"for output.s0.c.co211.us"
  %4211 = getelementptr inbounds i32, i32* %offset_c, i32 %4209
  %4212 = bitcast i32* %4211 to <32 x i32>*
  %4213 = load <32 x i32>, <32 x i32>* %4212, align 128, !tbaa !104
  br i1 %t843.not, label %after_bb218.us, label %next_bb220.us

next_bb220.us:                                    ; preds = %then_bb216.us
  %4214 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4347, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4215 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %4213, <32 x i32> %4214, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb218.us

after_bb218.us:                                   ; preds = %then_bb216.us, %next_bb220.us
  %convolved313.sroa.0.42.us = phi <32 x i32> [ %4215, %next_bb220.us ], [ %4213, %then_bb216.us ]
  %4216 = mul nsw i32 %output.s0.c.co213.us, %8
  br i1 %or.cond1393, label %"for convolved.s1.r19$y221.us.us.us", label %"consume convolved230.us", !prof !103

"consume convolved230.us":                        ; preds = %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us", %after_bb218.us, %"for output.s0.c.co211.us"
  %convolved313.sroa.0.48.us = phi <32 x i32> [ %convolved313.sroa.0.42.us, %after_bb218.us ], [ %convolved313.sroa.0.40.us, %"for output.s0.c.co211.us" ], [ %4466, %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us" ]
  %4217 = sext <32 x i32> %convolved313.sroa.0.48.us to <32 x i64>
  %a483.us = mul nsw <32 x i64> %4217, %4130
  %4218 = icmp slt <32 x i64> %a483.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4219 = select <32 x i1> %4218, <32 x i64> %a483.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4220 = add nsw <32 x i64> %4219, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a482.us = ashr <32 x i64> %4220, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %4221 = icmp slt <32 x i64> %a482.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a481.us = select <32 x i1> %4221, <32 x i64> %a482.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %4222 = icmp sgt <32 x i64> %a481.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4223 = select <32 x i1> %4222, <32 x i64> %a481.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4224 = trunc <32 x i64> %4223 to <32 x i32>
  %4225 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4136, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4226 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4227 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %4224, <32 x i32> %4226, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4228 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4225, <1 x i32> zeroinitializer, <32 x i32> %4227, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4229 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %4228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4230 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4229, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4231 = trunc <32 x i32> %4230 to <32 x i16>
  %4232 = shufflevector <32 x i16> %4231, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4233 = bitcast <64 x i16> %4232 to <32 x i32>
  %4234 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %4233, <32 x i32> %4140) #11
  %4235 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %4234, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %4236 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %4235, <32 x i32> zeroinitializer) #11
  %4237 = bitcast <32 x i32> %4236 to <64 x i16>
  %4238 = shufflevector <64 x i16> %4237, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4239 = trunc <32 x i16> %4238 to <32 x i8>
  %4240 = shufflevector <32 x i8> %4239, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4241 = bitcast <128 x i8> %4240 to <32 x i32>
  %4242 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %4241, <32 x i32> %4143) #11
  %4243 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %4242, <32 x i32> %4146) #11
  %4244 = bitcast <32 x i32> %4243 to <128 x i8>
  %4245 = shufflevector <128 x i8> %4244, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4246 = add nsw i32 %4351, %4209
  %4247 = getelementptr inbounds i8, i8* %23, i32 %4246
  %4248 = bitcast i8* %4247 to <32 x i8>*
  store <32 x i8> %4245, <32 x i8>* %4248, align 1, !tbaa !111
  %4249 = add nuw nsw i32 %output.s0.c.co213.us, 1
  %.not325.us = icmp eq i32 %4249, %4118
  br i1 %.not325.us, label %"end for output.s0.c.co212.us", label %"for output.s0.c.co211.us"

"end for output.s0.c.co212.us":                   ; preds = %"consume convolved230.us", %"consume sum_input210.us"
  %convolved313.sroa.0.41.us = phi <32 x i32> [ %convolved313.sroa.0.38.us, %"consume sum_input210.us" ], [ %convolved313.sroa.0.48.us, %"consume convolved230.us" ]
  br i1 %4147, label %"for output.s0.c.co.rebased.preheader.us", label %"end for output.s0.c.co.rebased.us", !prof !96

"for output.s0.c.co.rebased.us":                  ; preds = %"for output.s0.c.co.rebased.preheader.us", %after_bb254.us
  %convolved313.sroa.0.49.us = phi <32 x i32> [ %convolved313.sroa.0.57.us, %after_bb254.us ], [ %convolved313.sroa.0.41.us, %"for output.s0.c.co.rebased.preheader.us" ]
  %output.s0.c.co.rebased.us = phi i32 [ %4335, %after_bb254.us ], [ 0, %"for output.s0.c.co.rebased.preheader.us" ]
  %4250 = add nsw i32 %output.s0.c.co.rebased.us, %4118
  %4251 = icmp sgt i32 %4250, %a0
  %4252 = shl nsw i32 %4250, 5
  %4253 = icmp sge i32 %4252, %4
  %.not1315 = or i1 %4251, %4253
  %4254 = add nsw i32 %output.s0.c.co.rebased.us, %a479
  %.not1232 = icmp sgt i32 %4254, %a0
  %or.cond1316 = or i1 %.not1315, %.not1232
  br i1 %or.cond1316, label %"consume convolved253.us", label %then_bb236.us

then_bb236.us:                                    ; preds = %"for output.s0.c.co.rebased.us"
  %4255 = shl nsw i32 %4254, 5
  %4256 = getelementptr inbounds i32, i32* %offset_c, i32 %4255
  %4257 = bitcast i32* %4256 to <32 x i32>*
  %4258 = load <32 x i32>, <32 x i32>* %4257, align 128, !tbaa !104
  br i1 %t843.not, label %after_bb235.us, label %next_bb240.us

next_bb240.us:                                    ; preds = %then_bb236.us
  %4259 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4260 = call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %4258, <32 x i32> %4259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0) #11
  br label %after_bb235.us

after_bb235.us:                                   ; preds = %then_bb236.us, %next_bb240.us
  %convolved313.sroa.0.51.us = phi <32 x i32> [ %4260, %next_bb240.us ], [ %4258, %then_bb236.us ]
  %4261 = mul nsw i32 %4254, %8
  br i1 %or.cond1392, label %"for convolved.s1.r19$y244.us.us.us", label %"consume convolved253.us", !prof !118

"consume convolved253.us":                        ; preds = %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us", %after_bb235.us, %"for output.s0.c.co.rebased.us"
  %convolved313.sroa.0.57.us = phi <32 x i32> [ %convolved313.sroa.0.51.us, %after_bb235.us ], [ %convolved313.sroa.0.49.us, %"for output.s0.c.co.rebased.us" ], [ %4490, %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us" ]
  %4262 = add nsw i32 %4252, 32
  %.not319.us = icmp sgt i32 %4262, %4
  br i1 %.not319.us, label %next_bb256.us, label %then_bb255.us

then_bb255.us:                                    ; preds = %"consume convolved253.us"
  %4263 = sext <32 x i32> %convolved313.sroa.0.57.us to <32 x i64>
  %a490.us = mul nsw <32 x i64> %4263, %4130
  %4264 = icmp slt <32 x i64> %a490.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4265 = select <32 x i1> %4264, <32 x i64> %a490.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4266 = add nsw <32 x i64> %4265, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a489.us = ashr <32 x i64> %4266, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %4267 = icmp slt <32 x i64> %a489.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a488.us = select <32 x i1> %4267, <32 x i64> %a489.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %4268 = icmp sgt <32 x i64> %a488.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4269 = select <32 x i1> %4268, <32 x i64> %a488.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4270 = trunc <32 x i64> %4269 to <32 x i32>
  %4271 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4136, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4272 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4273 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %4270, <32 x i32> %4272, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4274 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4271, <1 x i32> zeroinitializer, <32 x i32> %4273, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4275 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %4274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4276 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4275, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4277 = trunc <32 x i32> %4276 to <32 x i16>
  %4278 = shufflevector <32 x i16> %4277, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4279 = bitcast <64 x i16> %4278 to <32 x i32>
  %4280 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %4279, <32 x i32> %4140) #11
  %4281 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %4280, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %4282 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %4281, <32 x i32> zeroinitializer) #11
  %4283 = bitcast <32 x i32> %4282 to <64 x i16>
  %4284 = shufflevector <64 x i16> %4283, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4285 = trunc <32 x i16> %4284 to <32 x i8>
  %4286 = shufflevector <32 x i8> %4285, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4287 = bitcast <128 x i8> %4286 to <32 x i32>
  %4288 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %4287, <32 x i32> %4143) #11
  %4289 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %4288, <32 x i32> %4146) #11
  %4290 = bitcast <32 x i32> %4289 to <128 x i8>
  %4291 = shufflevector <128 x i8> %4290, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4292 = add nsw i32 %output.s0.c.co.rebased.us, %a479
  %4293 = shl nsw i32 %4292, 5
  %4294 = add nsw i32 %4345, %4293
  %4295 = getelementptr inbounds i8, i8* %23, i32 %4294
  %4296 = bitcast i8* %4295 to <32 x i8>*
  store <32 x i8> %4291, <32 x i8>* %4296, align 1, !tbaa !111
  br label %after_bb254.us

next_bb256.us:                                    ; preds = %"consume convolved253.us"
  %4297 = or i32 %4252, 1
  %4298 = insertelement <32 x i32> undef, i32 %4297, i32 0
  %4299 = shufflevector <32 x i32> %4298, <32 x i32> undef, <32 x i32> zeroinitializer
  %4300 = add nsw <32 x i32> %4299, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4301 = icmp sle <32 x i32> %4300, %4149
  %.not320.us = icmp sgt i32 %4297, %4
  %4302 = sext <32 x i32> %convolved313.sroa.0.57.us to <32 x i64>
  %4303 = select i1 %.not320.us, <32 x i64> zeroinitializer, <32 x i64> %4302
  %a495.us = mul nsw <32 x i64> %4303, %4130
  %4304 = icmp slt <32 x i64> %a495.us, <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4305 = select <32 x i1> %4304, <32 x i64> %a495.us, <32 x i64> <i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983, i64 9223372035781033983>
  %4306 = add nsw <32 x i64> %4305, <i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824, i64 1073741824>
  %a494.us = ashr <32 x i64> %4306, <i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31, i64 31>
  %4307 = icmp slt <32 x i64> %a494.us, <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %a493.us = select <32 x i1> %4307, <32 x i64> %a494.us, <32 x i64> <i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647, i64 2147483647>
  %4308 = icmp sgt <32 x i64> %a493.us, <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4309 = select <32 x i1> %4308, <32 x i64> %a493.us, <32 x i64> <i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648, i64 -2147483648>
  %4310 = trunc <32 x i64> %4309 to <32 x i32>
  %4311 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4136, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4312 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %4135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4313 = call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %4310, <32 x i32> %4312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4314 = call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4311, <1 x i32> zeroinitializer, <32 x i32> %4313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4315 = call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %4314, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4316 = call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4315, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0) #11
  %4317 = trunc <32 x i32> %4316 to <32 x i16>
  %4318 = shufflevector <32 x i16> %4317, <32 x i16> undef, <64 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4319 = bitcast <64 x i16> %4318 to <32 x i32>
  %4320 = call <32 x i32> @llvm.hexagon.V6.vaddhsat.128B(<32 x i32> %4319, <32 x i32> %4140) #11
  %4321 = call <32 x i32> @llvm.hexagon.V6.vminh.128B(<32 x i32> %4320, <32 x i32> <i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 16711935, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>) #11
  %4322 = call <32 x i32> @llvm.hexagon.V6.vmaxh.128B(<32 x i32> %4321, <32 x i32> zeroinitializer) #11
  %4323 = bitcast <32 x i32> %4322 to <64 x i16>
  %4324 = shufflevector <64 x i16> %4323, <64 x i16> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4325 = trunc <32 x i16> %4324 to <32 x i8>
  %4326 = shufflevector <32 x i8> %4325, <32 x i8> undef, <128 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %4327 = bitcast <128 x i8> %4326 to <32 x i32>
  %4328 = call <32 x i32> @llvm.hexagon.V6.vminub.128B(<32 x i32> %4327, <32 x i32> %4143) #11
  %4329 = call <32 x i32> @llvm.hexagon.V6.vmaxub.128B(<32 x i32> %4328, <32 x i32> %4146) #11
  %4330 = bitcast <32 x i32> %4329 to <128 x i8>
  %4331 = shufflevector <128 x i8> %4330, <128 x i8> undef, <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %4332 = add nsw i32 %4345, %4252
  %4333 = getelementptr inbounds i8, i8* %23, i32 %4332
  %4334 = bitcast i8* %4333 to <32 x i8>*
  call void @llvm.masked.store.v32i8.p0v32i8(<32 x i8> %4331, <32 x i8>* %4334, i32 1, <32 x i1> %4301), !tbaa !111
  br label %after_bb254.us

after_bb254.us:                                   ; preds = %next_bb256.us, %then_bb255.us
  %4335 = add nuw nsw i32 %output.s0.c.co.rebased.us, 1
  %.not321.us = icmp eq i32 %4335, %t1167
  br i1 %.not321.us, label %"end for output.s0.c.co.rebased.us", label %"for output.s0.c.co.rebased.us"

"end for output.s0.c.co.rebased.us":              ; preds = %after_bb254.us, %"end for output.s0.c.co212.us"
  %convolved313.sroa.0.50.us = phi <32 x i32> [ %convolved313.sroa.0.41.us, %"end for output.s0.c.co212.us" ], [ %convolved313.sroa.0.57.us, %after_bb254.us ]
  %4336 = add nuw nsw i32 %output.s0.x.xo186.us, 1
  %.not318.us = icmp eq i32 %4336, %26
  br i1 %.not318.us, label %"end for output.s0.x.xo185.loopexit.us", label %"for output.s0.x.xo184.us"

"for sum_input.s1.r19$x198.preheader.us":         ; preds = %"for sum_input.s1.r19$y195.us"
  %4337 = mul nsw i32 %"sum_input.s1.r19$y197.us", %dilation_y
  %4338 = add nsw i32 %4337, %4162
  %4339 = mul nsw i32 %4338, %19
  %t1183.us = add i32 %4159, %4339
  br i1 %4153, label %"end for sum_input.s1.r19$x199.us.loopexit.unr-lcssa", label %"for sum_input.s1.r19$x198.us"

"for output.s0.c.co.rebased.preheader.us":        ; preds = %"end for output.s0.c.co212.us"
  %sum_input187312.sroa.0.0.vec.extract644.us = extractelement <32 x i32> %sum_input187312.sroa.0.34.us, i32 0
  %4340 = mul nsw i32 %sum_input187312.sroa.0.0.vec.extract644.us, %168
  %4341 = insertelement <1 x i32> poison, i32 %4340, i32 0
  %4342 = add nsw i32 %output.s0.x.xo186.us, %25
  %4343 = mul nsw i32 %4342, %stride_x
  %4344 = mul nsw i32 %4342, %27
  %4345 = add nsw i32 %4344, %t1180.us
  br label %"for output.s0.c.co.rebased.us"

"for output.s0.c.co211.preheader.us":             ; preds = %"consume sum_input210.us"
  %sum_input187312.sroa.0.0.vec.extract646.us = extractelement <32 x i32> %sum_input187312.sroa.0.34.us, i32 0
  %4346 = mul nsw i32 %sum_input187312.sroa.0.0.vec.extract646.us, %168
  %4347 = insertelement <1 x i32> poison, i32 %4346, i32 0
  %4348 = add nsw i32 %output.s0.x.xo186.us, %25
  %4349 = mul nsw i32 %4348, %stride_x
  %4350 = mul nsw i32 %4348, %27
  %4351 = add nsw i32 %4350, %t1180.us
  br label %"for output.s0.c.co211.us"

"for sum_input.s1.r19$y195.preheader.us":         ; preds = %then_bb193.us
  %4352 = add nsw i32 %output.s0.x.xo186.us, %25
  %4353 = sub i32 %4352, %16
  br label %"for sum_input.s1.r19$y195.us"

"for sum_input.s1.r19$y201.preheader.us":         ; preds = %next_bb194.us
  %4354 = add nsw i32 %output.s0.x.xo186.us, %25
  %4355 = mul nsw i32 %4354, %stride_x
  br i1 %4126, label %"for sum_input.s1.r19$y201.us.us", label %"consume sum_input210.us", !prof !96

"end for output.s0.x.xo185.loopexit.us":          ; preds = %"end for output.s0.c.co.rebased.us"
  %4356 = add nuw nsw i32 %output.s0.y.rebased183.us, 1
  %.not317.us = icmp eq i32 %4356, %29
  br i1 %.not317.us, label %"end for output.s0.y.rebased182", label %"for output.s0.y.rebased181.us"

"for sum_input.s1.r19$y201.us.us":                ; preds = %"for sum_input.s1.r19$y201.preheader.us", %"end for sum_input.s1.r19$x205.loopexit.us.us"
  %sum_input187312.sroa.0.29.us.us = phi <32 x i32> [ %.us-phi.us.us, %"end for sum_input.s1.r19$x205.loopexit.us.us" ], [ %sum_input187312.sroa.0.0.vec.insert655.us, %"for sum_input.s1.r19$y201.preheader.us" ]
  %"sum_input.s1.r19$y203.us.us" = phi i32 [ %4360, %"end for sum_input.s1.r19$x205.loopexit.us.us" ], [ 0, %"for sum_input.s1.r19$y201.preheader.us" ]
  %4357 = mul nsw i32 %"sum_input.s1.r19$y203.us.us", %dilation_y
  %4358 = add nsw i32 %4357, %4162
  %4359 = mul nsw i32 %4358, %19
  %t1185.us.us = add nsw i32 %4158, %4359
  br i1 %4127, label %"for sum_input.s1.r19$x204.us.us.us", label %"end for sum_input.s1.r19$x205.loopexit.us.us", !prof !96

"end for sum_input.s1.r19$x205.loopexit.us.us.loopexit": ; preds = %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us"
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.le.le = insertelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us.lcssa, i32 %.lcssa1457, i32 0
  br label %"end for sum_input.s1.r19$x205.loopexit.us.us"

"end for sum_input.s1.r19$x205.loopexit.us.us":   ; preds = %"end for sum_input.s1.r19$x205.loopexit.us.us.loopexit", %"for sum_input.s1.r19$y201.us.us"
  %.us-phi.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.29.us.us, %"for sum_input.s1.r19$y201.us.us" ], [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.le.le, %"end for sum_input.s1.r19$x205.loopexit.us.us.loopexit" ]
  %4360 = add nuw nsw i32 %"sum_input.s1.r19$y203.us.us", 1
  %.not329.us.us = icmp eq i32 %4360, %11
  br i1 %.not329.us.us, label %"consume sum_input210.us", label %"for sum_input.s1.r19$y201.us.us"

"for sum_input.s1.r19$x204.us.us.us":             ; preds = %"for sum_input.s1.r19$y201.us.us", %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us"
  %sum_input187312.sroa.0.30.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.le, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us" ], [ %sum_input187312.sroa.0.29.us.us, %"for sum_input.s1.r19$y201.us.us" ]
  %"sum_input.s1.r19$x206.us.us.us" = phi i32 [ %4445, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us" ], [ 0, %"for sum_input.s1.r19$y201.us.us" ]
  %4361 = mul nsw i32 %"sum_input.s1.r19$x206.us.us.us", %dilation_x
  %t1186.s.us.us.us = add nsw i32 %4361, %4355
  %4362 = mul nsw i32 %t1186.s.us.us.us, %17
  %4363 = add nsw i32 %t1185.us.us, %4362
  br i1 %4152, label %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa", label %"for sum_input.s1.r19$z.r124207.us.us.us"

"for sum_input.s1.r19$z.r124207.us.us.us":        ; preds = %"for sum_input.s1.r19$x204.us.us.us", %"for sum_input.s1.r19$z.r124207.us.us.us"
  %sum_input187312.sroa.0.32.us.us.us = phi <32 x i32> [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.7, %"for sum_input.s1.r19$z.r124207.us.us.us" ], [ %sum_input187312.sroa.0.30.us.us.us, %"for sum_input.s1.r19$x204.us.us.us" ]
  %"sum_input.s1.r19$z.r124209.us.us.us" = phi i32 [ %4435, %"for sum_input.s1.r19$z.r124207.us.us.us" ], [ 0, %"for sum_input.s1.r19$x204.us.us.us" ]
  %niter1468 = phi i32 [ %niter1468.nsub.7, %"for sum_input.s1.r19$z.r124207.us.us.us" ], [ %unroll_iter1467, %"for sum_input.s1.r19$x204.us.us.us" ]
  %sum_input187312.sroa.0.0.vec.extract649.us.us.us = extractelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us, i32 0
  %4364 = shl nsw i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4365 = add nsw i32 %4363, %4364
  %4366 = getelementptr inbounds i8, i8* %13, i32 %4365
  %4367 = bitcast i8* %4366 to <4 x i8>*
  %4368 = load <4 x i8>, <4 x i8>* %4367, align 4, !tbaa !108
  %4369 = zext <4 x i8> %4368 to <4 x i32>
  %4370 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4369) #9
  %4371 = add nsw i32 %4370, %sum_input187312.sroa.0.0.vec.extract649.us.us.us
  %4372 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4373 = or i32 %4372, 4
  %4374 = add nsw i32 %4363, %4373
  %4375 = getelementptr inbounds i8, i8* %13, i32 %4374
  %4376 = bitcast i8* %4375 to <4 x i8>*
  %4377 = load <4 x i8>, <4 x i8>* %4376, align 4, !tbaa !108
  %4378 = zext <4 x i8> %4377 to <4 x i32>
  %4379 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4378) #9
  %4380 = add nsw i32 %4379, %4371
  %4381 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4382 = or i32 %4381, 8
  %4383 = add nsw i32 %4363, %4382
  %4384 = getelementptr inbounds i8, i8* %13, i32 %4383
  %4385 = bitcast i8* %4384 to <4 x i8>*
  %4386 = load <4 x i8>, <4 x i8>* %4385, align 4, !tbaa !108
  %4387 = zext <4 x i8> %4386 to <4 x i32>
  %4388 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4387) #9
  %4389 = add nsw i32 %4388, %4380
  %4390 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4391 = or i32 %4390, 12
  %4392 = add nsw i32 %4363, %4391
  %4393 = getelementptr inbounds i8, i8* %13, i32 %4392
  %4394 = bitcast i8* %4393 to <4 x i8>*
  %4395 = load <4 x i8>, <4 x i8>* %4394, align 4, !tbaa !108
  %4396 = zext <4 x i8> %4395 to <4 x i32>
  %4397 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4396) #9
  %4398 = add nsw i32 %4397, %4389
  %4399 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4400 = or i32 %4399, 16
  %4401 = add nsw i32 %4363, %4400
  %4402 = getelementptr inbounds i8, i8* %13, i32 %4401
  %4403 = bitcast i8* %4402 to <4 x i8>*
  %4404 = load <4 x i8>, <4 x i8>* %4403, align 4, !tbaa !108
  %4405 = zext <4 x i8> %4404 to <4 x i32>
  %4406 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4405) #9
  %4407 = add nsw i32 %4406, %4398
  %4408 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4409 = or i32 %4408, 20
  %4410 = add nsw i32 %4363, %4409
  %4411 = getelementptr inbounds i8, i8* %13, i32 %4410
  %4412 = bitcast i8* %4411 to <4 x i8>*
  %4413 = load <4 x i8>, <4 x i8>* %4412, align 4, !tbaa !108
  %4414 = zext <4 x i8> %4413 to <4 x i32>
  %4415 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4414) #9
  %4416 = add nsw i32 %4415, %4407
  %4417 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4418 = or i32 %4417, 24
  %4419 = add nsw i32 %4363, %4418
  %4420 = getelementptr inbounds i8, i8* %13, i32 %4419
  %4421 = bitcast i8* %4420 to <4 x i8>*
  %4422 = load <4 x i8>, <4 x i8>* %4421, align 4, !tbaa !108
  %4423 = zext <4 x i8> %4422 to <4 x i32>
  %4424 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4423) #9
  %4425 = add nsw i32 %4424, %4416
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.6 = insertelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us, i32 %4425, i32 0
  %4426 = shl i32 %"sum_input.s1.r19$z.r124209.us.us.us", 2
  %4427 = or i32 %4426, 28
  %4428 = add nsw i32 %4363, %4427
  %4429 = getelementptr inbounds i8, i8* %13, i32 %4428
  %4430 = bitcast i8* %4429 to <4 x i8>*
  %4431 = load <4 x i8>, <4 x i8>* %4430, align 4, !tbaa !108
  %4432 = zext <4 x i8> %4431 to <4 x i32>
  %4433 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4432) #9
  %4434 = add nsw i32 %4433, %4425
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.7 = insertelement <32 x i32> %sum_input187312.sroa.0.0.vec.insert.us.us.us.6, i32 %4434, i32 0
  %4435 = add nuw nsw i32 %"sum_input.s1.r19$z.r124209.us.us.us", 8
  %niter1468.nsub.7 = add i32 %niter1468, -8
  %niter1468.ncmp.7 = icmp eq i32 %niter1468.nsub.7, 0
  br i1 %niter1468.ncmp.7, label %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit", label %"for sum_input.s1.r19$z.r124207.us.us.us"

"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit": ; preds = %"for sum_input.s1.r19$z.r124207.us.us.us"
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.6.le = insertelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us, i32 %4425, i32 0
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.7.le = insertelement <32 x i32> %sum_input187312.sroa.0.0.vec.insert.us.us.us.6.le, i32 %4434, i32 0
  br label %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa"

"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa": ; preds = %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit", %"for sum_input.s1.r19$x204.us.us.us"
  %sum_input187312.sroa.0.32.us.us.us.lcssa.ph = phi <32 x i32> [ undef, %"for sum_input.s1.r19$x204.us.us.us" ], [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.6.le, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit" ]
  %.lcssa1457.ph = phi i32 [ undef, %"for sum_input.s1.r19$x204.us.us.us" ], [ %4434, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit" ]
  %sum_input187312.sroa.0.32.us.us.us.unr = phi <32 x i32> [ %sum_input187312.sroa.0.30.us.us.us, %"for sum_input.s1.r19$x204.us.us.us" ], [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.7.le, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit" ]
  %"sum_input.s1.r19$z.r124209.us.us.us.unr" = phi i32 [ 0, %"for sum_input.s1.r19$x204.us.us.us" ], [ %4435, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa.loopexit" ]
  br i1 %lcmp.mod1464.not, label %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us", label %"for sum_input.s1.r19$z.r124207.us.us.us.epil"

"for sum_input.s1.r19$z.r124207.us.us.us.epil":   ; preds = %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa", %"for sum_input.s1.r19$z.r124207.us.us.us.epil"
  %sum_input187312.sroa.0.32.us.us.us.epil = phi <32 x i32> [ %sum_input187312.sroa.0.0.vec.insert.us.us.us.epil, %"for sum_input.s1.r19$z.r124207.us.us.us.epil" ], [ %sum_input187312.sroa.0.32.us.us.us.unr, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa" ]
  %"sum_input.s1.r19$z.r124209.us.us.us.epil" = phi i32 [ %4444, %"for sum_input.s1.r19$z.r124207.us.us.us.epil" ], [ %"sum_input.s1.r19$z.r124209.us.us.us.unr", %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa" ]
  %epil.iter1463 = phi i32 [ %epil.iter1463.sub, %"for sum_input.s1.r19$z.r124207.us.us.us.epil" ], [ %xtraiter1462, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa" ]
  %sum_input187312.sroa.0.0.vec.extract649.us.us.us.epil = extractelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us.epil, i32 0
  %4436 = shl nsw i32 %"sum_input.s1.r19$z.r124209.us.us.us.epil", 2
  %4437 = add nsw i32 %4363, %4436
  %4438 = getelementptr inbounds i8, i8* %13, i32 %4437
  %4439 = bitcast i8* %4438 to <4 x i8>*
  %4440 = load <4 x i8>, <4 x i8>* %4439, align 4, !tbaa !108
  %4441 = zext <4 x i8> %4440 to <4 x i32>
  %4442 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %4441) #9
  %4443 = add nsw i32 %4442, %sum_input187312.sroa.0.0.vec.extract649.us.us.us.epil
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.epil = insertelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us.epil, i32 %4443, i32 0
  %4444 = add nuw nsw i32 %"sum_input.s1.r19$z.r124209.us.us.us.epil", 1
  %epil.iter1463.sub = add i32 %epil.iter1463, -1
  %epil.iter1463.cmp.not = icmp eq i32 %epil.iter1463.sub, 0
  br i1 %epil.iter1463.cmp.not, label %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us", label %"for sum_input.s1.r19$z.r124207.us.us.us.epil", !llvm.loop !119

"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us": ; preds = %"for sum_input.s1.r19$z.r124207.us.us.us.epil", %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa"
  %sum_input187312.sroa.0.32.us.us.us.lcssa = phi <32 x i32> [ %sum_input187312.sroa.0.32.us.us.us.lcssa.ph, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa" ], [ %sum_input187312.sroa.0.32.us.us.us.epil, %"for sum_input.s1.r19$z.r124207.us.us.us.epil" ]
  %.lcssa1457 = phi i32 [ %.lcssa1457.ph, %"end for sum_input.s1.r19$z.r124208.loopexit.us.us.us.unr-lcssa" ], [ %4443, %"for sum_input.s1.r19$z.r124207.us.us.us.epil" ]
  %sum_input187312.sroa.0.0.vec.insert.us.us.us.le = insertelement <32 x i32> %sum_input187312.sroa.0.32.us.us.us.lcssa, i32 %.lcssa1457, i32 0
  %4445 = add nuw nsw i32 %"sum_input.s1.r19$x206.us.us.us", 1
  %.not330.us.us.us = icmp eq i32 %4445, %9
  br i1 %.not330.us.us.us, label %"end for sum_input.s1.r19$x205.loopexit.us.us.loopexit", label %"for sum_input.s1.r19$x204.us.us.us"

"for convolved.s1.r19$y221.us.us.us":             ; preds = %after_bb218.us, %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us"
  %convolved313.sroa.0.43.us.us.us = phi <32 x i32> [ %4466, %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.0.42.us, %after_bb218.us ]
  %"convolved.s1.r19$y223.us.us.us" = phi i32 [ %4469, %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us" ], [ 0, %after_bb218.us ]
  %4446 = mul nsw i32 %"convolved.s1.r19$y223.us.us.us", %dilation_y
  %4447 = add nsw i32 %4446, %4162
  %4448 = mul nsw i32 %4447, %19
  %t1191.us.us.us = add nsw i32 %4158, %4448
  %4449 = mul nsw i32 %"convolved.s1.r19$y223.us.us.us", %12
  %t1192.us.us.us = add nsw i32 %4449, %4216
  br label %"for convolved.s1.r19$x224.us.us.us.us"

"for convolved.s1.r19$x224.us.us.us.us":          ; preds = %"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us", %"for convolved.s1.r19$y221.us.us.us"
  %convolved313.sroa.0.44.us.us.us.us = phi <32 x i32> [ %4466, %"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us" ], [ %convolved313.sroa.0.43.us.us.us, %"for convolved.s1.r19$y221.us.us.us" ]
  %"convolved.s1.r19$x226.us.us.us.us" = phi i32 [ %4468, %"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y221.us.us.us" ]
  %4450 = mul nsw i32 %"convolved.s1.r19$x226.us.us.us.us", %dilation_x
  %t1193.s.us.us.us.us = add nsw i32 %4450, %4349
  %4451 = mul nsw i32 %t1193.s.us.us.us.us, %17
  %4452 = add nsw i32 %t1191.us.us.us, %4451
  %4453 = mul nsw i32 %"convolved.s1.r19$x226.us.us.us.us", %10
  %4454 = add nsw i32 %t1192.us.us.us, %4453
  br label %"for convolved.s1.r19$z.r124227.us.us.us.us"

"for convolved.s1.r19$z.r124227.us.us.us.us":     ; preds = %"for convolved.s1.r19$z.r124227.us.us.us.us", %"for convolved.s1.r19$x224.us.us.us.us"
  %convolved313.sroa.0.46.us.us.us.us = phi <32 x i32> [ %4466, %"for convolved.s1.r19$z.r124227.us.us.us.us" ], [ %convolved313.sroa.0.44.us.us.us.us, %"for convolved.s1.r19$x224.us.us.us.us" ]
  %"convolved.s1.r19$z.r124229.us.us.us.us" = phi i32 [ %4467, %"for convolved.s1.r19$z.r124227.us.us.us.us" ], [ 0, %"for convolved.s1.r19$x224.us.us.us.us" ]
  %4455 = shl nsw i32 %"convolved.s1.r19$z.r124229.us.us.us.us", 2
  %4456 = add nsw i32 %4452, %4455
  %4457 = getelementptr inbounds i8, i8* %13, i32 %4456
  %4458 = bitcast i8* %4457 to <4 x i8>*
  %4459 = load <4 x i8>, <4 x i8>* %4458, align 4, !tbaa !108
  %4460 = shl nsw i32 %"convolved.s1.r19$z.r124229.us.us.us.us", 7
  %4461 = add nsw i32 %4454, %4460
  %4462 = getelementptr inbounds i8, i8* %5, i32 %4461
  %4463 = bitcast i8* %4462 to <128 x i8>*
  %4464 = load <128 x i8>, <128 x i8>* %4463, align 128, !tbaa !106
  %4465 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4466 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.0.46.us.us.us.us, <128 x i8> %4464, <32 x i32> %4465, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4467 = add nuw nsw i32 %"convolved.s1.r19$z.r124229.us.us.us.us", 1
  %.not328.us.us.us.us = icmp eq i32 %4467, %7
  br i1 %.not328.us.us.us.us, label %"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us", label %"for convolved.s1.r19$z.r124227.us.us.us.us"

"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us": ; preds = %"for convolved.s1.r19$z.r124227.us.us.us.us"
  %4468 = add nuw nsw i32 %"convolved.s1.r19$x226.us.us.us.us", 1
  %.not327.us.us.us.us = icmp eq i32 %4468, %9
  br i1 %.not327.us.us.us.us, label %"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us", label %"for convolved.s1.r19$x224.us.us.us.us"

"end for convolved.s1.r19$x225.loopexit.split.us.us.us.us": ; preds = %"end for convolved.s1.r19$z.r124228.loopexit.us.us.us.us"
  %4469 = add nuw nsw i32 %"convolved.s1.r19$y223.us.us.us", 1
  %.not326.us.us.us = icmp eq i32 %4469, %11
  br i1 %.not326.us.us.us, label %"consume convolved230.us", label %"for convolved.s1.r19$y221.us.us.us"

"for convolved.s1.r19$y244.us.us.us":             ; preds = %after_bb235.us, %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us"
  %convolved313.sroa.0.52.us.us.us = phi <32 x i32> [ %4490, %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us" ], [ %convolved313.sroa.0.51.us, %after_bb235.us ]
  %"convolved.s1.r19$y246.us.us.us" = phi i32 [ %4493, %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us" ], [ 0, %after_bb235.us ]
  %4470 = mul nsw i32 %"convolved.s1.r19$y246.us.us.us", %dilation_y
  %4471 = add nsw i32 %4470, %4162
  %4472 = mul nsw i32 %4471, %19
  %t1201.us.us.us = add nsw i32 %4158, %4472
  %4473 = mul nsw i32 %"convolved.s1.r19$y246.us.us.us", %12
  %t1202.us.us.us = add nsw i32 %4473, %4261
  br label %"for convolved.s1.r19$x247.us.us.us.us"

"for convolved.s1.r19$x247.us.us.us.us":          ; preds = %"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us", %"for convolved.s1.r19$y244.us.us.us"
  %convolved313.sroa.0.53.us.us.us.us = phi <32 x i32> [ %4490, %"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us" ], [ %convolved313.sroa.0.52.us.us.us, %"for convolved.s1.r19$y244.us.us.us" ]
  %"convolved.s1.r19$x249.us.us.us.us" = phi i32 [ %4492, %"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us" ], [ 0, %"for convolved.s1.r19$y244.us.us.us" ]
  %4474 = mul nsw i32 %"convolved.s1.r19$x249.us.us.us.us", %dilation_x
  %t1203.s.us.us.us.us = add nsw i32 %4474, %4343
  %4475 = mul nsw i32 %t1203.s.us.us.us.us, %17
  %4476 = add nsw i32 %t1201.us.us.us, %4475
  %4477 = mul nsw i32 %"convolved.s1.r19$x249.us.us.us.us", %10
  %4478 = add nsw i32 %t1202.us.us.us, %4477
  br label %"for convolved.s1.r19$z.r124250.us.us.us.us"

"for convolved.s1.r19$z.r124250.us.us.us.us":     ; preds = %"for convolved.s1.r19$z.r124250.us.us.us.us", %"for convolved.s1.r19$x247.us.us.us.us"
  %convolved313.sroa.0.55.us.us.us.us = phi <32 x i32> [ %4490, %"for convolved.s1.r19$z.r124250.us.us.us.us" ], [ %convolved313.sroa.0.53.us.us.us.us, %"for convolved.s1.r19$x247.us.us.us.us" ]
  %"convolved.s1.r19$z.r124252.us.us.us.us" = phi i32 [ %4491, %"for convolved.s1.r19$z.r124250.us.us.us.us" ], [ 0, %"for convolved.s1.r19$x247.us.us.us.us" ]
  %4479 = shl nsw i32 %"convolved.s1.r19$z.r124252.us.us.us.us", 2
  %4480 = add nsw i32 %4476, %4479
  %4481 = getelementptr inbounds i8, i8* %13, i32 %4480
  %4482 = bitcast i8* %4481 to <4 x i8>*
  %4483 = load <4 x i8>, <4 x i8>* %4482, align 4, !tbaa !108
  %4484 = shl nsw i32 %"convolved.s1.r19$z.r124252.us.us.us.us", 7
  %4485 = add nsw i32 %4478, %4484
  %4486 = getelementptr inbounds i8, i8* %5, i32 %4485
  %4487 = bitcast i8* %4486 to <128 x i8>*
  %4488 = load <128 x i8>, <128 x i8>* %4487, align 128, !tbaa !106
  %4489 = call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %4483, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0) #11
  %4490 = call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %convolved313.sroa.0.55.us.us.us.us, <128 x i8> %4488, <32 x i32> %4489, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0) #11
  %4491 = add nuw nsw i32 %"convolved.s1.r19$z.r124252.us.us.us.us", 1
  %.not324.us.us.us.us = icmp eq i32 %4491, %7
  br i1 %.not324.us.us.us.us, label %"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us", label %"for convolved.s1.r19$z.r124250.us.us.us.us"

"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us": ; preds = %"for convolved.s1.r19$z.r124250.us.us.us.us"
  %4492 = add nuw nsw i32 %"convolved.s1.r19$x249.us.us.us.us", 1
  %.not323.us.us.us.us = icmp eq i32 %4492, %9
  br i1 %.not323.us.us.us.us, label %"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us", label %"for convolved.s1.r19$x247.us.us.us.us"

"end for convolved.s1.r19$x248.loopexit.split.us.us.us.us": ; preds = %"end for convolved.s1.r19$z.r124251.loopexit.us.us.us.us"
  %4493 = add nuw nsw i32 %"convolved.s1.r19$y246.us.us.us", 1
  %.not322.us.us.us = icmp eq i32 %4493, %11
  br i1 %.not322.us.us.us, label %"consume convolved253.us", label %"for convolved.s1.r19$y244.us.us.us"

"end for output.s0.y.rebased182":                 ; preds = %"end for output.s0.x.xo185.loopexit.us", %"for output.s0.y.rebased181.preheader", %"for output.s0.b.rebased178"
  %sum_input187312.sroa.0.23 = phi <32 x i32> [ %sum_input187312.sroa.0.21, %"for output.s0.b.rebased178" ], [ %sum_input187312.sroa.0.21, %"for output.s0.y.rebased181.preheader" ], [ %sum_input187312.sroa.0.34.us, %"end for output.s0.x.xo185.loopexit.us" ]
  %convolved313.sroa.0.37 = phi <32 x i32> [ %convolved313.sroa.0.35, %"for output.s0.b.rebased178" ], [ %convolved313.sroa.0.35, %"for output.s0.y.rebased181.preheader" ], [ %convolved313.sroa.0.50.us, %"end for output.s0.x.xo185.loopexit.us" ]
  %4494 = add nuw nsw i32 %output.s0.b.rebased180, 1
  %.not316 = icmp eq i32 %4494, %21
  br i1 %.not316, label %after_bb3, label %"for output.s0.b.rebased178"
}

; Function Attrs: nounwind
define i32 @conv_nn_hvx128_argv(i8** nocapture readonly %0) local_unnamed_addr #11 {
entry:
  %1 = bitcast i8** %0 to %struct.halide_buffer_t**
  %2 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %1, align 4
  %3 = getelementptr i8*, i8** %0, i32 1
  %4 = load i8*, i8** %3, align 4
  %5 = load i8, i8* %4, align 1
  %6 = getelementptr i8*, i8** %0, i32 2
  %7 = bitcast i8** %6 to %struct.halide_buffer_t**
  %8 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %7, align 4
  %9 = getelementptr i8*, i8** %0, i32 3
  %10 = load i8*, i8** %9, align 4
  %11 = load i8, i8* %10, align 1
  %12 = getelementptr i8*, i8** %0, i32 4
  %13 = bitcast i8** %12 to %struct.halide_buffer_t**
  %14 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %13, align 4
  %15 = getelementptr i8*, i8** %0, i32 5
  %16 = bitcast i8** %15 to i32**
  %17 = load i32*, i32** %16, align 4
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr i8*, i8** %0, i32 6
  %20 = bitcast i8** %19 to i32**
  %21 = load i32*, i32** %20, align 4
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr i8*, i8** %0, i32 7
  %24 = bitcast i8** %23 to i32**
  %25 = load i32*, i32** %24, align 4
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr i8*, i8** %0, i32 8
  %28 = bitcast i8** %27 to i32**
  %29 = load i32*, i32** %28, align 4
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr i8*, i8** %0, i32 9
  %32 = bitcast i8** %31 to i32**
  %33 = load i32*, i32** %32, align 4
  %34 = load i32, i32* %33, align 4
  %35 = getelementptr i8*, i8** %0, i32 10
  %36 = bitcast i8** %35 to i32**
  %37 = load i32*, i32** %36, align 4
  %38 = load i32, i32* %37, align 4
  %39 = getelementptr i8*, i8** %0, i32 11
  %40 = load i8*, i8** %39, align 4
  %41 = load i8, i8* %40, align 1
  %42 = getelementptr i8*, i8** %0, i32 12
  %43 = load i8*, i8** %42, align 4
  %44 = load i8, i8* %43, align 1
  %45 = getelementptr i8*, i8** %0, i32 13
  %46 = load i8*, i8** %45, align 4
  %47 = load i8, i8* %46, align 1
  %48 = getelementptr i8*, i8** %0, i32 14
  %49 = bitcast i8** %48 to %struct.halide_buffer_t**
  %50 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %49, align 4
  %51 = tail call i32 @conv_nn_hvx128(%struct.halide_buffer_t* %2, i8 %5, %struct.halide_buffer_t* %8, i8 %11, %struct.halide_buffer_t* %14, i32 %18, i32 %22, i32 %26, i32 %30, i32 %34, i32 %38, i8 %41, i8 %44, i8 %47, %struct.halide_buffer_t* %50) #16
  ret i32 0
}

; Function Attrs: norecurse nounwind readnone willreturn
define nonnull %struct.halide_filter_metadata_t* @conv_nn_hvx128_metadata() local_unnamed_addr #12 {
entry:
  ret %struct.halide_filter_metadata_t* @conv_nn_hvx128_metadata_storage
}

; Function Attrs: nofree nosync nounwind readnone willreturn
declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32>) #13

; Function Attrs: argmemonly nofree nosync nounwind willreturn writeonly
declare void @llvm.masked.store.v32i8.p0v32i8(<32 x i8>, <32 x i8>*, i32 immarg, <32 x i1>) #5

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.0(<128 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl(<32 x i32> %arg.2, <128 x i8> %arg.1, <128 x i8> %arg, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %0
}

declare <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl(<32 x i32>, <128 x i8>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.1(<32 x i32> %arg, <1 x i32> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %0, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %2
}

declare <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32>, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.2(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.3(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.4(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.5(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.6(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.7(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.8(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.9(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.10(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.11(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.12(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.13(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.14(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.15(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.16(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.17(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.18(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.19(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.20(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.21(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.22(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.23(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.24(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.25(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.26(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

declare <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8>, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32>, <128 x i8>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.27(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.28(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.29(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.30(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.31(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.32(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.33(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.34(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.35(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.36(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.37(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.38(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.39(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.40(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.41(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.42(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.43(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.44(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.45(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.46(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.47(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.48(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.49(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.50(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

declare <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32>, <1 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8>, i32, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8>, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

declare <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16>, <64 x i16>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8>, <128 x i16>, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16>, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8>, <64 x i16>, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16>, <64 x i16>, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16>, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32)

declare <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32)

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.51(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.52(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.53(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.54(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.55(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.56(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.57(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.58(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.59(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.60(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.61(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.62(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.63(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.64(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.65(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.66(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.67(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.68(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.69(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.70(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.71(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.72(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.73(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.74(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.75(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.76(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.77(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.78(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.79(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.80(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.81(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.82(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.83(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.84(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.85(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.86(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.87(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.88(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

declare <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32)

declare <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32>, <128 x i8>, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32>, <32 x i32>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16>, <64 x i16>, i32, i32, i32, i32, i32, i32, i32)

declare <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16>, <64 x i16>, i32, i32, i32, i32, i32, i32, i32)

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.89(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.90(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.91(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.92(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.93(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.94(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.95(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.96(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.97(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.98(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.99(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.100(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.101(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.102(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <64 x i16> @hydride.node.conv_nn_hvx_depth5.103(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <64 x i16> %arg.5) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %5, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %4, <1 x i32> zeroinitializer, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %3, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %9 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %10 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.3(<128 x i8> %9, <32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %11 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %13, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %12, <1 x i32> zeroinitializer, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %17, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %16, <1 x i32> zeroinitializer, <32 x i32> %18, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %20 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %15, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %21 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.4(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <128 x i8> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %24 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.2(<32 x i32> %11, <32 x i32> %23, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %25 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.2(<64 x i16> %arg.5, <64 x i16> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %26 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.5(<64 x i16> %25, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %27 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> zeroinitializer, <64 x i16> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  ret <64 x i16> %27
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.104(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.105(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.106(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.107(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.108(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.109(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.110(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.111(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.112(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.113(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.114(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.115(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.116(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.117(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.118(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.119(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.120(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.121(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.122(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.123(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.124(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.125(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.126(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.127(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.128(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.129(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.130(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.131(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.132(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.133(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.134(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.135(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <128 x i8> @hydride.node.conv_nn_hvx_depth5.136(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2, <32 x i32> %arg.3, <1 x i32> %arg.4, <32 x i32> %arg.5, <1 x i32> %arg.6, <32 x i32> %arg.7, <1 x i32> %arg.8, <128 x i16> %arg.9, <128 x i8> %arg.10, <128 x i8> %arg.11) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %6 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %7 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %8 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %5, <1 x i32> zeroinitializer, <32 x i32> %7, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %9 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %10 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %4, <32 x i32> %9, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %11 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %12 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %11, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %13 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %14 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %15 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %14, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %16 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %13, <1 x i32> zeroinitializer, <32 x i32> %15, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %17 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %16, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %18 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %19 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %20 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %19, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %21 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %18, <1 x i32> zeroinitializer, <32 x i32> %20, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %22 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %21, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %23 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %17, <32 x i32> %22, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %24 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %23, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %25 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %24, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %26 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %12, <32 x i32> %25, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %27 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %26, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %28 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %29 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %30 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %29, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %31 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %28, <1 x i32> zeroinitializer, <32 x i32> %30, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %32 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %31, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %33 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %34 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %35 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %34, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %36 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %33, <1 x i32> zeroinitializer, <32 x i32> %35, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %37 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %36, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %38 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %32, <32 x i32> %37, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %39 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %38, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %40 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %39, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %41 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %42 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %43 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %42, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %44 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %41, <1 x i32> zeroinitializer, <32 x i32> %43, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %45 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %44, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %46 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %47 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %48 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %47, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %49 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %46, <1 x i32> zeroinitializer, <32 x i32> %48, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %50 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %49, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %51 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %45, <32 x i32> %50, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %52 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %51, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %53 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %52, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %54 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %40, <32 x i32> %53, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %55 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %54, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %56 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %27, <128 x i8> %55, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %57 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %58 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %59 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %58, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %60 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %57, <1 x i32> zeroinitializer, <32 x i32> %59, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %61 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %60, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %62 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %63 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %64 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %63, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %65 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %62, <1 x i32> zeroinitializer, <32 x i32> %64, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %66 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %65, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %67 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %61, <32 x i32> %66, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %68 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %67, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %69 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %68, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %70 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %71 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %72 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %71, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %73 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %70, <1 x i32> zeroinitializer, <32 x i32> %72, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %74 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %73, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %75 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %76 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %77 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %76, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %78 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %75, <1 x i32> zeroinitializer, <32 x i32> %77, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %79 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %78, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %80 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %74, <32 x i32> %79, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %81 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %80, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %82 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %81, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %83 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %69, <32 x i32> %82, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %84 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %83, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %85 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %86 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %87 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %86, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %88 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %85, <1 x i32> zeroinitializer, <32 x i32> %87, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %89 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %88, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %90 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %91 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %92 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %91, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %93 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %90, <1 x i32> zeroinitializer, <32 x i32> %92, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %94 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %93, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %95 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %89, <32 x i32> %94, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %96 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %95, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %97 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %96, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %98 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %99 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %100 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %99, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %101 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %98, <1 x i32> zeroinitializer, <32 x i32> %100, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %102 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %101, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %103 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %104 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %105 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %104, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %106 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %103, <1 x i32> zeroinitializer, <32 x i32> %105, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %107 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %106, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %108 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %102, <32 x i32> %107, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %109 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %108, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %110 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %109, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %111 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %97, <32 x i32> %110, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %112 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %111, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %113 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %84, <128 x i8> %112, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %114 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %56, <64 x i16> %113, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %115 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %114, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %116 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %115, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %117 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %116, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %118 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %117, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %119 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %120 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %121 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %120, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %122 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %119, <1 x i32> zeroinitializer, <32 x i32> %121, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %123 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %122, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %124 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %125 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %126 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %125, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %127 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %124, <1 x i32> zeroinitializer, <32 x i32> %126, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %128 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %127, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %129 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %123, <32 x i32> %128, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %130 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %129, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %131 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %130, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %132 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %133 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %134 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %133, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %135 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %132, <1 x i32> zeroinitializer, <32 x i32> %134, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %136 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %135, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %137 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %138 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %139 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %138, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %140 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %137, <1 x i32> zeroinitializer, <32 x i32> %139, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %141 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %140, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %142 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %136, <32 x i32> %141, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %143 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %142, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %144 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %143, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %145 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %131, <32 x i32> %144, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %146 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %145, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %147 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %148 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %149 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %148, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %150 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %147, <1 x i32> zeroinitializer, <32 x i32> %149, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %151 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %150, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %152 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %153 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %154 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %153, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %155 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %152, <1 x i32> zeroinitializer, <32 x i32> %154, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %156 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %155, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %157 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %151, <32 x i32> %156, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %158 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %157, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %159 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %158, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %160 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %161 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %162 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %161, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %163 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %160, <1 x i32> zeroinitializer, <32 x i32> %162, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %164 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %163, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %165 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %166 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %167 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %166, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %168 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %165, <1 x i32> zeroinitializer, <32 x i32> %167, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %169 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %168, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %170 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %164, <32 x i32> %169, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %171 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %170, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %172 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %171, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %173 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %159, <32 x i32> %172, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %174 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %173, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %175 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %146, <128 x i8> %174, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %176 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %177 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %178 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %177, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %179 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %176, <1 x i32> zeroinitializer, <32 x i32> %178, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %180 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %179, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %181 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %182 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %183 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %182, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %184 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %181, <1 x i32> zeroinitializer, <32 x i32> %183, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %185 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %184, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %186 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %180, <32 x i32> %185, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %187 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %186, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %188 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %187, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %189 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %190 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %191 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %190, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %192 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %189, <1 x i32> zeroinitializer, <32 x i32> %191, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %193 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %192, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %194 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %195 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %196 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %195, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %197 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %194, <1 x i32> zeroinitializer, <32 x i32> %196, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %198 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %197, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %199 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %193, <32 x i32> %198, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %200 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %199, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %201 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %200, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %202 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %188, <32 x i32> %201, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %203 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %202, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %204 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %205 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %206 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %205, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %207 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %204, <1 x i32> zeroinitializer, <32 x i32> %206, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %208 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %207, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %209 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %210 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %211 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %210, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %212 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %209, <1 x i32> zeroinitializer, <32 x i32> %211, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %213 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %212, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %214 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %208, <32 x i32> %213, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %215 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %214, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %216 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %215, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %217 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %218 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %219 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %218, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %220 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %217, <1 x i32> zeroinitializer, <32 x i32> %219, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %221 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %220, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %222 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %223 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %224 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %223, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %225 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %222, <1 x i32> zeroinitializer, <32 x i32> %224, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %226 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %225, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %227 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %221, <32 x i32> %226, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %228 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %227, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %229 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %228, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %230 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %216, <32 x i32> %229, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %231 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %230, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %232 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %203, <128 x i8> %231, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %233 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %175, <64 x i16> %232, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %234 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %233, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %235 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %234, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %236 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %235, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %237 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %236, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %238 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %118, <64 x i16> %237, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %239 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %238, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %240 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %241 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %242 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %241, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %243 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %240, <1 x i32> zeroinitializer, <32 x i32> %242, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %244 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %243, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %245 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %246 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %247 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %246, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %248 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %245, <1 x i32> zeroinitializer, <32 x i32> %247, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %249 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %248, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %250 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %244, <32 x i32> %249, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %251 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %250, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %252 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %251, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %253 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %254 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %255 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %254, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %256 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %253, <1 x i32> zeroinitializer, <32 x i32> %255, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %257 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %256, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %258 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %259 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %260 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %259, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %261 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %258, <1 x i32> zeroinitializer, <32 x i32> %260, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %262 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %261, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %263 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %257, <32 x i32> %262, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %264 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %263, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %265 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %264, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %266 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %252, <32 x i32> %265, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %267 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %266, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %268 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %269 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %270 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %269, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %271 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %268, <1 x i32> zeroinitializer, <32 x i32> %270, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %272 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %271, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %273 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %274 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %275 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %274, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %276 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %273, <1 x i32> zeroinitializer, <32 x i32> %275, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %277 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %276, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %278 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %272, <32 x i32> %277, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %279 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %278, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %280 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %279, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %281 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %282 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %283 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %282, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %284 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %281, <1 x i32> zeroinitializer, <32 x i32> %283, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %285 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %284, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %286 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %287 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %288 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %287, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %289 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %286, <1 x i32> zeroinitializer, <32 x i32> %288, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %290 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %289, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %291 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %285, <32 x i32> %290, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %292 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %291, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %293 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %292, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %294 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %280, <32 x i32> %293, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %295 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %294, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %296 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %267, <128 x i8> %295, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %297 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %298 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %299 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %298, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %300 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %297, <1 x i32> zeroinitializer, <32 x i32> %299, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %301 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %300, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %302 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %303 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %304 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %303, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %305 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %302, <1 x i32> zeroinitializer, <32 x i32> %304, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %306 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %305, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %307 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %301, <32 x i32> %306, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %308 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %307, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %309 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %308, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %310 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %311 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %312 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %311, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %313 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %310, <1 x i32> zeroinitializer, <32 x i32> %312, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %314 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %313, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %315 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %316 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %317 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %316, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %318 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %315, <1 x i32> zeroinitializer, <32 x i32> %317, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %319 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %318, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %320 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %314, <32 x i32> %319, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %321 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %320, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %322 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %321, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %323 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %309, <32 x i32> %322, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %324 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %323, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %325 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %326 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %327 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %326, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %328 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %325, <1 x i32> zeroinitializer, <32 x i32> %327, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %329 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %328, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %330 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %331 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %332 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %331, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %333 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %330, <1 x i32> zeroinitializer, <32 x i32> %332, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %334 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %333, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %335 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %329, <32 x i32> %334, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %336 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %335, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %337 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %336, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %338 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %339 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %340 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %339, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %341 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %338, <1 x i32> zeroinitializer, <32 x i32> %340, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %342 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %341, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %343 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %344 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %345 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %344, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %346 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %343, <1 x i32> zeroinitializer, <32 x i32> %345, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %347 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %346, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %348 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %342, <32 x i32> %347, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %349 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %348, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %350 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %349, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %351 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %337, <32 x i32> %350, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %352 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %351, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %353 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %324, <128 x i8> %352, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %354 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %296, <64 x i16> %353, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %355 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %354, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %356 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl.1(<128 x i16> %355, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %357 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %356, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %358 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %357, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %359 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %360 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %361 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %360, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %362 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %359, <1 x i32> zeroinitializer, <32 x i32> %361, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %363 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %362, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %364 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %365 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %366 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %365, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %367 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %364, <1 x i32> zeroinitializer, <32 x i32> %366, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %368 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %367, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %369 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %363, <32 x i32> %368, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %370 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %369, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %371 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %370, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %372 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %373 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %374 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %373, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %375 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %372, <1 x i32> zeroinitializer, <32 x i32> %374, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %376 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %375, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %377 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %378 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %379 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %378, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %380 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %377, <1 x i32> zeroinitializer, <32 x i32> %379, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %381 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %380, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %382 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %376, <32 x i32> %381, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %383 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %382, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %384 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %383, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %385 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %371, <32 x i32> %384, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %386 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %385, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %387 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %388 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %389 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %388, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %390 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %387, <1 x i32> zeroinitializer, <32 x i32> %389, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %391 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %390, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %392 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %393 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %394 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %393, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %395 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %392, <1 x i32> zeroinitializer, <32 x i32> %394, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %396 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %395, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %397 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %391, <32 x i32> %396, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %398 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %397, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %399 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %398, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %400 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %401 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %402 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %401, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %403 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %400, <1 x i32> zeroinitializer, <32 x i32> %402, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %404 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %403, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %405 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %406 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.4, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %407 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.3, <32 x i32> %406, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %408 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %405, <1 x i32> zeroinitializer, <32 x i32> %407, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %409 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %408, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %410 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %404, <32 x i32> %409, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %411 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %410, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %412 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %411, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %413 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %399, <32 x i32> %412, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %414 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %413, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %415 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %386, <128 x i8> %414, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %416 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %417 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %418 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %417, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %419 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %416, <1 x i32> zeroinitializer, <32 x i32> %418, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %420 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %419, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %421 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %422 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %423 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %422, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %424 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %421, <1 x i32> zeroinitializer, <32 x i32> %423, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %425 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %424, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %426 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %420, <32 x i32> %425, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %427 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %426, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %428 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %427, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %429 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %430 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %431 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %430, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %432 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %429, <1 x i32> zeroinitializer, <32 x i32> %431, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %433 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %432, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %434 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %435 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %436 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %435, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %437 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %434, <1 x i32> zeroinitializer, <32 x i32> %436, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %438 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %437, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %439 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %433, <32 x i32> %438, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %440 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %439, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %441 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %440, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %442 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %428, <32 x i32> %441, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %443 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %442, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %444 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %445 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %446 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %445, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %447 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %444, <1 x i32> zeroinitializer, <32 x i32> %446, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %448 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %447, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %449 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %450 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %451 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %450, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %452 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %449, <1 x i32> zeroinitializer, <32 x i32> %451, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %453 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %452, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %454 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %448, <32 x i32> %453, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %455 = tail call <128 x i8> @llvm.hydride.hexagon_V6_lo_128B_dsl(<256 x i8> %454, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %456 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl(<128 x i8> %455, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %457 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %458 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.6, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %459 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.5, <32 x i32> %458, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %460 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %457, <1 x i32> zeroinitializer, <32 x i32> %459, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %461 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %460, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %462 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %463 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.8, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %464 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg.7, <32 x i32> %463, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %465 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %462, <1 x i32> zeroinitializer, <32 x i32> %464, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %466 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %465, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %467 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %461, <32 x i32> %466, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %468 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %467, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %469 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.1(<32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, <128 x i8> %468, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %470 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl(<32 x i32> %456, <32 x i32> %469, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %471 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %470, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %472 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl(<128 x i8> %443, <128 x i8> %471, i32 1024, i32 1024, i32 0, i32 512, i32 16, i32 0, i32 512, i32 16, i32 2, i32 32, i32 2, i32 16, i32 0)
  %473 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %415, <64 x i16> %472, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %474 = tail call <128 x i16> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl.1(<256 x i8> %473, <128 x i16> %arg.9, i32 2048, i32 2048, i32 0, i32 2048, i32 16, i32 1, i32 0)
  %475 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl.1(<128 x i16> %474, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %476 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.1(<128 x i8> %475, <64 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %477 = tail call <64 x i16> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.2(<64 x i16> %476, <64 x i16> zeroinitializer, i32 1024, i32 1024, i32 0, i32 1024, i32 16, i32 1, i32 0)
  %478 = tail call <256 x i8> @llvm.hydride.hexagon_V6_vcombine_128B_dsl.1(<64 x i16> %358, <64 x i16> %477, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 1024, i32 8, i32 1024, i32 0)
  %479 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vassign_128B_dsl(<256 x i8> %478, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0)
  %480 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vpackeh_128B_dsl.1(<128 x i8> %239, <128 x i8> %479, i32 1024, i32 1024, i32 0, i32 512, i32 8, i32 0, i32 512, i32 8, i32 2, i32 64, i32 2, i32 8, i32 0)
  %481 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vminuh_128B_dsl.2(<128 x i8> %480, <128 x i8> %arg.10, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  %482 = tail call <128 x i8> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.3(<128 x i8> %arg.11, <128 x i8> %481, i32 1024, i32 1024, i32 0, i32 1024, i32 8, i32 0, i32 0)
  ret <128 x i8> %482
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.137(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.138(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.139(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.140(<32 x i32> %arg, <1 x i32> %arg.1) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vsubh_128B_dsl(<32 x i32> %arg, <32 x i32> %0, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 -1, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.141(<4 x i8> %arg, <128 x i8> %arg.1, <32 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl.1(<4 x i8> %arg, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vrmpybv_128B_dsl.1(<32 x i32> %arg.2, <128 x i8> %arg.1, <32 x i32> %0, i32 1024, i32 32, i32 0, i32 32, i32 8, i32 -1, i32 0, i32 0, i32 16, i32 0, i32 0)
  ret <32 x i32> %1
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.142(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

define <32 x i32> @hydride.node.conv_nn_hvx_depth5.143(<32 x i32> %arg, <1 x i32> %arg.1, <1 x i32> %arg.2) local_unnamed_addr {
entry:
  %0 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %1 = tail call <32 x i32> @llvm.hydride.hexagon_V6_lvsplatw_128B_dsl(<1 x i32> %arg.1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 0)
  %2 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vaddhsat_128B_dsl(<32 x i32> %arg, <32 x i32> %1, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %3 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vasrhv_128B_dsl(<32 x i32> %0, <1 x i32> zeroinitializer, <32 x i32> %2, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %4 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vminuh_128B_dsl(<32 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>, <32 x i32> %3, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  %5 = tail call <32 x i32> @llvm.hydride.hexagon_V6_vmaxw_128B_dsl.4(<32 x i32> %4, <32 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>, i32 1024, i32 1024, i32 0, i32 1024, i32 32, i32 1, i32 0)
  ret <32 x i32> %5
}

; Function Attrs: argmemonly nofree nosync nounwind willreturn
declare void @llvm.memmove.p0i8.p0i8.i32(i8* nocapture writeonly, i8* nocapture readonly, i32, i1 immarg) #3

attributes #0 = { nounwind mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-builtins" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind willreturn mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { argmemonly nofree nosync nounwind willreturn }
attributes #4 = { nounwind "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { argmemonly nofree nosync nounwind willreturn writeonly }
attributes #6 = { alwaysinline nounwind willreturn mustprogress "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind willreturn "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nofree nosync nounwind readnone speculatable willreturn }
attributes #9 = { nounwind readnone }
attributes #10 = { nounwind "reciprocal-estimates"="none" }
attributes #11 = { nounwind }
attributes #12 = { norecurse nounwind readnone willreturn }
attributes #13 = { nofree nosync nounwind readnone willreturn }
attributes #14 = { nobuiltin nounwind "no-builtins" }
attributes #15 = { nobuiltin "no-builtins" }
attributes #16 = { noinline }

!llvm.module.flags = !{!0, !1, !2, !3, !4, !5, !6, !7, !8}
!llvm.ident = !{!9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9, !9}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 1}
!2 = !{i32 2, !"halide_use_soft_float_abi", i32 0}
!3 = !{i32 2, !"halide_mcpu", !"hexagonv66"}
!4 = !{i32 2, !"halide_mattrs", !"+hvx-length128b,+long-calls,+hvxv66"}
!5 = !{i32 2, !"halide_mabi", !""}
!6 = !{i32 2, !"halide_use_pic", i32 1}
!7 = !{i32 2, !"halide_use_large_code_model", i32 0}
!8 = !{i32 2, !"halide_per_instruction_fast_math_flags", i32 0}
!9 = !{!"clang version 12.0.1 (https://github.com/llvm/llvm-project.git fed41342a82f5a3a9201819a82bf7a48313e296b)"}
!10 = !{!11, !11, i64 0}
!11 = !{!"any pointer", !12, i64 0}
!12 = !{!"omnipotent char", !13, i64 0}
!13 = !{!"Simple C++ TBAA"}
!14 = !{!15, !15, i64 0}
!15 = !{!"int", !12, i64 0}
!16 = distinct !{!16, !17}
!17 = !{!"llvm.loop.mustprogress"}
!18 = !{!19, !19, i64 0}
!19 = !{!"bool", !12, i64 0}
!20 = distinct !{!20, !17}
!21 = !{i8 0, i8 2}
!22 = !{!12, !12, i64 0}
!23 = distinct !{!23, !17}
!24 = !{!25, !25, i64 0}
!25 = !{!"double", !12, i64 0}
!26 = !{!27, !27, i64 0}
!27 = !{!"long long", !12, i64 0}
!28 = distinct !{!28, !17}
!29 = distinct !{!29, !17}
!30 = distinct !{!30, !17}
!31 = distinct !{!31, !32}
!32 = !{!"llvm.loop.unroll.disable"}
!33 = distinct !{!33, !17}
!34 = !{!35, !36, i64 0}
!35 = !{!"_ZTS13halide_type_t", !36, i64 0, !12, i64 1, !37, i64 2}
!36 = !{!"_ZTS18halide_type_code_t", !12, i64 0}
!37 = !{!"short", !12, i64 0}
!38 = !{!35, !12, i64 1}
!39 = !{!35, !37, i64 2}
!40 = !{!41, !27, i64 0}
!41 = !{!"_ZTS15halide_buffer_t", !27, i64 0, !11, i64 8, !11, i64 12, !27, i64 16, !35, i64 24, !15, i64 28, !11, i64 32, !11, i64 36}
!42 = !{!41, !11, i64 8}
!43 = !{!41, !11, i64 12}
!44 = !{!41, !27, i64 16}
!45 = !{!41, !15, i64 28}
!46 = !{!41, !11, i64 32}
!47 = !{!48, !15, i64 0}
!48 = !{!"_ZTS18halide_dimension_t", !15, i64 0, !15, i64 4, !15, i64 8, !15, i64 12}
!49 = !{!48, !15, i64 4}
!50 = !{!48, !15, i64 8}
!51 = distinct !{!51, !17}
!52 = !{!53, !11, i64 0}
!53 = !{!"_ZTS29halide_device_allocation_pool", !11, i64 0, !11, i64 4}
!54 = distinct !{!54, !17}
!55 = !{!53, !11, i64 4}
!56 = distinct !{!56, !17}
!57 = !{!58, !27, i64 0}
!58 = !{!"_ZTSN6Halide7Runtime8Internal11device_copyE", !27, i64 0, !27, i64 8, !27, i64 16, !12, i64 24, !12, i64 152, !12, i64 280, !27, i64 408}
!59 = !{!58, !27, i64 8}
!60 = !{!58, !27, i64 408}
!61 = distinct !{!61, !17}
!62 = !{!58, !27, i64 16}
!63 = distinct !{!63, !32}
!64 = distinct !{!64, !17}
!65 = distinct !{!65, !17}
!66 = distinct !{!66, !32}
!67 = distinct !{!67, !17}
!68 = distinct !{!68, !17}
!69 = distinct !{!69, !17}
!70 = !{i64 0, i64 8, !26, i64 8, i64 8, !26, i64 16, i64 8, !26, i64 24, i64 128, !22, i64 152, i64 128, !22, i64 280, i64 128, !22, i64 408, i64 8, !26}
!71 = !{!72, !11, i64 60}
!72 = !{!"_ZTS25halide_device_interface_t", !11, i64 0, !11, i64 4, !11, i64 8, !11, i64 12, !11, i64 16, !11, i64 20, !11, i64 24, !11, i64 28, !11, i64 32, !11, i64 36, !11, i64 40, !11, i64 44, !11, i64 48, !11, i64 52, !11, i64 56, !11, i64 60}
!73 = !{!74, !11, i64 24}
!74 = !{!"_ZTS30halide_device_interface_impl_t", !11, i64 0, !11, i64 4, !11, i64 8, !11, i64 12, !11, i64 16, !11, i64 20, !11, i64 24, !11, i64 28, !11, i64 32, !11, i64 36, !11, i64 40, !11, i64 44, !11, i64 48, !11, i64 52, !11, i64 56, !11, i64 60}
!75 = !{!74, !11, i64 20}
!76 = !{!74, !11, i64 28}
!77 = !{!74, !11, i64 0}
!78 = !{!74, !11, i64 8}
!79 = !{!74, !11, i64 4}
!80 = !{!74, !11, i64 16}
!81 = !{!74, !11, i64 12}
!82 = !{!74, !11, i64 32}
!83 = !{!74, !11, i64 36}
!84 = distinct !{!84, !32}
!85 = distinct !{!85, !32}
!86 = distinct !{!86, !17}
!87 = distinct !{!87, !17}
!88 = !{!74, !11, i64 56}
!89 = !{!74, !11, i64 60}
!90 = !{!74, !11, i64 40}
!91 = !{!74, !11, i64 44}
!92 = !{!74, !11, i64 48}
!93 = !{!74, !11, i64 52}
!94 = !{i32 22, i32 33}
!95 = !{!"branch_weights", i32 0, i32 1073741824}
!96 = !{!"branch_weights", i32 1073741824, i32 0}
!97 = !{!98, !98, i64 0}
!98 = !{!"bias", !99, i64 0}
!99 = !{!"Halide buffer"}
!100 = !{!101, !101, i64 0}
!101 = !{!"bias_im_global_wrapper$0", !99, i64 0}
!102 = distinct !{!102, !32}
!103 = !{!"branch_weights", i32 -2147483648, i32 0}
!104 = !{!105, !105, i64 0}
!105 = !{!"offset_c", !99, i64 0}
!106 = !{!107, !107, i64 0}
!107 = !{!"filter", !99, i64 0}
!108 = !{!109, !109, i64 0}
!109 = !{!"input", !99, i64 0}
!110 = distinct !{!110, !32}
!111 = !{!112, !112, i64 0}
!112 = !{!"output", !99, i64 0}
!113 = distinct !{!113, !32}
!114 = distinct !{!114, !32}
!115 = distinct !{!115, !32}
!116 = distinct !{!116, !32}
!117 = distinct !{!117, !32}
!118 = !{!"branch_weights", i32 -2147483648, i32 -2147483648}
!119 = distinct !{!119, !32}
