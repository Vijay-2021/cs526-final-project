#ifndef blur5x5_batch_0015_sample_0001_SCHEDULE_H
#define blur5x5_batch_0015_sample_0001_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=x86-64-linux-avx-avx2-avx512-avx512_sapphirerapids-avx512_skylake-disable_llvm_loop_opt-f16c-fma-sse41  // NOLINT
// with machine_params=10,16777216,40

#include "Halide.h"


inline void apply_schedule_blur5x5_batch_0015_sample_0001(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func blur_y = pipeline.get_func(4);
    Func blur_x = pipeline.get_func(3);
    Func repeat_edge = pipeline.get_func(2);
    Func lambda_0 = pipeline.get_func(1);
    Var _0(repeat_edge.get_schedule().dims()[0].var);
    Var _0i("_0i");
    Var _1(repeat_edge.get_schedule().dims()[1].var);
    Var x(blur_y.get_schedule().dims()[0].var);
    Var xi("xi");
    Var xii("xii");
    Var y(blur_y.get_schedule().dims()[1].var);
    Var yi("yi");
    Var yii("yii");
    blur_y
        .split(y, y, yi, 36, TailStrategy::ShiftInwards)
        .split(yi, yi, yii, 9, TailStrategy::ShiftInwards)
        .split(x, x, xi, 64, TailStrategy::ShiftInwards)
        .split(xi, xi, xii, 32, TailStrategy::ShiftInwards)
        .unroll(xi)
        .vectorize(xii)
        .compute_root()
        .reorder({xii, xi, yii, x, yi, y})
        .parallel(y);
    blur_x
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 32, TailStrategy::RoundUp)
        .unroll(x)
        .unroll(y)
        .vectorize(xi)
        .compute_at(blur_y, yii)
        .store_at(blur_y, x)
        .reorder({xi, x, y});
    repeat_edge
        .store_in(MemoryType::Stack)
        .split(_0, _0, _0i, 32, TailStrategy::ShiftInwards)
        .vectorize(_0i)
        .compute_at(blur_y, yi)
        .store_at(blur_y, y)
        .reorder({_0i, _0, _1});

}

#endif  // blur5x5_batch_0015_sample_0001_SCHEDULE_H
