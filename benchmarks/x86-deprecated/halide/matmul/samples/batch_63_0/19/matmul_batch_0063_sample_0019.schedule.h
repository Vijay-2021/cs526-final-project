#ifndef matmul_batch_0063_sample_0019_SCHEDULE_H
#define matmul_batch_0063_sample_0019_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=x86-64-linux-avx-avx2-disable_llvm_loop_opt-f16c-fma-sse41  // NOLINT
// with machine_params=32,24000000,40

#include "Halide.h"


inline void apply_schedule_matmul_batch_0063_sample_0019(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func output = pipeline.get_func(11);
    Func scaled_plus_offset = pipeline.get_func(10);
    Func multiplied = pipeline.get_func(9);
    Func row_sums_a = pipeline.get_func(8);
    Func sum = pipeline.get_func(7);
    Func multiplied_no_offsets = pipeline.get_func(6);
    Func mat_b_swizzled = pipeline.get_func(5);
    Func column_sums_b = pipeline.get_func(3);
    Func sum_1 = pipeline.get_func(2);
    Var k(mat_b_swizzled.get_schedule().dims()[2].var);
    Var x(output.get_schedule().dims()[0].var);
    Var xi("xi");
    Var xii("xii");
    Var xiii("xiii");
    Var y(output.get_schedule().dims()[1].var);
    Var yi("yi");
    Var yii("yii");
    RVar fk_x(sum.update(0).get_schedule().dims()[0].var);
    RVar k_x(multiplied_no_offsets.update(0).get_schedule().dims()[0].var);
    output
        .split(x, x, xi, 960, TailStrategy::ShiftInwards)
        .split(y, y, yi, 68, TailStrategy::ShiftInwards)
        .split(xi, xi, xii, 96, TailStrategy::ShiftInwards)
        .split(yi, yi, yii, 4, TailStrategy::ShiftInwards)
        .split(xii, xii, xiii, 32, TailStrategy::ShiftInwards)
        .unroll(xii)
        .unroll(yii)
        .vectorize(xiii)
        .compute_root()
        .reorder({xiii, xii, yii, yi, xi, x, y})
        .fuse(x, y, x)
        .parallel(x);
    scaled_plus_offset
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 8, TailStrategy::ShiftInwards)
        .unroll(x)
        .vectorize(xi)
        .compute_at(output, xii)
        .reorder({xi, x, y});
    multiplied
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 16, TailStrategy::RoundUp)
        .unroll(x)
        .vectorize(xi)
        .compute_at(output, xii)
        .reorder({xi, x, y});
    row_sums_a
        .split(y, y, yi, 8, TailStrategy::RoundUp)
        .unroll(y)
        .vectorize(yi)
        .compute_at(output, x)
        .reorder({yi, y});
    sum
        .split(y, y, yi, 8, TailStrategy::RoundUp)
        .vectorize(yi)
        .compute_root()
        .reorder({yi, y})
        .parallel(y);
    sum.update(0)
        .split(y, y, yi, 32, TailStrategy::GuardWithIf)
        .vectorize(yi)
        .reorder({yi, fk_x, y})
        .parallel(y);
    multiplied_no_offsets
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 8, TailStrategy::RoundUp)
        .vectorize(xi)
        .compute_at(output, yi)
        .reorder({xi, x, y});
    multiplied_no_offsets.update(0)
        .split(x, x, xi, 32, TailStrategy::GuardWithIf)
        .unroll(x)
        .unroll(y)
        .vectorize(xi)
        .reorder({xi, x, y, k_x});
    mat_b_swizzled
        .split(y, y, yi, 8, TailStrategy::ShiftInwards)
        .split(x, x, xi, 32, TailStrategy::ShiftInwards)
        .vectorize(xi)
        .compute_root()
        .reorder({xi, x, yi, k, y})
        .parallel(y);
    column_sums_b
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 8, TailStrategy::RoundUp)
        .unroll(x)
        .vectorize(xi)
        .compute_at(output, xi)
        .reorder({xi, x});
    sum_1
        .split(x, x, xi, 16, TailStrategy::RoundUp)
        .split(xi, xi, xii, 8, TailStrategy::RoundUp)
        .unroll(xi)
        .vectorize(xii)
        .compute_root()
        .reorder({xii, xi, x})
        .parallel(x);
    sum_1.update(0)
        .split(x, x, xi, 32, TailStrategy::GuardWithIf)
        .vectorize(xi)
        .reorder({xi, fk_x, x})
        .parallel(x);

}

#endif  // matmul_batch_0063_sample_0019_SCHEDULE_H
