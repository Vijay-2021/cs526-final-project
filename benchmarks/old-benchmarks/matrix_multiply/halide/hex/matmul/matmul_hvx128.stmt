module name=matmul, target=hexagon-64-linux-hvx-hvx_128
external_plus_metadata func matmul (A, B, out) {
assert((uint64)reinterpret((halide_buffer_t *)out.buffer) != (uint64)0, halide_error_buffer_argument_is_null("out"))
assert((uint64)reinterpret((halide_buffer_t *)B.buffer) != (uint64)0, halide_error_buffer_argument_is_null("B"))
assert((uint64)reinterpret((halide_buffer_t *)A.buffer) != (uint64)0, halide_error_buffer_argument_is_null("A"))
let A = (void *)_halide_buffer_get_host((halide_buffer_t *)A.buffer)
let A.type = (uint32)_halide_buffer_get_type((halide_buffer_t *)A.buffer)
let A.dimensions = _halide_buffer_get_dimensions((halide_buffer_t *)A.buffer)
let A.min.0 = _halide_buffer_get_min((halide_buffer_t *)A.buffer, 0)
let A.extent.0 = _halide_buffer_get_extent((halide_buffer_t *)A.buffer, 0)
let A.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)A.buffer, 0)
let A.min.1 = _halide_buffer_get_min((halide_buffer_t *)A.buffer, 1)
let A.extent.1 = _halide_buffer_get_extent((halide_buffer_t *)A.buffer, 1)
let A.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)A.buffer, 1)
let B = (void *)_halide_buffer_get_host((halide_buffer_t *)B.buffer)
let B.type = (uint32)_halide_buffer_get_type((halide_buffer_t *)B.buffer)
let B.dimensions = _halide_buffer_get_dimensions((halide_buffer_t *)B.buffer)
let B.min.0 = _halide_buffer_get_min((halide_buffer_t *)B.buffer, 0)
let B.extent.0 = _halide_buffer_get_extent((halide_buffer_t *)B.buffer, 0)
let B.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)B.buffer, 0)
let B.min.1 = _halide_buffer_get_min((halide_buffer_t *)B.buffer, 1)
let B.extent.1 = _halide_buffer_get_extent((halide_buffer_t *)B.buffer, 1)
let B.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)B.buffer, 1)
let out = (void *)_halide_buffer_get_host((halide_buffer_t *)out.buffer)
let out.type = (uint32)_halide_buffer_get_type((halide_buffer_t *)out.buffer)
let out.dimensions = _halide_buffer_get_dimensions((halide_buffer_t *)out.buffer)
let out.min.0 = _halide_buffer_get_min((halide_buffer_t *)out.buffer, 0)
let out.extent.0 = _halide_buffer_get_extent((halide_buffer_t *)out.buffer, 0)
let out.stride.0 = _halide_buffer_get_stride((halide_buffer_t *)out.buffer, 0)
let out.min.1 = _halide_buffer_get_min((halide_buffer_t *)out.buffer, 1)
let out.extent.1 = _halide_buffer_get_extent((halide_buffer_t *)out.buffer, 1)
let out.stride.1 = _halide_buffer_get_stride((halide_buffer_t *)out.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)A.buffer)) {
 (halide_buffer_t *)_halide_buffer_init((halide_buffer_t *)A.buffer, (halide_dimension_t *)_halide_buffer_get_shape((halide_buffer_t *)A.buffer), (void *)reinterpret((uint64)0), (uint64)0, (halide_device_interface_t *)reinterpret((uint64)0), 1, 16, 2, (halide_dimension_t *)make_struct(0, 128, 1, 0, 0, 128, 128, 0), (uint64)0)
}
if ((uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)B.buffer)) {
 (halide_buffer_t *)_halide_buffer_init((halide_buffer_t *)B.buffer, (halide_dimension_t *)_halide_buffer_get_shape((halide_buffer_t *)B.buffer), (void *)reinterpret((uint64)0), (uint64)0, (halide_device_interface_t *)reinterpret((uint64)0), 1, 16, 2, (halide_dimension_t *)make_struct(0, 144, 1, 0, 0, 128, 144, 0), (uint64)0)
}
if ((uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)out.buffer)) {
 (halide_buffer_t *)_halide_buffer_init((halide_buffer_t *)out.buffer, (halide_dimension_t *)_halide_buffer_get_shape((halide_buffer_t *)out.buffer), (void *)reinterpret((uint64)0), (uint64)0, (halide_device_interface_t *)reinterpret((uint64)0), 1, 16, 2, (halide_dimension_t *)make_struct(0, 128, 1, 0, 0, 128, 128, 0), (uint64)0)
}
if (!((uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)out.buffer) || ((uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)A.buffer) || (uint1)_halide_buffer_is_bounds_query((halide_buffer_t *)B.buffer)))) {
 assert(A.type == (uint32)69633, halide_error_bad_type("Input buffer A", A.type, (uint32)69633))
 assert(A.dimensions == 2, halide_error_bad_dimensions("Input buffer A", A.dimensions, 2))
 assert(B.type == (uint32)69633, halide_error_bad_type("Input buffer B", B.type, (uint32)69633))
 assert(B.dimensions == 2, halide_error_bad_dimensions("Input buffer B", B.dimensions, 2))
 assert(out.type == (uint32)69633, halide_error_bad_type("Output buffer out", out.type, (uint32)69633))
 assert(out.dimensions == 2, halide_error_bad_dimensions("Output buffer out", out.dimensions, 2))
 assert((A.min.0 <= 0) && (128 <= (A.extent.0 + A.min.0)), halide_error_access_out_of_bounds("Input buffer A", 0, 0, 127, A.min.0, (A.extent.0 + A.min.0) + -1))
 assert(0 <= A.extent.0, halide_error_buffer_extents_negative("Input buffer A", 0, A.extent.0))
 assert((A.min.1 <= 0) && (128 <= (A.extent.1 + A.min.1)), halide_error_access_out_of_bounds("Input buffer A", 1, 0, 127, A.min.1, (A.extent.1 + A.min.1) + -1))
 assert(0 <= A.extent.1, halide_error_buffer_extents_negative("Input buffer A", 1, A.extent.1))
 assert((B.min.0 <= 0) && (144 <= (B.extent.0 + B.min.0)), halide_error_access_out_of_bounds("Input buffer B", 0, 0, 143, B.min.0, (B.extent.0 + B.min.0) + -1))
 assert(0 <= B.extent.0, halide_error_buffer_extents_negative("Input buffer B", 0, B.extent.0))
 assert((B.min.1 <= 0) && (128 <= (B.extent.1 + B.min.1)), halide_error_access_out_of_bounds("Input buffer B", 1, 0, 127, B.min.1, (B.extent.1 + B.min.1) + -1))
 assert(0 <= B.extent.1, halide_error_buffer_extents_negative("Input buffer B", 1, B.extent.1))
 assert((out.min.0 <= 0) && (128 <= (out.extent.0 + out.min.0)), halide_error_access_out_of_bounds("Output buffer out", 0, 0, 127, out.min.0, (out.extent.0 + out.min.0) + -1))
 assert(0 <= out.extent.0, halide_error_buffer_extents_negative("Output buffer out", 0, out.extent.0))
 assert((out.min.1 <= 0) && (128 <= (out.extent.1 + out.min.1)), halide_error_access_out_of_bounds("Output buffer out", 1, 0, 127, out.min.1, (out.extent.1 + out.min.1) + -1))
 assert(0 <= out.extent.1, halide_error_buffer_extents_negative("Output buffer out", 1, out.extent.1))
 assert(A.stride.0 == 1, halide_error_constraint_violated("A.stride.0", A.stride.0, "1", 1))
 assert(B.stride.0 == 1, halide_error_constraint_violated("B.stride.0", B.stride.0, "1", 1))
 assert(out.stride.0 == 1, halide_error_constraint_violated("out.stride.0", out.stride.0, "1", 1))
 let A.total_extent.1 = int64(A.extent.1)*int64(A.extent.0)
 let B.total_extent.1 = int64(B.extent.1)*int64(B.extent.0)
 let out.total_extent.1 = int64(out.extent.1)*int64(out.extent.0)
 assert(uint64(A.extent.0) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("A", uint64(A.extent.0), (uint64)2147483647))
 assert((uint64)abs(int64(A.extent.1)*int64(A.stride.1)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("A", (uint64)abs(int64(A.extent.1)*int64(A.stride.1)), (uint64)2147483647))
 assert(A.total_extent.1 <= (int64)2147483647, halide_error_buffer_extents_too_large("A", A.total_extent.1, (int64)2147483647))
 assert(uint64(B.extent.0) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("B", uint64(B.extent.0), (uint64)2147483647))
 assert((uint64)abs(int64(B.extent.1)*int64(B.stride.1)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("B", (uint64)abs(int64(B.extent.1)*int64(B.stride.1)), (uint64)2147483647))
 assert(B.total_extent.1 <= (int64)2147483647, halide_error_buffer_extents_too_large("B", B.total_extent.1, (int64)2147483647))
 assert(uint64(out.extent.0) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("out", uint64(out.extent.0), (uint64)2147483647))
 assert((uint64)abs(int64(out.extent.1)*int64(out.stride.1)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("out", (uint64)abs(int64(out.extent.1)*int64(out.stride.1)), (uint64)2147483647))
 assert(out.total_extent.1 <= (int64)2147483647, halide_error_buffer_extents_too_large("out", out.total_extent.1, (int64)2147483647))
 assert((0 <= out.min.1) && ((out.extent.1 + out.min.1) <= 128), halide_error_explicit_bounds_too_small("y", "out", 0, 127, out.min.1, (out.extent.1 + out.min.1) + -1))
 assert((0 <= out.min.0) && ((out.extent.0 + out.min.0) <= 128), halide_error_explicit_bounds_too_small("x", "out", 0, 127, out.min.0, (out.extent.0 + out.min.0) + -1))
 produce out {
  let t190 = (B.min.1*B.stride.1) + B.min.0
  let t191 = (A.min.1*A.stride.1) + A.min.0
  for<Hexagon> (out.s0.__outermost, 0, 1) {
   parallel (out.s0.x.x.xy, 0, 9) {
    let t195 = min((out.s0.x.x.xy % 3)*48, 80)
    let t192 = min((out.s0.x.x.xy/3)*48, 80)
    let t193 = t195 - t190
    for (out.s0.y.yi.yi, 0, 12) {
     let out.s0.y.min_2 = (out.s0.y.yi.yi*4) + t192
     allocate matrix_mul[uint16 * 64 * 4]
     produce matrix_mul {
      for<Hexagon> (matrix_mul.s0.__outermost, 0, 1) {
       matrix_mul[ramp(0, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(16, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(64, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(80, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(128, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(144, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(192, 1, 32)] = x32((uint16)0)
       matrix_mul[ramp(208, 1, 32)] = x32((uint16)0)
      }
      let t199 = ((out.s0.y.min_2 + 3)*A.stride.1) - t191
      let t198 = ((out.s0.y.min_2 + 2)*A.stride.1) - t191
      let t197 = ((out.s0.y.min_2 + 1)*A.stride.1) - t191
      let t196 = (A.stride.1*out.s0.y.min_2) - t191
      for (matrix_mul.s1.k$x.k$x, 0, 32) {
       matrix_mul[ramp(0, 1, 32)] = matrix_mul[ramp(0, 1, 32)] + (B[ramp(((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t196]))
       matrix_mul[ramp(32, 1, 32)] = matrix_mul[ramp(32, 1, 32)] + (B[ramp((((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193) + 32, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t196]))
       matrix_mul[ramp(64, 1, 32)] = matrix_mul[ramp(64, 1, 32)] + (B[ramp(((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t197]))
       matrix_mul[ramp(96, 1, 32)] = matrix_mul[ramp(96, 1, 32)] + (B[ramp((((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193) + 32, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t197]))
       matrix_mul[ramp(128, 1, 32)] = matrix_mul[ramp(128, 1, 32)] + (B[ramp(((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t198]))
       matrix_mul[ramp(160, 1, 32)] = matrix_mul[ramp(160, 1, 32)] + (B[ramp((((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193) + 32, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t198]))
       matrix_mul[ramp(192, 1, 32)] = matrix_mul[ramp(192, 1, 32)] + (B[ramp(((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t199]))
       matrix_mul[ramp(224, 1, 32)] = matrix_mul[ramp(224, 1, 32)] + (B[ramp((((B.stride.1*matrix_mul.s1.k$x.k$x)*4) + t193) + 32, 1, 32)]*x32(A[(matrix_mul.s1.k$x.k$x*4) + t199]))
       matrix_mul[ramp(0, 1, 32)] = matrix_mul[ramp(0, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 1]))
       matrix_mul[ramp(32, 1, 32)] = matrix_mul[ramp(32, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 1]))
       matrix_mul[ramp(64, 1, 32)] = matrix_mul[ramp(64, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 1]))
       matrix_mul[ramp(96, 1, 32)] = matrix_mul[ramp(96, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 1]))
       matrix_mul[ramp(128, 1, 32)] = matrix_mul[ramp(128, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 1]))
       matrix_mul[ramp(160, 1, 32)] = matrix_mul[ramp(160, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 1]))
       matrix_mul[ramp(192, 1, 32)] = matrix_mul[ramp(192, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 1]))
       matrix_mul[ramp(224, 1, 32)] = matrix_mul[ramp(224, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 1)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 1]))
       matrix_mul[ramp(0, 1, 32)] = matrix_mul[ramp(0, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 2]))
       matrix_mul[ramp(32, 1, 32)] = matrix_mul[ramp(32, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 2]))
       matrix_mul[ramp(64, 1, 32)] = matrix_mul[ramp(64, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 2]))
       matrix_mul[ramp(96, 1, 32)] = matrix_mul[ramp(96, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 2]))
       matrix_mul[ramp(128, 1, 32)] = matrix_mul[ramp(128, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 2]))
       matrix_mul[ramp(160, 1, 32)] = matrix_mul[ramp(160, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 2]))
       matrix_mul[ramp(192, 1, 32)] = matrix_mul[ramp(192, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 2]))
       matrix_mul[ramp(224, 1, 32)] = matrix_mul[ramp(224, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 2)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 2]))
       matrix_mul[ramp(0, 1, 32)] = matrix_mul[ramp(0, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 3]))
       matrix_mul[ramp(32, 1, 32)] = matrix_mul[ramp(32, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t196) + 3]))
       matrix_mul[ramp(64, 1, 32)] = matrix_mul[ramp(64, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 3]))
       matrix_mul[ramp(96, 1, 32)] = matrix_mul[ramp(96, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t197) + 3]))
       matrix_mul[ramp(128, 1, 32)] = matrix_mul[ramp(128, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 3]))
       matrix_mul[ramp(160, 1, 32)] = matrix_mul[ramp(160, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t198) + 3]))
       matrix_mul[ramp(192, 1, 32)] = matrix_mul[ramp(192, 1, 32)] + (B[ramp((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 3]))
       matrix_mul[ramp(224, 1, 32)] = matrix_mul[ramp(224, 1, 32)] + (B[ramp(((((matrix_mul.s1.k$x.k$x*4) + 3)*B.stride.1) + t193) + 32, 1, 32)]*x32(A[((matrix_mul.s1.k$x.k$x*4) + t199) + 3]))
      }
     }
     consume matrix_mul {
      let t23 = (out.s0.y.yi.yi*4) + t192
      out[ramp((out.stride.1*t23) + t195, 1, 32) aligned(4, 0)] = matrix_mul[ramp(0, 1, 32)]
      out[ramp(((out.stride.1*t23) + t195) + 16, 1, 32) aligned(4, 0)] = matrix_mul[ramp(16, 1, 32)]
      out[ramp(((t23 + 1)*out.stride.1) + t195, 1, 32)] = matrix_mul[ramp(64, 1, 32)]
      out[ramp((((t23 + 1)*out.stride.1) + t195) + 16, 1, 32)] = matrix_mul[ramp(80, 1, 32)]
      out[ramp(((t23 + 2)*out.stride.1) + t195, 1, 32) aligned(2, 0)] = matrix_mul[ramp(128, 1, 32)]
      out[ramp((((t23 + 2)*out.stride.1) + t195) + 16, 1, 32) aligned(2, 0)] = matrix_mul[ramp(144, 1, 32)]
      out[ramp(((t23 + 3)*out.stride.1) + t195, 1, 32)] = matrix_mul[ramp(192, 1, 32)]
      out[ramp((((t23 + 3)*out.stride.1) + t195) + 16, 1, 32)] = matrix_mul[ramp(208, 1, 32)]
      free matrix_mul
     }
    }
   }
  }
 }
}
}


