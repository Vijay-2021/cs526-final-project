#ifndef conv_nn_batch_0035_sample_0009_SCHEDULE_H
#define conv_nn_batch_0035_sample_0009_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=x86-64-linux-avx-avx2-avx512-avx512_sapphirerapids-avx512_skylake-disable_llvm_loop_opt-f16c-fma-sse41  // NOLINT
// with machine_params=10,16777216,40

#include "Halide.h"


inline void apply_schedule_conv_nn_batch_0035_sample_0009(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func output = pipeline.get_func(7);
    Func convolved = pipeline.get_func(6);
    Func sum_input = pipeline.get_func(5);
    Func offset_c = pipeline.get_func(4);
    Func input_wrapper = pipeline.get_func(2);
    Var b(output.get_schedule().dims()[3].var);
    Var bi("bi");
    Var c(output.get_schedule().dims()[0].var);
    Var ci("ci");
    Var cii("cii");
    Var x(output.get_schedule().dims()[1].var);
    Var xi("xi");
    Var y(output.get_schedule().dims()[2].var);
    RVar r19_x(convolved.update(0).get_schedule().dims()[0].var);
    RVar r19_y(convolved.update(0).get_schedule().dims()[1].var);
    RVar r19_z(convolved.update(0).get_schedule().dims()[2].var);
    output
        .split(c, c, ci, 128, TailStrategy::ShiftInwards)
        .split(x, x, xi, 2, TailStrategy::ShiftInwards)
        .split(ci, ci, cii, 64, TailStrategy::ShiftInwards)
        .unroll(ci)
        .unroll(xi)
        .vectorize(cii)
        .compute_root()
        .reorder({cii, ci, xi, c, x, y, b})
        .fuse(x, y, x)
        .fuse(c, x, c)
        .parallel(c);
    convolved
        .split(c, c, ci, 64, TailStrategy::ShiftInwards)
        .unroll(c)
        .vectorize(ci)
        .compute_at(output, c)
        .reorder({ci, c, x, y, b});
    convolved.update(0)
        .split(c, c, ci, 64, TailStrategy::GuardWithIf)
        .vectorize(ci)
        .reorder({ci, r19_x, r19_y, r19_z, c, x, y, b});
    sum_input
        .store_in(MemoryType::Stack)
        .split(b, b, bi, 16, TailStrategy::RoundUp)
        .vectorize(bi)
        .compute_at(convolved, x)
        .reorder({bi, b, x, y})
        .reorder_storage(b, x, y);
    sum_input.update(0)
        .split(b, b, bi, 64, TailStrategy::GuardWithIf)
        .vectorize(bi)
        .reorder({bi, r19_x, r19_y, r19_z, b, x, y});
    offset_c
        .split(c, c, ci, 16, TailStrategy::RoundUp)
        .unroll(c)
        .vectorize(ci)
        .compute_at(output, c)
        .reorder({ci, c});
    offset_c.update(0)
        .split(c, c, ci, 64, TailStrategy::GuardWithIf)
        .unroll(c)
        .vectorize(ci)
        .reorder({ci, c, r19_x, r19_y, r19_z});
    offset_c.update(1)
        .split(c, c, ci, 64, TailStrategy::GuardWithIf)
        .unroll(c)
        .vectorize(ci)
        .reorder({ci, c});

}

#endif  // conv_nn_batch_0035_sample_0009_SCHEDULE_H
