#ifndef fully_connected_batch_0029_sample_0031_SCHEDULE_H
#define fully_connected_batch_0029_sample_0031_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=x86-64-linux-avx-avx2-disable_llvm_loop_opt-f16c-fma-sse41  // NOLINT
// with machine_params=32,24000000,40

#include "Halide.h"


inline void apply_schedule_fully_connected_batch_0029_sample_0031(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func output = pipeline.get_func(4);
    Func multiplied = pipeline.get_func(3);
    Var b(output.get_schedule().dims()[1].var);
    Var bi("bi");
    Var c(output.get_schedule().dims()[0].var);
    Var ci("ci");
    Var cii("cii");

    // Added vectorization factors
    RVar r9_x(multiplied.update(0).get_schedule().dims()[0].var);
    output
        .split(c, c, ci, 480, TailStrategy::ShiftInwards)
        .split(b, b, bi, 9, TailStrategy::ShiftInwards)
        .split(ci, ci, cii, 32, TailStrategy::ShiftInwards)
        .unroll(bi)
        .vectorize(cii, 512/ 64)
        .compute_root()
        .reorder({cii, bi, ci, c, b})
        .fuse(c, b, c)
        .parallel(c);
    multiplied.update(0)
        .split(c, c, ci, 32, TailStrategy::GuardWithIf)
        .unroll(b)
        .vectorize(ci, 512 / 64)
        .reorder({ci, c, b, r9_x});
    multiplied
        .store_in(MemoryType::Stack)
        .split(c, c, ci, 8, TailStrategy::ShiftInwards)
        .vectorize(ci, 512 / 64)
        .compute_at(output, ci)
        .reorder({ci, c, b});

}

#endif  // fully_connected_batch_0029_sample_0031_SCHEDULE_H
